{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 3D Medical Image Segmentation with nnUNetV2 (Lower Limb)\n",
        "\n",
        "This notebook demonstrates a complete workflow for performing 3D medical image segmentation, specifically targeting lower limb structures, using the powerful `nnUNetV2` framework. The process involves:\n",
        "\n",
        "1.  **Environment Setup**: Installing necessary libraries.\n",
        "2.  **Data Preparation**: Mounting Google Drive, defining paths, and organizing input data and model checkpoints.\n",
        "3.  **Model Loading**: Initializing and loading a pre-trained `nnUNetV2` model.\n",
        "4.  **Inference**: Executing the segmentation prediction on a raw medical image.\n",
        "5.  **Result Analysis**: Calculating and displaying volumetric statistics of the segmented anatomical structures and saving the results.\n",
        "\n",
        "This workflow is designed to be easily adaptable for various medical image segmentation tasks using `nnUNetV2` models."
      ],
      "metadata": {
        "id": "59oWO272vP4V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Environment Setup\n",
        "\n",
        "This section handles the installation of the required Python libraries. We will install `nnunetv2`, the core framework for 3D medical image segmentation, and `nibabel`, which is essential for reading and writing neuroimaging file formats such as NIfTI (.nii.gz)."
      ],
      "metadata": {
        "id": "Sp5WcHYlvWND"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import sys\n",
        "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"nnunetv2\", \"nibabel\"], check=True)\n",
        "print(\"‚úÖ Installation complete\\n\")"
      ],
      "metadata": {
        "id": "4Y2BI1w9gJW_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3194f91a-e175-4153-d637-ba90d1410d44"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Installation complete\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparation: Mounting Google Drive\n",
        "\n",
        "This section handles the mounting of Google Drive, which is crucial for this notebook's operation. By mounting Google Drive, we gain access to essential input files, including the raw NIfTI medical image for segmentation, the pre-trained `nnUNetV2` model checkpoint, and configuration files (`dataset.json`, `plans.json`). It also allows us to save the final segmentation results directly back to Google Drive for persistent storage and future use."
      ],
      "metadata": {
        "id": "a-qC2WbDvkeG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "print(\"üìÅ Mounting Google Drive...\")\n",
        "drive.mount('/content/drive')\n",
        "print(\"‚úÖ Drive mounted\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZalJGRrpIpr",
        "outputId": "2a1f799a-402c-4da1-b768-53bc7030013b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÅ Mounting Google Drive...\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "‚úÖ Drive mounted\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Preparation: Configuration\n",
        "\n",
        "This section sets up the environment and prepares all necessary files for the `nnUNetV2` inference. It defines critical paths for input data, model checkpoints, and output results, both on Google Drive and within the Colab working directory. It also creates the required directory structure and copies the model and input files from Google Drive to the local working environment, ensuring that the `nnUNetV2` predictor has access to all its dependencies."
      ],
      "metadata": {
        "id": "2zT2M-CUvwaF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "import torch\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"‚öôÔ∏è  CONFIGURATION\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Files on Google Drive\n",
        "INPUT_FILE = \"/content/drive/MyDrive/SMIR.Lower_limb.051Y.F.CT.168-Pelvis-Thighs.nii.gz\"\n",
        "CHECKPOINT_FILE = \"/content/drive/MyDrive/checkpoint_best.pth\"\n",
        "DATASET_JSON = \"/content/drive/MyDrive/dataset.json\"\n",
        "PLANS_JSON = \"/content/drive/MyDrive/plans.json\"\n",
        "\n",
        "# Working directories\n",
        "WORK_DIR = \"/content/nnunet_inference\"\n",
        "MODEL_DIR = f\"{WORK_DIR}/model\"\n",
        "INPUT_DIR = f\"{WORK_DIR}/input\"\n",
        "OUTPUT_DIR = f\"{WORK_DIR}/output\"\n",
        "\n",
        "# Create structure (include fold_0 for the checkpoint)\n",
        "FOLD_DIR = f\"{MODEL_DIR}/fold_0\"\n",
        "for d in [MODEL_DIR, FOLD_DIR, INPUT_DIR, OUTPUT_DIR]:\n",
        "    Path(d).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Verify source files\n",
        "print(\"\\nüîç Verifying files:\")\n",
        "files_ok = True\n",
        "for name, path in [\n",
        "    (\"Input NIfTI\", INPUT_FILE),\n",
        "    (\"Checkpoint\", CHECKPOINT_FILE),\n",
        "    (\"Dataset JSON\", DATASET_JSON),\n",
        "    (\"Plans JSON\", PLANS_JSON)\n",
        "]:\n",
        "    if os.path.exists(path):\n",
        "        size_mb = os.path.getsize(path) / (1024 * 1024)\n",
        "        print(f\"  ‚úÖ {name}: {size_mb:.1f} MB\")\n",
        "    else:\n",
        "        print(f\"  ‚ùå {name}: NOT FOUND - {path}\")\n",
        "        files_ok = False\n",
        "\n",
        "if not files_ok:\n",
        "    raise FileNotFoundError(\"Missing files on Google Drive!\")\n",
        "\n",
        "# Copy files to the working folder\n",
        "print(\"\\nüìã Preparing files...\")\n",
        "shutil.copy(PLANS_JSON, f\"{MODEL_DIR}/plans.json\")\n",
        "shutil.copy(CHECKPOINT_FILE, f\"{FOLD_DIR}/checkpoint_best.pth\")  # In fold_0/\n",
        "shutil.copy(INPUT_FILE, f\"{INPUT_DIR}/case_001_0000.nii.gz\")\n",
        "if os.path.exists(DATASET_JSON):\n",
        "    shutil.copy(DATASET_JSON, f\"{MODEL_DIR}/dataset.json\")\n",
        "\n",
        "print(\"‚úÖ Files prepared\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGzPVSG2pK0d",
        "outputId": "218e5f50-7c99-4850-ad4a-d2e57ad0ab61"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "‚öôÔ∏è  CONFIGURATION\n",
            "======================================================================\n",
            "\n",
            "üîç Verifying files:\n",
            "  ‚úÖ Input NIfTI: 72.0 MB\n",
            "  ‚úÖ Checkpoint: 341.6 MB\n",
            "  ‚úÖ Dataset JSON: 0.0 MB\n",
            "  ‚úÖ Plans JSON: 0.0 MB\n",
            "\n",
            "üìã Preparing files...\n",
            "‚úÖ Files prepared\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Loading\n",
        "\n",
        "This section focuses on initializing and loading the pre-trained `nnUNetV2` model. It detects the available computing device (GPU if available, otherwise CPU) and then sets up the `nnUNetPredictor` with specific inference parameters. Finally, it loads the model weights from the provided checkpoint file into the predictor, preparing it for the segmentation task."
      ],
      "metadata": {
        "id": "p0uOpzzuv40A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nnunetv2.inference.predict_from_raw_data import nnUNetPredictor\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"üöÄ MODEL LOADING\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"üñ•Ô∏è  Device: {device}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
        "\n",
        "# Initialize the predictor\n",
        "print(\"\\nüì¶ Initializing predictor...\")\n",
        "predictor = nnUNetPredictor(\n",
        "    tile_step_size=0.5,\n",
        "    use_gaussian=True,\n",
        "    use_mirroring=True,\n",
        "    perform_everything_on_device=True,\n",
        "    device=device,\n",
        "    verbose=False,\n",
        "    allow_tqdm=True\n",
        ")\n",
        "\n",
        "# Load the model from the checkpoint\n",
        "print(\"üîÑ Loading checkpoint...\")\n",
        "predictor.initialize_from_trained_model_folder(\n",
        "    MODEL_DIR,\n",
        "    use_folds=(0,),\n",
        "    checkpoint_name='checkpoint_best.pth'\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Model loaded successfully!\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pu7KqYn7pQh_",
        "outputId": "9972b5c0-5253-4ad8-dc20-f75c69aa479a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "üöÄ MODEL LOADING\n",
            "======================================================================\n",
            "üñ•Ô∏è  Device: cuda\n",
            "   GPU: Tesla T4\n",
            "\n",
            "üì¶ Initializing predictor...\n",
            "üîÑ Loading checkpoint...\n",
            "‚úÖ Model loaded successfully!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inference\n",
        "\n",
        "This section performs the actual segmentation of the medical image using the loaded `nnUNetV2` model. The `predict_from_files` method of the `nnUNetPredictor` is invoked, taking the prepared input image from the specified input directory and generating the segmentation mask, which is then saved to the output directory. This step leverages the power of the pre-trained model to automatically identify and delineate anatomical structures within the 3D medical scan."
      ],
      "metadata": {
        "id": "6CENqORZwB0N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nibabel as nib\n",
        "import numpy as np\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"üß† INFERENCE\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "print(f\"üìÇ Input: {INPUT_DIR}\")\n",
        "print(f\"üìÇ Output: {OUTPUT_DIR}\")\n",
        "\n",
        "# Launch inference\n",
        "print(\"\\nüöÄ Launching inference...\")\n",
        "predictor.predict_from_files(\n",
        "    list_of_lists_or_source_folder=INPUT_DIR,\n",
        "    output_folder_or_list_of_truncated_output_files=OUTPUT_DIR,\n",
        "    save_probabilities=False,\n",
        "    overwrite=True,\n",
        "    num_processes_preprocessing=2,\n",
        "    num_processes_segmentation_export=2,\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Inference complete!\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mb1ezERxpTMD",
        "outputId": "25bba8af-216a-4430-a29e-41f23263977b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "üß† INFERENCE\n",
            "======================================================================\n",
            "üìÇ Input: /content/nnunet_inference/input\n",
            "üìÇ Output: /content/nnunet_inference/output\n",
            "\n",
            "üöÄ Launching inference...\n",
            "There are 1 cases in the source folder\n",
            "I am processing 0 out of 1 (max process ID is 0, we start counting with 0!)\n",
            "There are 1 cases that I would like to predict\n",
            "\n",
            "Predicting case_001:\n",
            "perform_everything_on_device: True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 252/252 [07:28<00:00,  1.78s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sending off prediction to background worker for resampling and export\n",
            "done with case_001\n",
            "‚úÖ Inference complete!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Statistics and Result Saving\n",
        "\n",
        "This final section is dedicated to analyzing the segmentation results and saving them. It loads the generated NIfTI segmentation file, calculates volumetric statistics for each detected anatomical structure (bones) based on predefined labels, and then saves the final segmentation output to Google Drive for future reference and persistent storage."
      ],
      "metadata": {
        "id": "lLNyLBK1xUNw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nibabel as nib\n",
        "import numpy as np\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"üìä STATISTICS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Labels\n",
        "LABELS = {\n",
        "    0: \"background\",\n",
        "    1: \"Femur_L\",\n",
        "    2: \"Femur_R\",\n",
        "    3: \"Hip_L\",\n",
        "    4: \"Hip_R\",\n",
        "    5: \"Patella_L\",\n",
        "    6: \"Patella_R\",\n",
        "    7: \"Sacrum\",\n",
        "    8: \"Threshold-200-MAX\"\n",
        "}\n",
        "\n",
        "# Find the output file\n",
        "output_files = list(Path(OUTPUT_DIR).glob(\"*.nii.gz\"))\n",
        "if output_files:\n",
        "    output_file = output_files[0]\n",
        "    print(f\"‚úÖ Segmentation: {output_file.name}\\n\")\n",
        "\n",
        "    # Load and analyze\n",
        "    nii = nib.load(str(output_file))\n",
        "    seg_data = nii.get_fdata()\n",
        "    spacing = nii.header.get_zooms()\n",
        "\n",
        "    print(f\"üìè Dimensions: {seg_data.shape}\")\n",
        "    print(f\"üìè Spacing: {spacing}\")\n",
        "    print(f\"\\nü¶¥ Detected Bones:\")\n",
        "\n",
        "    # Statistics per bone\n",
        "    for label_id in np.unique(seg_data):\n",
        "        if label_id > 0:\n",
        "            voxel_count = int(np.sum(seg_data == label_id))\n",
        "            volume_mm3 = float(voxel_count * np.prod(spacing))\n",
        "            volume_cm3 = volume_mm3 / 1000\n",
        "            label_name = LABELS.get(int(label_id), f\"Unknown_{int(label_id)}\")\n",
        "            print(f\"   ‚Ä¢ {label_name:20s}: {voxel_count:8,} voxels ({volume_cm3:8.2f} cm¬≥)\")\n",
        "\n",
        "    # Save to Google Drive\n",
        "    output_on_drive = \"/content/drive/MyDrive/segmentation_result.nii.gz\"\n",
        "    shutil.copy(str(output_file), output_on_drive)\n",
        "\n",
        "    print(f\"\\nüíæ Result saved on Google Drive:\")\n",
        "    print(f\"   {output_on_drive}\")\n",
        "\n",
        "else:\n",
        "    print(\"‚ùå No output file found!\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"‚úÖ COMPLETED!\")\n",
        "print(\"=\" * 70)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPOigB0hpW3r",
        "outputId": "7e13793d-6747-4b1a-8c41-4a1fb5a164c1"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "üìä STATISTICS\n",
            "======================================================================\n",
            "‚úÖ Segmentation: case_001.nii.gz\n",
            "\n",
            "üìè Dimensions: (312, 205, 889)\n",
            "üìè Spacing: (np.float32(0.9765625), np.float32(0.9765625), np.float32(0.6997555))\n",
            "\n",
            "ü¶¥ Detected Bones:\n",
            "   ‚Ä¢ Femur_L             :  943,041 voxels (  629.33 cm¬≥)\n",
            "   ‚Ä¢ Hip_L               :  730,025 voxels (  487.17 cm¬≥)\n",
            "   ‚Ä¢ Patella_L           :   51,400 voxels (   34.30 cm¬≥)\n",
            "   ‚Ä¢ Patella_R           :      930 voxels (    0.62 cm¬≥)\n",
            "   ‚Ä¢ Sacrum              :  195,121 voxels (  130.21 cm¬≥)\n",
            "   ‚Ä¢ Threshold-200-MAX   :  236,533 voxels (  157.85 cm¬≥)\n",
            "\n",
            "üíæ Result saved on Google Drive:\n",
            "   /content/drive/MyDrive/segmentation_result.nii.gz\n",
            "\n",
            "======================================================================\n",
            "‚úÖ COMPLETED!\n",
            "======================================================================\n"
          ]
        }
      ]
    }
  ]
}