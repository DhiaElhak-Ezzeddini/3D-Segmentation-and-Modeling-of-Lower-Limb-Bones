
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-11-22 01:40:12.387565: Using torch.compile... 
2025-11-22 01:40:16.671850: do_dummy_2d_data_aug: True 
2025-11-22 01:40:16.672338: Creating new 5-fold cross-validation split... 
2025-11-22 01:40:16.675444: Desired fold for training: 5 
2025-11-22 01:40:16.675560: INFO: You requested fold 5 for training but splits contain only 5 folds. I am now creating a random (but seeded) 80:20 split! 
2025-11-22 01:40:16.676612: This random 80:20 split has 18 training and 5 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [48, 384, 64], 'median_image_size_in_voxels': [158.0, 1284.0, 261.0], 'spacing': [1.26953125, 0.5, 1.26953125], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 7, 'features_per_stage': [32, 64, 128, 256, 320, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[1, 3, 1], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [1, 2, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2], [1, 2, 1]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset001_PelvisThighs', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.26953125, 0.5, 1.26953125], 'original_median_shape_after_transp': [184, 1284, 310], 'image_reader_writer': 'NibabelIO', 'transpose_forward': [1, 0, 2], 'transpose_backward': [1, 0, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 3071.0, 'mean': 613.2944946289062, 'median': 443.0, 'min': -136.0, 'percentile_00_5': 181.0, 'percentile_99_5': 1723.0, 'std': 426.4911193847656}}} 
 
2025-11-22 01:40:53.662390: Unable to plot network architecture: nnUNet_compile is enabled! 
2025-11-22 01:40:53.698929:  
2025-11-22 01:40:53.704129: Epoch 0 
2025-11-22 01:40:53.704517: Current learning rate: 0.01 
2025-11-22 01:45:07.878479: train_loss 0.3294 
2025-11-22 01:45:07.878734: val_loss 0.1868 
2025-11-22 01:45:07.879216: Pseudo dice [0.2916, 0.0, 0.0, 0.0009, 0.0, 0.0, 0.0, 0.0] 
2025-11-22 01:45:07.879399: Epoch time: 254.19 s 
2025-11-22 01:45:07.879540: Yayy! New best EMA pseudo Dice: 0.0366 
2025-11-22 01:45:10.015559:  
2025-11-22 01:45:10.015863: Epoch 1 
2025-11-22 01:45:10.016047: Current learning rate: 0.00999 
2025-11-22 01:46:53.187514: train_loss 0.1643 
2025-11-22 01:46:53.187777: val_loss 0.1589 
2025-11-22 01:46:53.187971: Pseudo dice [0.0124, 0.3162, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] 
2025-11-22 01:46:53.188089: Epoch time: 103.17 s 
2025-11-22 01:46:53.188217: Yayy! New best EMA pseudo Dice: 0.037 
2025-11-22 01:46:56.330036:  
2025-11-22 01:46:56.330369: Epoch 2 
2025-11-22 01:46:56.330552: Current learning rate: 0.00998 
2025-11-22 01:48:37.224989: train_loss 0.1278 
2025-11-22 01:48:37.225371: val_loss 0.1234 
2025-11-22 01:48:37.225598: Pseudo dice [0.0061, 0.3938, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] 
2025-11-22 01:48:37.225735: Epoch time: 100.9 s 
2025-11-22 01:48:37.225880: Yayy! New best EMA pseudo Dice: 0.0383 
2025-11-22 01:48:40.260254:  
2025-11-22 01:48:40.260570: Epoch 3 
2025-11-22 01:48:40.260735: Current learning rate: 0.00997 
2025-11-22 01:50:20.809250: train_loss 0.11 
2025-11-22 01:50:20.809488: val_loss 0.127 
2025-11-22 01:50:20.809696: Pseudo dice [0.0754, 0.381, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] 
2025-11-22 01:50:20.809851: Epoch time: 100.55 s 
2025-11-22 01:50:20.810064: Yayy! New best EMA pseudo Dice: 0.0402 
2025-11-22 01:50:23.623261:  
2025-11-22 01:50:23.623585: Epoch 4 
2025-11-22 01:50:23.623800: Current learning rate: 0.00996 
2025-11-22 01:52:04.481060: train_loss 0.1193 
2025-11-22 01:52:04.481334: val_loss 0.101 
2025-11-22 01:52:04.481616: Pseudo dice [0.3503, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] 
2025-11-22 01:52:04.481792: Epoch time: 100.86 s 
2025-11-22 01:52:04.481913: Yayy! New best EMA pseudo Dice: 0.0406 
2025-11-22 01:52:07.328932:  
2025-11-22 01:52:07.329267: Epoch 5 
2025-11-22 01:52:07.329461: Current learning rate: 0.00995 
2025-11-22 01:53:47.584155: train_loss 0.0921 
2025-11-22 01:53:47.584444: val_loss 0.1362 
2025-11-22 01:53:47.584619: Pseudo dice [0.1051, 0.332, 0.0, 0.0142, 0.0, 0.0, 0.0, 0.0] 
2025-11-22 01:53:47.584728: Epoch time: 100.26 s 
2025-11-22 01:53:47.584857: Yayy! New best EMA pseudo Dice: 0.0421 
2025-11-22 01:53:50.279253:  
2025-11-22 01:53:50.279546: Epoch 6 
2025-11-22 01:53:50.279723: Current learning rate: 0.00995 
2025-11-22 01:55:30.373561: train_loss 0.0848 
2025-11-22 01:55:30.373922: val_loss 0.1072 
2025-11-22 01:55:30.374128: Pseudo dice [0.0, 0.4374, 0.0875, 0.0004, 0.0, 0.0, 0.0, 0.0] 
2025-11-22 01:55:30.374265: Epoch time: 100.1 s 
2025-11-22 01:55:30.374392: Yayy! New best EMA pseudo Dice: 0.0445 
2025-11-22 01:55:33.507985:  
2025-11-22 01:55:33.508287: Epoch 7 
2025-11-22 01:55:33.508451: Current learning rate: 0.00994 
2025-11-22 01:57:13.993694: train_loss 0.076 
2025-11-22 01:57:13.993948: val_loss 0.1018 
2025-11-22 01:57:13.994144: Pseudo dice [0.4614, 0.0, 0.2306, 0.0006, 0.0, 0.0, 0.0, 0.0] 
2025-11-22 01:57:13.994290: Epoch time: 100.49 s 
2025-11-22 01:57:13.994397: Yayy! New best EMA pseudo Dice: 0.0487 
2025-11-22 01:57:16.918555:  
2025-11-22 01:57:16.918804: Epoch 8 
2025-11-22 01:57:16.918975: Current learning rate: 0.00993 
2025-11-22 01:58:57.718754: train_loss 0.0566 
2025-11-22 01:58:57.719014: val_loss 0.0639 
2025-11-22 01:58:57.719222: Pseudo dice [0.2756, 0.452, 0.0, 0.2802, 0.0, 0.0, 0.0, 0.0349] 
2025-11-22 01:58:57.719411: Epoch time: 100.8 s 
2025-11-22 01:58:57.719543: Yayy! New best EMA pseudo Dice: 0.0569 
2025-11-22 01:59:00.616452:  
2025-11-22 01:59:00.616747: Epoch 9 
2025-11-22 01:59:00.616937: Current learning rate: 0.00992 
2025-11-22 02:00:41.442023: train_loss 0.0631 
2025-11-22 02:00:41.442345: val_loss 0.058 
2025-11-22 02:00:41.442797: Pseudo dice [0.4655, 0.0, 0.4026, 0.018, 0.0, 0.0, 0.0, 0.2659] 
2025-11-22 02:00:41.442974: Epoch time: 100.83 s 
2025-11-22 02:00:41.443077: Yayy! New best EMA pseudo Dice: 0.0656 
2025-11-22 02:00:44.292482:  
2025-11-22 02:00:44.292847: Epoch 10 
2025-11-22 02:00:44.293018: Current learning rate: 0.00991 
2025-11-22 02:02:25.337034: train_loss 0.0321 
2025-11-22 02:02:25.337467: val_loss 0.0373 
2025-11-22 02:02:25.337675: Pseudo dice [0.4959, 0.0303, 0.4629, 0.0, 0.0, 0.0, 0.0, 0.5016] 
2025-11-22 02:02:25.337851: Epoch time: 101.05 s 
2025-11-22 02:02:25.337968: Yayy! New best EMA pseudo Dice: 0.0777 
2025-11-22 02:02:28.630368:  
2025-11-22 02:02:28.630696: Epoch 11 
2025-11-22 02:02:28.630877: Current learning rate: 0.0099 
2025-11-22 02:04:09.947382: train_loss 0.0106 
2025-11-22 02:04:09.947737: val_loss 0.0414 
2025-11-22 02:04:09.947991: Pseudo dice [0.0, 0.6503, 0.3141, 0.2999, 0.0, 0.0, 0.0, 0.5195] 
2025-11-22 02:04:09.948128: Epoch time: 101.32 s 
2025-11-22 02:04:09.948278: Yayy! New best EMA pseudo Dice: 0.0922 
2025-11-22 02:04:12.846491:  
2025-11-22 02:04:12.846849: Epoch 12 
2025-11-22 02:04:12.847039: Current learning rate: 0.00989 
2025-11-22 02:05:54.435440: train_loss 0.001 
2025-11-22 02:05:54.435699: val_loss 0.0651 
2025-11-22 02:05:54.435959: Pseudo dice [0.0, 0.3772, 0.0152, 0.4149, 0.0, 0.0, 0.0668, 0.5967] 
2025-11-22 02:05:54.436067: Epoch time: 101.59 s 
2025-11-22 02:05:54.436138: Yayy! New best EMA pseudo Dice: 0.1013 
2025-11-22 02:05:57.216139:  
2025-11-22 02:05:57.216548: Epoch 13 
2025-11-22 02:05:57.216719: Current learning rate: 0.00988 
2025-11-22 02:07:38.901881: train_loss -0.0105 
2025-11-22 02:07:38.902181: val_loss 0.0306 
2025-11-22 02:07:38.902408: Pseudo dice [0.0, 0.5338, 0.0, 0.4463, 0.0, 0.0, 0.0011, 0.4225] 
2025-11-22 02:07:38.902611: Epoch time: 101.69 s 
2025-11-22 02:07:38.902735: Yayy! New best EMA pseudo Dice: 0.1088 
2025-11-22 02:07:41.763228:  
2025-11-22 02:07:41.763388: Epoch 14 
2025-11-22 02:07:41.763569: Current learning rate: 0.00987 
2025-11-22 02:09:23.397666: train_loss -0.0194 
2025-11-22 02:09:23.397990: val_loss -0.0149 
2025-11-22 02:09:23.398200: Pseudo dice [0.1527, 0.5649, 0.0, 0.3767, 0.0, 0.0, 0.0124, 0.6863] 
2025-11-22 02:09:23.398434: Epoch time: 101.64 s 
2025-11-22 02:09:23.398543: Yayy! New best EMA pseudo Dice: 0.1203 
2025-11-22 02:09:26.162321:  
2025-11-22 02:09:26.162587: Epoch 15 
2025-11-22 02:09:26.162783: Current learning rate: 0.00986 
2025-11-22 02:11:07.496657: train_loss -0.039 
2025-11-22 02:11:07.497013: val_loss -0.0109 
2025-11-22 02:11:07.497343: Pseudo dice [0.3976, 0.3985, 0.3193, 0.0061, 0.0115, 0.0, 0.2814, 0.5961] 
2025-11-22 02:11:07.497508: Epoch time: 101.34 s 
2025-11-22 02:11:07.497630: Yayy! New best EMA pseudo Dice: 0.1334 
2025-11-22 02:11:11.007796:  
2025-11-22 02:11:11.008167: Epoch 16 
2025-11-22 02:11:11.008379: Current learning rate: 0.00986 
2025-11-22 02:12:51.941540: train_loss -0.046 
2025-11-22 02:12:51.941851: val_loss -0.021 
2025-11-22 02:12:51.942167: Pseudo dice [0.0, 0.6565, 0.5566, 0.0, 0.2807, 0.0, 0.4498, 0.722] 
2025-11-22 02:12:51.942417: Epoch time: 100.94 s 
2025-11-22 02:12:51.942552: Yayy! New best EMA pseudo Dice: 0.1534 
2025-11-22 02:12:54.924893:  
2025-11-22 02:12:54.925225: Epoch 17 
2025-11-22 02:12:54.925402: Current learning rate: 0.00985 
2025-11-22 02:14:36.750341: train_loss -0.0503 
2025-11-22 02:14:36.750692: val_loss -0.0492 
2025-11-22 02:14:36.750978: Pseudo dice [0.0, 0.4888, 0.0004, 0.4822, 0.0, 0.6181, 0.4754, 0.7378] 
2025-11-22 02:14:36.751143: Epoch time: 101.83 s 
2025-11-22 02:14:36.751318: Yayy! New best EMA pseudo Dice: 0.1731 
2025-11-22 02:14:40.973226:  
2025-11-22 02:14:40.973544: Epoch 18 
2025-11-22 02:14:40.973720: Current learning rate: 0.00984 
2025-11-22 02:16:23.454820: train_loss -0.072 
2025-11-22 02:16:23.455089: val_loss -0.0505 
2025-11-22 02:16:23.455321: Pseudo dice [0.5544, 0.0106, 0.0, 0.5466, 0.4442, 0.022, 0.6077, 0.7094] 
2025-11-22 02:16:23.455486: Epoch time: 102.48 s 
2025-11-22 02:16:23.455605: Yayy! New best EMA pseudo Dice: 0.192 
2025-11-22 02:16:26.666441:  
2025-11-22 02:16:26.666809: Epoch 19 
2025-11-22 02:16:26.667005: Current learning rate: 0.00983 
2025-11-22 02:18:09.115207: train_loss -0.0727 
2025-11-22 02:18:09.115483: val_loss -0.0735 
2025-11-22 02:18:09.115711: Pseudo dice [0.1144, 0.5973, 0.5257, 0.0065, 0.65, 0.0606, 0.5786, 0.7523] 
2025-11-22 02:18:09.115914: Epoch time: 102.45 s 
2025-11-22 02:18:09.116043: Yayy! New best EMA pseudo Dice: 0.2138 
2025-11-22 02:18:12.279682:  
2025-11-22 02:18:12.280025: Epoch 20 
2025-11-22 02:18:12.280224: Current learning rate: 0.00982 
2025-11-22 02:19:54.236116: train_loss -0.0834 
2025-11-22 02:19:54.236346: val_loss -0.0692 
2025-11-22 02:19:54.236547: Pseudo dice [0.6524, 0.0, 0.5168, 0.0, 0.8301, 0.0205, 0.5679, 0.7075] 
2025-11-22 02:19:54.236684: Epoch time: 101.96 s 
2025-11-22 02:19:54.236872: Yayy! New best EMA pseudo Dice: 0.2336 
2025-11-22 02:19:57.685349:  
2025-11-22 02:19:57.685645: Epoch 21 
2025-11-22 02:19:57.685823: Current learning rate: 0.00981 
2025-11-22 02:21:39.218789: train_loss -0.0967 
2025-11-22 02:21:39.219019: val_loss -0.0901 
2025-11-22 02:21:39.219206: Pseudo dice [0.5005, 0.4961, 0.0, 0.5427, 0.0, 0.7296, 0.6024, 0.8077] 
2025-11-22 02:21:39.219400: Epoch time: 101.54 s 
2025-11-22 02:21:39.219553: Yayy! New best EMA pseudo Dice: 0.2563 
2025-11-22 02:21:42.147151:  
2025-11-22 02:21:42.147479: Epoch 22 
2025-11-22 02:21:42.147660: Current learning rate: 0.0098 
2025-11-22 02:23:23.465829: train_loss -0.1119 
2025-11-22 02:23:23.466062: val_loss -0.0451 
2025-11-22 02:23:23.466267: Pseudo dice [0.0, 0.5881, 0.0, 0.5406, 0.0003, 0.3672, 0.5804, 0.7211] 
2025-11-22 02:23:23.466392: Epoch time: 101.32 s 
2025-11-22 02:23:23.466509: Yayy! New best EMA pseudo Dice: 0.2656 
2025-11-22 02:23:26.556681:  
2025-11-22 02:23:26.557007: Epoch 23 
2025-11-22 02:23:26.557268: Current learning rate: 0.00979 
2025-11-22 02:25:08.543851: train_loss -0.0855 
2025-11-22 02:25:08.544196: val_loss -0.0525 
2025-11-22 02:25:08.544415: Pseudo dice [0.0448, 0.6171, 0.5305, 0.0072, 0.0055, 0.6857, 0.5578, 0.5783] 
2025-11-22 02:25:08.544614: Epoch time: 101.99 s 
2025-11-22 02:25:08.544725: Yayy! New best EMA pseudo Dice: 0.2769 
2025-11-22 02:25:11.457941:  
2025-11-22 02:25:11.458224: Epoch 24 
2025-11-22 02:25:11.458399: Current learning rate: 0.00978 
2025-11-22 02:26:52.898102: train_loss -0.1007 
2025-11-22 02:26:52.898343: val_loss -0.1011 
2025-11-22 02:26:52.898553: Pseudo dice [0.6633, 0.0002, 0.0001, 0.6376, 0.5689, 0.0001, 0.6313, 0.7442] 
2025-11-22 02:26:52.898677: Epoch time: 101.44 s 
2025-11-22 02:26:52.898822: Yayy! New best EMA pseudo Dice: 0.2898 
2025-11-22 02:26:55.775928:  
2025-11-22 02:26:55.776262: Epoch 25 
2025-11-22 02:26:55.776417: Current learning rate: 0.00977 
2025-11-22 02:28:37.180077: train_loss -0.1216 
2025-11-22 02:28:37.180451: val_loss -0.1014 
2025-11-22 02:28:37.180662: Pseudo dice [0.0294, 0.5061, 0.0, 0.4585, 0.6905, 0.0, 0.6807, 0.7665] 
2025-11-22 02:28:37.180928: Epoch time: 101.41 s 
2025-11-22 02:28:37.181045: Yayy! New best EMA pseudo Dice: 0.2999 
2025-11-22 02:28:40.035162:  
2025-11-22 02:28:40.035448: Epoch 26 
2025-11-22 02:28:40.035616: Current learning rate: 0.00977 
2025-11-22 02:30:21.641630: train_loss -0.1165 
2025-11-22 02:30:21.641872: val_loss -0.1045 
2025-11-22 02:30:21.642081: Pseudo dice [0.6421, 0.0, 0.0002, 0.595, 0.6648, 0.0, 0.7468, 0.7913] 
2025-11-22 02:30:21.642221: Epoch time: 101.61 s 
2025-11-22 02:30:21.642388: Yayy! New best EMA pseudo Dice: 0.3129 
2025-11-22 02:30:24.756263:  
2025-11-22 02:30:24.756576: Epoch 27 
2025-11-22 02:30:24.756757: Current learning rate: 0.00976 
2025-11-22 02:32:06.359273: train_loss -0.1214 
2025-11-22 02:32:06.359613: val_loss -0.1076 
2025-11-22 02:32:06.359829: Pseudo dice [0.6391, 0.0, 0.0134, 0.5314, 0.66, 0.0, 0.669, 0.7899] 
2025-11-22 02:32:06.359951: Epoch time: 101.6 s 
2025-11-22 02:32:06.360051: Yayy! New best EMA pseudo Dice: 0.3229 
2025-11-22 02:32:09.231894:  
2025-11-22 02:32:09.232238: Epoch 28 
2025-11-22 02:32:09.232408: Current learning rate: 0.00975 
2025-11-22 02:33:50.660215: train_loss -0.1187 
2025-11-22 02:33:50.660476: val_loss -0.0887 
2025-11-22 02:33:50.660668: Pseudo dice [0.0, 0.6622, 0.4357, 0.0, 0.3759, 0.0007, 0.6704, 0.7295] 
2025-11-22 02:33:50.660805: Epoch time: 101.43 s 
2025-11-22 02:33:50.660924: Yayy! New best EMA pseudo Dice: 0.3266 
2025-11-22 02:33:53.432691:  
2025-11-22 02:33:53.433023: Epoch 29 
2025-11-22 02:33:53.433230: Current learning rate: 0.00974 
2025-11-22 02:35:35.128172: train_loss -0.1247 
2025-11-22 02:35:35.128407: val_loss -0.0765 
2025-11-22 02:35:35.128641: Pseudo dice [0.582, 0.0, 0.5108, 0.0, 0.821, 0.0, 0.6217, 0.8032] 
2025-11-22 02:35:35.128844: Epoch time: 101.7 s 
2025-11-22 02:35:35.129011: Yayy! New best EMA pseudo Dice: 0.3356 
2025-11-22 02:35:38.067545:  
2025-11-22 02:35:38.067874: Epoch 30 
2025-11-22 02:35:38.068043: Current learning rate: 0.00973 
2025-11-22 02:37:19.666835: train_loss -0.1356 
2025-11-22 02:37:19.667180: val_loss -0.1217 
2025-11-22 02:37:19.667400: Pseudo dice [0.0, 0.7378, 0.4347, 0.0021, 0.0001, 0.7276, 0.7379, 0.7806] 
2025-11-22 02:37:19.667630: Epoch time: 101.6 s 
2025-11-22 02:37:19.667743: Yayy! New best EMA pseudo Dice: 0.3448 
2025-11-22 02:37:22.490312:  
2025-11-22 02:37:22.490502: Epoch 31 
2025-11-22 02:37:22.490664: Current learning rate: 0.00972 
2025-11-22 02:39:04.335571: train_loss -0.1222 
2025-11-22 02:39:04.335856: val_loss -0.1189 
2025-11-22 02:39:04.336121: Pseudo dice [0.6432, 0.0158, 0.0295, 0.4659, 0.5454, 0.0, 0.697, 0.8133] 
2025-11-22 02:39:04.336249: Epoch time: 101.85 s 
2025-11-22 02:39:04.336356: Yayy! New best EMA pseudo Dice: 0.3505 
2025-11-22 02:39:07.260384:  
2025-11-22 02:39:07.260800: Epoch 32 
2025-11-22 02:39:07.260979: Current learning rate: 0.00971 
2025-11-22 02:40:49.395752: train_loss -0.131 
2025-11-22 02:40:49.396075: val_loss -0.0997 
2025-11-22 02:40:49.396300: Pseudo dice [0.6826, 0.0, 0.5743, 0.0, 0.5932, 0.0068, 0.7005, 0.7796] 
2025-11-22 02:40:49.396513: Epoch time: 102.14 s 
2025-11-22 02:40:49.396638: Yayy! New best EMA pseudo Dice: 0.3571 
2025-11-22 02:40:52.335577:  
2025-11-22 02:40:52.335905: Epoch 33 
2025-11-22 02:40:52.336079: Current learning rate: 0.0097 
2025-11-22 02:42:33.940504: train_loss -0.1292 
2025-11-22 02:42:33.940730: val_loss -0.1184 
2025-11-22 02:42:33.941082: Pseudo dice [0.6684, 0.0298, 0.0, 0.588, 0.6325, 0.0, 0.6234, 0.7709] 
2025-11-22 02:42:33.941239: Epoch time: 101.61 s 
2025-11-22 02:42:33.941349: Yayy! New best EMA pseudo Dice: 0.3628 
2025-11-22 02:42:36.916903:  
2025-11-22 02:42:36.917234: Epoch 34 
2025-11-22 02:42:36.917432: Current learning rate: 0.00969 
2025-11-22 02:44:18.705946: train_loss -0.1403 
2025-11-22 02:44:18.706261: val_loss -0.1123 
2025-11-22 02:44:18.706488: Pseudo dice [0.6028, 0.0014, 0.0, 0.5472, 0.6597, 0.0, 0.6856, 0.7923] 
2025-11-22 02:44:18.706738: Epoch time: 101.79 s 
2025-11-22 02:44:18.706888: Yayy! New best EMA pseudo Dice: 0.3677 
2025-11-22 02:44:21.562844:  
2025-11-22 02:44:21.563204: Epoch 35 
2025-11-22 02:44:21.563373: Current learning rate: 0.00968 
2025-11-22 02:46:02.959908: train_loss -0.1293 
2025-11-22 02:46:02.960169: val_loss -0.1094 
2025-11-22 02:46:02.960379: Pseudo dice [0.0, 0.6634, 0.5325, 0.0014, 0.0012, 0.7662, 0.741, 0.8051] 
2025-11-22 02:46:02.960537: Epoch time: 101.4 s 
2025-11-22 02:46:02.960647: Yayy! New best EMA pseudo Dice: 0.3748 
2025-11-22 02:46:05.724344:  
2025-11-22 02:46:05.724729: Epoch 36 
2025-11-22 02:46:05.724937: Current learning rate: 0.00968 
2025-11-22 02:47:47.105177: train_loss -0.1347 
2025-11-22 02:47:47.105722: val_loss -0.104 
2025-11-22 02:47:47.106003: Pseudo dice [0.0, 0.6383, 0.5712, 0.0003, 0.7081, 0.0028, 0.6613, 0.8113] 
2025-11-22 02:47:47.106204: Epoch time: 101.38 s 
2025-11-22 02:47:47.106316: Yayy! New best EMA pseudo Dice: 0.3797 
2025-11-22 02:47:50.302474:  
2025-11-22 02:47:50.302816: Epoch 37 
2025-11-22 02:47:50.302981: Current learning rate: 0.00967 
2025-11-22 02:49:31.504583: train_loss -0.1432 
2025-11-22 02:49:31.504818: val_loss -0.1074 
2025-11-22 02:49:31.505073: Pseudo dice [0.6099, 0.0014, 0.0805, 0.5179, 0.562, 0.0, 0.7355, 0.8124] 
2025-11-22 02:49:31.505223: Epoch time: 101.2 s 
2025-11-22 02:49:31.505520: Yayy! New best EMA pseudo Dice: 0.3832 
2025-11-22 02:49:34.699775:  
2025-11-22 02:49:34.700109: Epoch 38 
2025-11-22 02:49:34.700247: Current learning rate: 0.00966 
2025-11-22 02:51:16.609794: train_loss -0.1386 
2025-11-22 02:51:16.610022: val_loss -0.0964 
2025-11-22 02:51:16.610198: Pseudo dice [0.5459, 0.0, 0.6021, 0.0013, 0.4222, 0.5386, 0.5702, 0.7383] 
2025-11-22 02:51:16.610323: Epoch time: 101.91 s 
2025-11-22 02:51:16.610460: Yayy! New best EMA pseudo Dice: 0.3877 
2025-11-22 02:51:20.413589:  
2025-11-22 02:51:20.413910: Epoch 39 
2025-11-22 02:51:20.414068: Current learning rate: 0.00965 
2025-11-22 02:53:02.063842: train_loss -0.132 
2025-11-22 02:53:02.064073: val_loss -0.1111 
2025-11-22 02:53:02.064341: Pseudo dice [0.0049, 0.5677, 0.0086, 0.7034, 0.6286, 0.1357, 0.7025, 0.7459] 
2025-11-22 02:53:02.064530: Epoch time: 101.65 s 
2025-11-22 02:53:02.064646: Yayy! New best EMA pseudo Dice: 0.3926 
2025-11-22 02:53:05.026297:  
2025-11-22 02:53:05.026657: Epoch 40 
2025-11-22 02:53:05.026851: Current learning rate: 0.00964 
2025-11-22 02:54:46.970112: train_loss -0.1394 
2025-11-22 02:54:46.970329: val_loss -0.125 
2025-11-22 02:54:46.970494: Pseudo dice [0.0, 0.484, 0.0042, 0.5267, 0.0, 0.4124, 0.7577, 0.8362] 
2025-11-22 02:54:46.970633: Epoch time: 101.95 s 
2025-11-22 02:54:49.197855:  
2025-11-22 02:54:49.198195: Epoch 41 
2025-11-22 02:54:49.198372: Current learning rate: 0.00963 
2025-11-22 02:56:30.889102: train_loss -0.1502 
2025-11-22 02:56:30.889434: val_loss -0.1199 
2025-11-22 02:56:30.889607: Pseudo dice [0.0, 0.5815, 0.4617, 0.0033, 0.5909, 0.0103, 0.7607, 0.8064] 
2025-11-22 02:56:30.889721: Epoch time: 101.69 s 
2025-11-22 02:56:32.676868:  
2025-11-22 02:56:32.677205: Epoch 42 
2025-11-22 02:56:32.677379: Current learning rate: 0.00962 
2025-11-22 02:58:14.187584: train_loss -0.1455 
2025-11-22 02:58:14.187877: val_loss -0.122 
2025-11-22 02:58:14.188199: Pseudo dice [0.672, 0.1768, 0.0, 0.423, 0.7292, 0.0253, 0.7618, 0.8316] 
2025-11-22 02:58:14.188373: Epoch time: 101.51 s 
2025-11-22 02:58:14.188500: Yayy! New best EMA pseudo Dice: 0.3982 
2025-11-22 02:58:17.227592:  
2025-11-22 02:58:17.227926: Epoch 43 
2025-11-22 02:58:17.228093: Current learning rate: 0.00961 
2025-11-22 02:59:59.018158: train_loss -0.1508 
2025-11-22 02:59:59.018434: val_loss -0.1309 
2025-11-22 02:59:59.018651: Pseudo dice [0.4018, 0.0161, 0.0118, 0.5451, 0.4253, 0.0918, 0.7234, 0.8013] 
2025-11-22 02:59:59.018809: Epoch time: 101.79 s 
2025-11-22 03:00:01.107533:  
2025-11-22 03:00:01.107870: Epoch 44 
2025-11-22 03:00:01.108050: Current learning rate: 0.0096 
2025-11-22 03:01:42.731998: train_loss -0.1408 
2025-11-22 03:01:42.732255: val_loss -0.1172 
2025-11-22 03:01:42.732502: Pseudo dice [0.62, 0.0009, 0.0057, 0.6259, 0.5453, 0.0, 0.7328, 0.8049] 
2025-11-22 03:01:42.732599: Epoch time: 101.63 s 
2025-11-22 03:01:44.494495:  
2025-11-22 03:01:44.494857: Epoch 45 
2025-11-22 03:01:44.495046: Current learning rate: 0.00959 
2025-11-22 03:03:26.255608: train_loss -0.1487 
2025-11-22 03:03:26.256044: val_loss -0.1193 
2025-11-22 03:03:26.256254: Pseudo dice [0.1472, 0.5263, 0.5309, 0.0582, 0.5678, 0.0, 0.667, 0.8087] 
2025-11-22 03:03:26.256394: Epoch time: 101.76 s 
2025-11-22 03:03:26.256509: Yayy! New best EMA pseudo Dice: 0.3997 
2025-11-22 03:03:29.433043:  
2025-11-22 03:03:29.433393: Epoch 46 
2025-11-22 03:03:29.433552: Current learning rate: 0.00959 
2025-11-22 03:05:11.589794: train_loss -0.1474 
2025-11-22 03:05:11.590063: val_loss -0.0938 
2025-11-22 03:05:11.590279: Pseudo dice [0.6133, 0.0, 0.5802, 0.0, 0.5378, 0.0006, 0.6794, 0.7843] 
2025-11-22 03:05:11.590426: Epoch time: 102.16 s 
2025-11-22 03:05:13.313658:  
2025-11-22 03:05:13.314000: Epoch 47 
2025-11-22 03:05:13.314151: Current learning rate: 0.00958 
2025-11-22 03:06:55.472189: train_loss -0.1531 
2025-11-22 03:06:55.472596: val_loss -0.1213 
2025-11-22 03:06:55.472916: Pseudo dice [0.0, 0.6614, 0.1782, 0.641, 0.3426, 0.0141, 0.707, 0.7929] 
2025-11-22 03:06:55.473089: Epoch time: 102.16 s 
2025-11-22 03:06:55.473214: Yayy! New best EMA pseudo Dice: 0.4014 
2025-11-22 03:06:58.259615:  
2025-11-22 03:06:58.259957: Epoch 48 
2025-11-22 03:06:58.260130: Current learning rate: 0.00957 
2025-11-22 03:08:40.228811: train_loss -0.1747 
2025-11-22 03:08:40.229048: val_loss -0.1235 
2025-11-22 03:08:40.229294: Pseudo dice [0.0, 0.6959, 0.0, 0.5337, 0.7363, 0.0003, 0.621, 0.7553] 
2025-11-22 03:08:40.229452: Epoch time: 101.97 s 
2025-11-22 03:08:40.229563: Yayy! New best EMA pseudo Dice: 0.4031 
2025-11-22 03:08:43.166019:  
2025-11-22 03:08:43.166329: Epoch 49 
2025-11-22 03:08:43.166513: Current learning rate: 0.00956 
2025-11-22 03:10:25.134620: train_loss -0.1733 
2025-11-22 03:10:25.135019: val_loss -0.1442 
2025-11-22 03:10:25.135252: Pseudo dice [0.5388, 0.5447, 0.363, 0.4608, 0.0, 0.569, 0.7703, 0.8586] 
2025-11-22 03:10:25.135359: Epoch time: 101.97 s 
2025-11-22 03:10:25.882056: Yayy! New best EMA pseudo Dice: 0.4141 
2025-11-22 03:10:28.844200:  
2025-11-22 03:10:28.844509: Epoch 50 
2025-11-22 03:10:28.844675: Current learning rate: 0.00955 
2025-11-22 03:12:10.874017: train_loss -0.1625 
2025-11-22 03:12:10.874255: val_loss -0.118 
2025-11-22 03:12:10.874443: Pseudo dice [0.6509, 0.0002, 0.4818, 0.0, 0.0, 0.7608, 0.7703, 0.806] 
2025-11-22 03:12:10.874561: Epoch time: 102.03 s 
2025-11-22 03:12:10.874913: Yayy! New best EMA pseudo Dice: 0.416 
2025-11-22 03:12:13.670361:  
2025-11-22 03:12:13.670627: Epoch 51 
2025-11-22 03:12:13.670807: Current learning rate: 0.00954 
2025-11-22 03:13:55.155891: train_loss -0.1597 
2025-11-22 03:13:55.156116: val_loss -0.114 
2025-11-22 03:13:55.156311: Pseudo dice [0.6739, 0.0009, 0.0, 0.5402, 0.7775, 0.021, 0.7248, 0.7704] 
2025-11-22 03:13:55.156411: Epoch time: 101.49 s 
2025-11-22 03:13:55.156484: Yayy! New best EMA pseudo Dice: 0.4183 
2025-11-22 03:13:58.087004:  
2025-11-22 03:13:58.087318: Epoch 52 
2025-11-22 03:13:58.087495: Current learning rate: 0.00953 
2025-11-22 03:15:39.175027: train_loss -0.1548 
2025-11-22 03:15:39.175292: val_loss -0.1158 
2025-11-22 03:15:39.175491: Pseudo dice [0.5169, 0.0, 0.5474, 0.0001, 0.4653, 0.1752, 0.7085, 0.7589] 
2025-11-22 03:15:39.175659: Epoch time: 101.09 s 
2025-11-22 03:15:40.899817:  
2025-11-22 03:15:40.900400: Epoch 53 
2025-11-22 03:15:40.900579: Current learning rate: 0.00952 
2025-11-22 03:17:22.111637: train_loss -0.1539 
2025-11-22 03:17:22.111920: val_loss -0.1165 
2025-11-22 03:17:22.112161: Pseudo dice [0.5243, 0.0022, 0.589, 0.0, 0.3191, 0.04, 0.6683, 0.8424] 
2025-11-22 03:17:22.112346: Epoch time: 101.21 s 
2025-11-22 03:17:23.840540:  
2025-11-22 03:17:23.840725: Epoch 54 
2025-11-22 03:17:23.840945: Current learning rate: 0.00951 
2025-11-22 03:19:05.520079: train_loss -0.1767 
2025-11-22 03:19:05.520335: val_loss -0.1262 
2025-11-22 03:19:05.520660: Pseudo dice [0.6146, 0.1562, 0.606, 0.0, 0.5773, 0.0581, 0.7742, 0.7612] 
2025-11-22 03:19:05.520859: Epoch time: 101.68 s 
2025-11-22 03:19:07.417735:  
2025-11-22 03:19:07.418021: Epoch 55 
2025-11-22 03:19:07.418189: Current learning rate: 0.0095 
2025-11-22 03:20:48.517698: train_loss -0.1636 
2025-11-22 03:20:48.517971: val_loss -0.1315 
2025-11-22 03:20:48.518190: Pseudo dice [0.1598, 0.5212, 0.0, 0.6038, 0.5856, 0.077, 0.7684, 0.8492] 
2025-11-22 03:20:48.518345: Epoch time: 101.1 s 
2025-11-22 03:20:50.413932:  
2025-11-22 03:20:50.414169: Epoch 56 
2025-11-22 03:20:50.414364: Current learning rate: 0.00949 
2025-11-22 03:22:31.758834: train_loss -0.1428 
2025-11-22 03:22:31.759060: val_loss -0.1069 
2025-11-22 03:22:31.759236: Pseudo dice [0.6527, 0.0031, 0.0128, 0.5211, 0.6325, 0.0774, 0.7362, 0.7708] 
2025-11-22 03:22:31.759376: Epoch time: 101.35 s 
2025-11-22 03:22:31.759604: Yayy! New best EMA pseudo Dice: 0.4188 
2025-11-22 03:22:34.925475:  
2025-11-22 03:22:34.925828: Epoch 57 
2025-11-22 03:22:34.926012: Current learning rate: 0.00949 
2025-11-22 03:24:16.715322: train_loss -0.1532 
2025-11-22 03:24:16.715580: val_loss -0.1454 
2025-11-22 03:24:16.715858: Pseudo dice [0.0, 0.5857, 0.0, 0.6525, 0.6278, 0.0128, 0.7919, 0.8258] 
2025-11-22 03:24:16.716066: Epoch time: 101.79 s 
2025-11-22 03:24:16.716151: Yayy! New best EMA pseudo Dice: 0.4206 
2025-11-22 03:24:19.526697:  
2025-11-22 03:24:19.527079: Epoch 58 
2025-11-22 03:24:19.527282: Current learning rate: 0.00948 
2025-11-22 03:26:01.178683: train_loss -0.1514 
2025-11-22 03:26:01.178956: val_loss -0.1446 
2025-11-22 03:26:01.179167: Pseudo dice [0.008, 0.5838, 0.0, 0.6507, 0.0, 0.5242, 0.8138, 0.8138] 
2025-11-22 03:26:01.179411: Epoch time: 101.65 s 
2025-11-22 03:26:01.179528: Yayy! New best EMA pseudo Dice: 0.421 
2025-11-22 03:26:03.939208:  
2025-11-22 03:26:03.939506: Epoch 59 
2025-11-22 03:26:03.939668: Current learning rate: 0.00947 
2025-11-22 03:27:45.808171: train_loss -0.1685 
2025-11-22 03:27:45.808464: val_loss -0.1204 
2025-11-22 03:27:45.808642: Pseudo dice [0.6505, 0.028, 0.0125, 0.4903, 0.5256, 0.0847, 0.7638, 0.7666] 
2025-11-22 03:27:45.808776: Epoch time: 101.87 s 
2025-11-22 03:27:48.606068:  
2025-11-22 03:27:48.606363: Epoch 60 
2025-11-22 03:27:48.606531: Current learning rate: 0.00946 
2025-11-22 03:29:30.504864: train_loss -0.172 
2025-11-22 03:29:30.505176: val_loss -0.156 
2025-11-22 03:29:30.505405: Pseudo dice [0.6585, 0.0006, 0.0242, 0.5774, 0.6055, 0.3852, 0.7598, 0.8693] 
2025-11-22 03:29:30.505562: Epoch time: 101.9 s 
2025-11-22 03:29:30.505701: Yayy! New best EMA pseudo Dice: 0.4269 
2025-11-22 03:29:33.248030:  
2025-11-22 03:29:33.248373: Epoch 61 
2025-11-22 03:29:33.248554: Current learning rate: 0.00945 
2025-11-22 03:31:15.287462: train_loss -0.1668 
2025-11-22 03:31:15.287704: val_loss -0.1233 
2025-11-22 03:31:15.288029: Pseudo dice [0.604, 0.0, 0.7048, 0.0002, 0.6393, 0.04, 0.7771, 0.7634] 
2025-11-22 03:31:15.288197: Epoch time: 102.04 s 
2025-11-22 03:31:15.288311: Yayy! New best EMA pseudo Dice: 0.4283 
2025-11-22 03:31:18.500338:  
2025-11-22 03:31:18.500701: Epoch 62 
2025-11-22 03:31:18.500874: Current learning rate: 0.00944 
2025-11-22 03:33:00.430729: train_loss -0.1701 
2025-11-22 03:33:00.431087: val_loss -0.1585 
2025-11-22 03:33:00.431371: Pseudo dice [0.6068, 0.033, 0.2547, 0.6549, 0.5534, 0.0, 0.8096, 0.8128] 
2025-11-22 03:33:00.431657: Epoch time: 101.93 s 
2025-11-22 03:33:00.431803: Yayy! New best EMA pseudo Dice: 0.432 
2025-11-22 03:33:03.216083:  
2025-11-22 03:33:03.216418: Epoch 63 
2025-11-22 03:33:03.216583: Current learning rate: 0.00943 
2025-11-22 03:34:44.901011: train_loss -0.1658 
2025-11-22 03:34:44.901249: val_loss -0.1264 
2025-11-22 03:34:44.901455: Pseudo dice [0.684, 0.0188, 0.0001, 0.6, 0.4562, 0.3362, 0.6977, 0.7908] 
2025-11-22 03:34:44.901576: Epoch time: 101.69 s 
2025-11-22 03:34:44.901715: Yayy! New best EMA pseudo Dice: 0.4336 
2025-11-22 03:34:47.754404:  
2025-11-22 03:34:47.754715: Epoch 64 
2025-11-22 03:34:47.754903: Current learning rate: 0.00942 
2025-11-22 03:36:29.374880: train_loss -0.1646 
2025-11-22 03:36:29.375156: val_loss -0.1654 
2025-11-22 03:36:29.375430: Pseudo dice [0.7315, 0.0658, 0.6227, 0.0, 0.5111, 0.1625, 0.8106, 0.8376] 
2025-11-22 03:36:29.375601: Epoch time: 101.62 s 
2025-11-22 03:36:29.375706: Yayy! New best EMA pseudo Dice: 0.4371 
2025-11-22 03:36:32.138947:  
2025-11-22 03:36:32.139274: Epoch 65 
2025-11-22 03:36:32.139447: Current learning rate: 0.00941 
2025-11-22 03:38:13.934614: train_loss -0.1806 
2025-11-22 03:38:13.935018: val_loss -0.1327 
2025-11-22 03:38:13.935242: Pseudo dice [0.5663, 0.1816, 0.5528, 0.0, 0.0, 0.5495, 0.7878, 0.7992] 
2025-11-22 03:38:13.935379: Epoch time: 101.8 s 
2025-11-22 03:38:15.834836:  
2025-11-22 03:38:15.835156: Epoch 66 
2025-11-22 03:38:15.835330: Current learning rate: 0.0094 
2025-11-22 03:39:57.690258: train_loss -0.1682 
2025-11-22 03:39:57.690504: val_loss -0.1649 
2025-11-22 03:39:57.690684: Pseudo dice [0.0, 0.7209, 0.0, 0.621, 0.4149, 0.4897, 0.752, 0.8253] 
2025-11-22 03:39:57.690844: Epoch time: 101.86 s 
2025-11-22 03:39:57.690958: Yayy! New best EMA pseudo Dice: 0.4405 
2025-11-22 03:40:00.463987:  
2025-11-22 03:40:00.464448: Epoch 67 
2025-11-22 03:40:00.464636: Current learning rate: 0.00939 
2025-11-22 03:41:42.746512: train_loss -0.1729 
2025-11-22 03:41:42.746739: val_loss -0.1417 
2025-11-22 03:41:42.746989: Pseudo dice [0.1041, 0.6232, 0.3825, 0.0, 0.6975, 0.2707, 0.7832, 0.8378] 
2025-11-22 03:41:42.747172: Epoch time: 102.28 s 
2025-11-22 03:41:42.747283: Yayy! New best EMA pseudo Dice: 0.4427 
2025-11-22 03:41:45.706981:  
2025-11-22 03:41:45.707262: Epoch 68 
2025-11-22 03:41:45.707426: Current learning rate: 0.00939 
2025-11-22 03:43:27.292207: train_loss -0.1579 
2025-11-22 03:43:27.292453: val_loss -0.1235 
2025-11-22 03:43:27.292662: Pseudo dice [0.68, 0.0024, 0.6161, 0.0692, 0.3892, 0.0572, 0.7008, 0.7454] 
2025-11-22 03:43:27.292826: Epoch time: 101.59 s 
2025-11-22 03:43:29.157640:  
2025-11-22 03:43:29.157999: Epoch 69 
2025-11-22 03:43:29.158127: Current learning rate: 0.00938 
2025-11-22 03:45:10.860217: train_loss -0.1848 
2025-11-22 03:45:10.860446: val_loss -0.1688 
2025-11-22 03:45:10.860637: Pseudo dice [0.0002, 0.6493, 0.0, 0.3829, 0.0, 0.634, 0.8177, 0.8594] 
2025-11-22 03:45:10.860797: Epoch time: 101.7 s 
2025-11-22 03:45:13.021099:  
2025-11-22 03:45:13.021423: Epoch 70 
2025-11-22 03:45:13.021590: Current learning rate: 0.00937 
2025-11-22 03:46:54.652740: train_loss -0.1792 
2025-11-22 03:46:54.653009: val_loss -0.1479 
2025-11-22 03:46:54.653224: Pseudo dice [0.0, 0.624, 0.0165, 0.6039, 0.0, 0.5153, 0.7551, 0.8337] 
2025-11-22 03:46:54.653368: Epoch time: 101.63 s 
2025-11-22 03:46:56.873560:  
2025-11-22 03:46:56.873918: Epoch 71 
2025-11-22 03:46:56.874113: Current learning rate: 0.00936 
2025-11-22 03:48:38.309500: train_loss -0.1832 
2025-11-22 03:48:38.309819: val_loss -0.1412 
2025-11-22 03:48:38.310097: Pseudo dice [0.5383, 0.0268, 0.0, 0.7407, 0.0, 0.6212, 0.8331, 0.8303] 
2025-11-22 03:48:38.310241: Epoch time: 101.44 s 
2025-11-22 03:48:40.495081:  
2025-11-22 03:48:40.495441: Epoch 72 
2025-11-22 03:48:40.495591: Current learning rate: 0.00935 
2025-11-22 03:50:22.301319: train_loss -0.1823 
2025-11-22 03:50:22.301592: val_loss -0.1466 
2025-11-22 03:50:22.301735: Pseudo dice [0.5182, 0.3377, 0.0005, 0.6714, 0.7196, 0.0976, 0.8095, 0.7801] 
2025-11-22 03:50:22.301912: Epoch time: 101.81 s 
2025-11-22 03:50:24.582010:  
2025-11-22 03:50:24.582286: Epoch 73 
2025-11-22 03:50:24.582450: Current learning rate: 0.00934 
2025-11-22 03:52:05.962584: train_loss -0.1865 
2025-11-22 03:52:05.962892: val_loss -0.1189 
2025-11-22 03:52:05.963225: Pseudo dice [0.0732, 0.6401, 0.0, 0.5923, 0.6248, 0.1596, 0.6108, 0.7711] 
2025-11-22 03:52:05.963382: Epoch time: 101.38 s 
2025-11-22 03:52:07.901048:  
2025-11-22 03:52:07.901413: Epoch 74 
2025-11-22 03:52:07.901592: Current learning rate: 0.00933 
2025-11-22 03:53:49.366031: train_loss -0.1725 
2025-11-22 03:53:49.366275: val_loss -0.1302 
2025-11-22 03:53:49.366494: Pseudo dice [0.6448, 0.0, 0.1674, 0.6822, 0.1053, 0.4852, 0.8037, 0.8304] 
2025-11-22 03:53:49.366647: Epoch time: 101.47 s 
2025-11-22 03:53:49.366778: Yayy! New best EMA pseudo Dice: 0.4436 
2025-11-22 03:53:52.123182:  
2025-11-22 03:53:52.123542: Epoch 75 
2025-11-22 03:53:52.123700: Current learning rate: 0.00932 
2025-11-22 03:55:33.743812: train_loss -0.1726 
2025-11-22 03:55:33.744027: val_loss -0.1608 
2025-11-22 03:55:33.744208: Pseudo dice [0.5956, 0.0, 0.539, 0.0, 0.0, 0.6358, 0.8164, 0.8584] 
2025-11-22 03:55:33.744415: Epoch time: 101.62 s 
2025-11-22 03:55:35.840055:  
2025-11-22 03:55:35.840353: Epoch 76 
2025-11-22 03:55:35.840541: Current learning rate: 0.00931 
2025-11-22 03:57:17.494951: train_loss -0.1718 
2025-11-22 03:57:17.495323: val_loss -0.1567 
2025-11-22 03:57:17.495588: Pseudo dice [0.6937, 0.2296, 0.7764, 0.0003, 0.7111, 0.0741, 0.8324, 0.7943] 
2025-11-22 03:57:17.495784: Epoch time: 101.66 s 
2025-11-22 03:57:17.495906: Yayy! New best EMA pseudo Dice: 0.4495 
2025-11-22 03:57:20.247306:  
2025-11-22 03:57:20.247621: Epoch 77 
2025-11-22 03:57:20.247801: Current learning rate: 0.0093 
2025-11-22 03:59:02.096007: train_loss -0.1769 
2025-11-22 03:59:02.096236: val_loss -0.1746 
2025-11-22 03:59:02.096460: Pseudo dice [0.7138, 0.2834, 0.5631, 0.0, 0.6595, 0.1814, 0.8352, 0.8095] 
2025-11-22 03:59:02.096609: Epoch time: 101.85 s 
2025-11-22 03:59:02.096719: Yayy! New best EMA pseudo Dice: 0.4551 
2025-11-22 03:59:04.846831:  
2025-11-22 03:59:04.847144: Epoch 78 
2025-11-22 03:59:04.847334: Current learning rate: 0.0093 
2025-11-22 04:00:46.879621: train_loss -0.189 
2025-11-22 04:00:46.879911: val_loss -0.1395 
2025-11-22 04:00:46.880078: Pseudo dice [0.6802, 0.1253, 0.5552, 0.0, 0.5911, 0.006, 0.761, 0.7878] 
2025-11-22 04:00:46.880224: Epoch time: 102.03 s 
2025-11-22 04:00:49.198591:  
2025-11-22 04:00:49.198931: Epoch 79 
2025-11-22 04:00:49.199090: Current learning rate: 0.00929 
2025-11-22 04:02:30.917064: train_loss -0.1781 
2025-11-22 04:02:30.917335: val_loss -0.128 
2025-11-22 04:02:30.917516: Pseudo dice [0.6059, 0.2182, 0.0371, 0.5963, 0.0, 0.715, 0.7533, 0.7688] 
2025-11-22 04:02:30.917639: Epoch time: 101.72 s 
2025-11-22 04:02:32.855344:  
2025-11-22 04:02:32.855700: Epoch 80 
2025-11-22 04:02:32.855919: Current learning rate: 0.00928 
2025-11-22 04:04:14.465652: train_loss -0.1761 
2025-11-22 04:04:14.465965: val_loss -0.1693 
2025-11-22 04:04:14.466170: Pseudo dice [0.6093, 0.0, 0.6336, 0.0001, 0.734, 0.0, 0.8247, 0.7804] 
2025-11-22 04:04:14.466308: Epoch time: 101.61 s 
2025-11-22 04:04:17.239975:  
2025-11-22 04:04:17.240214: Epoch 81 
2025-11-22 04:04:17.240374: Current learning rate: 0.00927 
2025-11-22 04:05:59.415080: train_loss -0.1748 
2025-11-22 04:05:59.415307: val_loss -0.1537 
2025-11-22 04:05:59.415478: Pseudo dice [0.5821, 0.0, 0.7148, 0.0, 0.0, 0.5153, 0.836, 0.8037] 
2025-11-22 04:05:59.415621: Epoch time: 102.18 s 
2025-11-22 04:06:01.261287:  
2025-11-22 04:06:01.261492: Epoch 82 
2025-11-22 04:06:01.261723: Current learning rate: 0.00926 
2025-11-22 04:07:43.174868: train_loss -0.1799 
2025-11-22 04:07:43.175230: val_loss -0.1381 
2025-11-22 04:07:43.175450: Pseudo dice [0.5384, 0.0, 0.5975, 0.0001, 0.4568, 0.1086, 0.8393, 0.8295] 
2025-11-22 04:07:43.175574: Epoch time: 101.91 s 
2025-11-22 04:07:44.874754:  
2025-11-22 04:07:44.875103: Epoch 83 
2025-11-22 04:07:44.875272: Current learning rate: 0.00925 
2025-11-22 04:09:26.380220: train_loss -0.1766 
2025-11-22 04:09:26.380621: val_loss -0.1237 
2025-11-22 04:09:26.380917: Pseudo dice [0.7041, 0.0, 0.6164, 0.0004, 0.6971, 0.0757, 0.6794, 0.7792] 
2025-11-22 04:09:26.381097: Epoch time: 101.51 s 
2025-11-22 04:09:28.149012:  
2025-11-22 04:09:28.149325: Epoch 84 
2025-11-22 04:09:28.149480: Current learning rate: 0.00924 
2025-11-22 04:11:09.763259: train_loss -0.1799 
2025-11-22 04:11:09.763586: val_loss -0.1427 
2025-11-22 04:11:09.763902: Pseudo dice [0.5832, 0.0016, 0.6166, 0.0, 0.0, 0.6675, 0.7777, 0.8101] 
2025-11-22 04:11:09.764059: Epoch time: 101.62 s 
2025-11-22 04:11:11.531598:  
2025-11-22 04:11:11.531926: Epoch 85 
2025-11-22 04:11:11.532111: Current learning rate: 0.00923 
2025-11-22 04:12:53.562836: train_loss -0.1693 
2025-11-22 04:12:53.563077: val_loss -0.1599 
2025-11-22 04:12:53.563350: Pseudo dice [0.0, 0.6655, 0.0, 0.5412, 0.0, 0.7479, 0.8119, 0.8174] 
2025-11-22 04:12:53.563566: Epoch time: 102.03 s 
2025-11-22 04:12:55.307245:  
2025-11-22 04:12:55.307636: Epoch 86 
2025-11-22 04:12:55.307844: Current learning rate: 0.00922 
2025-11-22 04:14:37.070071: train_loss -0.1545 
2025-11-22 04:14:37.070285: val_loss -0.1238 
2025-11-22 04:14:37.070490: Pseudo dice [0.2864, 0.6337, 0.3208, 0.5878, 0.0, 0.6363, 0.7099, 0.6997] 
2025-11-22 04:14:37.070635: Epoch time: 101.76 s 
2025-11-22 04:14:38.975436:  
2025-11-22 04:14:38.975788: Epoch 87 
2025-11-22 04:14:38.975975: Current learning rate: 0.00921 
2025-11-22 04:16:20.950171: train_loss -0.1805 
2025-11-22 04:16:20.950448: val_loss -0.1443 
2025-11-22 04:16:20.950647: Pseudo dice [0.0012, 0.6897, 0.0039, 0.6046, 0.0, 0.6478, 0.8326, 0.7844] 
2025-11-22 04:16:20.950783: Epoch time: 101.98 s 
2025-11-22 04:16:22.674799:  
2025-11-22 04:16:22.675108: Epoch 88 
2025-11-22 04:16:22.675280: Current learning rate: 0.0092 
2025-11-22 04:18:04.316522: train_loss -0.1637 
2025-11-22 04:18:04.316751: val_loss -0.1472 
2025-11-22 04:18:04.316967: Pseudo dice [0.7723, 0.0024, 0.526, 0.0001, 0.7102, 0.0055, 0.807, 0.7407] 
2025-11-22 04:18:04.317100: Epoch time: 101.64 s 
2025-11-22 04:18:05.973904:  
2025-11-22 04:18:05.974192: Epoch 89 
2025-11-22 04:18:05.974344: Current learning rate: 0.0092 
2025-11-22 04:19:47.825652: train_loss -0.173 
2025-11-22 04:19:47.825908: val_loss -0.1798 
2025-11-22 04:19:47.826118: Pseudo dice [0.6616, 0.1027, 0.6924, 0.0495, 0.0, 0.7021, 0.8249, 0.8256] 
2025-11-22 04:19:47.826245: Epoch time: 101.85 s 
2025-11-22 04:19:49.806961:  
2025-11-22 04:19:49.807171: Epoch 90 
2025-11-22 04:19:49.807371: Current learning rate: 0.00919 
2025-11-22 04:21:31.584844: train_loss -0.1711 
2025-11-22 04:21:31.585123: val_loss -0.1083 
2025-11-22 04:21:31.585338: Pseudo dice [0.6665, 0.006, 0.6434, 0.0, 0.7178, 0.0007, 0.6899, 0.7183] 
2025-11-22 04:21:31.585479: Epoch time: 101.78 s 
2025-11-22 04:21:33.647581:  
2025-11-22 04:21:33.647832: Epoch 91 
2025-11-22 04:21:33.647999: Current learning rate: 0.00918 
2025-11-22 04:23:15.638092: train_loss -0.1768 
2025-11-22 04:23:15.638336: val_loss -0.1706 
2025-11-22 04:23:15.638535: Pseudo dice [0.6033, 0.0052, 0.6465, 0.0106, 0.3626, 0.0001, 0.8462, 0.8566] 
2025-11-22 04:23:15.638681: Epoch time: 101.99 s 
2025-11-22 04:23:17.484002:  
2025-11-22 04:23:17.484153: Epoch 92 
2025-11-22 04:23:17.484308: Current learning rate: 0.00917 
2025-11-22 04:24:59.180522: train_loss -0.1926 
2025-11-22 04:24:59.180752: val_loss -0.1793 
2025-11-22 04:24:59.180951: Pseudo dice [0.1299, 0.6233, 0.1698, 0.658, 0.4469, 0.6676, 0.7871, 0.8455] 
2025-11-22 04:24:59.181233: Epoch time: 101.7 s 
2025-11-22 04:24:59.181408: Yayy! New best EMA pseudo Dice: 0.4565 
2025-11-22 04:25:02.098946:  
2025-11-22 04:25:02.099291: Epoch 93 
2025-11-22 04:25:02.099480: Current learning rate: 0.00916 
2025-11-22 04:26:43.180290: train_loss -0.178 
2025-11-22 04:26:43.180702: val_loss -0.1491 
2025-11-22 04:26:43.180901: Pseudo dice [0.6341, 0.0158, 0.0642, 0.5915, 0.0, 0.5103, 0.844, 0.7509] 
2025-11-22 04:26:43.181015: Epoch time: 101.08 s 
2025-11-22 04:26:44.946383:  
2025-11-22 04:26:44.946692: Epoch 94 
2025-11-22 04:26:44.946877: Current learning rate: 0.00915 
2025-11-22 04:28:26.470129: train_loss -0.1885 
2025-11-22 04:28:26.470389: val_loss -0.1678 
2025-11-22 04:28:26.470553: Pseudo dice [0.6368, 0.0136, 0.5566, 0.4341, 0.5688, 0.0, 0.8665, 0.8399] 
2025-11-22 04:28:26.470675: Epoch time: 101.53 s 
2025-11-22 04:28:26.470810: Yayy! New best EMA pseudo Dice: 0.4571 
2025-11-22 04:28:29.297289:  
2025-11-22 04:28:29.297632: Epoch 95 
2025-11-22 04:28:29.297824: Current learning rate: 0.00914 
2025-11-22 04:30:10.707256: train_loss -0.1814 
2025-11-22 04:30:10.707473: val_loss -0.1609 
2025-11-22 04:30:10.707659: Pseudo dice [0.1922, 0.6886, 0.0013, 0.6032, 0.0, 0.7464, 0.8477, 0.8147] 
2025-11-22 04:30:10.707929: Epoch time: 101.41 s 
2025-11-22 04:30:10.708100: Yayy! New best EMA pseudo Dice: 0.46 
2025-11-22 04:30:13.447804:  
2025-11-22 04:30:13.448124: Epoch 96 
2025-11-22 04:30:13.448297: Current learning rate: 0.00913 
2025-11-22 04:31:54.757158: train_loss -0.1952 
2025-11-22 04:31:54.757412: val_loss -0.1446 
2025-11-22 04:31:54.757629: Pseudo dice [0.6183, 0.0395, 0.6451, 0.1285, 0.0, 0.6215, 0.8065, 0.8334] 
2025-11-22 04:31:54.757797: Epoch time: 101.31 s 
2025-11-22 04:31:54.757925: Yayy! New best EMA pseudo Dice: 0.4602 
2025-11-22 04:31:57.735282:  
2025-11-22 04:31:57.735666: Epoch 97 
2025-11-22 04:31:57.735858: Current learning rate: 0.00912 
2025-11-22 04:33:38.739317: train_loss -0.1842 
2025-11-22 04:33:38.739575: val_loss -0.1067 
2025-11-22 04:33:38.739837: Pseudo dice [0.5057, 0.0005, 0.3921, 0.0, 0.2775, 0.0052, 0.7353, 0.7233] 
2025-11-22 04:33:38.740109: Epoch time: 101.01 s 
2025-11-22 04:33:40.817912:  
2025-11-22 04:33:40.818183: Epoch 98 
2025-11-22 04:33:40.818339: Current learning rate: 0.00911 
2025-11-22 04:35:22.075553: train_loss -0.1686 
2025-11-22 04:35:22.075854: val_loss -0.1539 
2025-11-22 04:35:22.076033: Pseudo dice [0.5298, 0.0035, 0.0, 0.7623, 0.0029, 0.59, 0.8093, 0.7618] 
2025-11-22 04:35:22.076136: Epoch time: 101.26 s 
2025-11-22 04:35:23.857894:  
2025-11-22 04:35:23.858310: Epoch 99 
2025-11-22 04:35:23.858489: Current learning rate: 0.0091 
2025-11-22 04:37:05.601453: train_loss -0.1921 
2025-11-22 04:37:05.601826: val_loss -0.13 
2025-11-22 04:37:05.602040: Pseudo dice [0.5618, 0.2467, 0.0, 0.5466, 0.0, 0.5226, 0.8032, 0.801] 
2025-11-22 04:37:05.602175: Epoch time: 101.75 s 
2025-11-22 04:37:08.143626:  
2025-11-22 04:37:08.143846: Epoch 100 
2025-11-22 04:37:08.143992: Current learning rate: 0.0091 
2025-11-22 04:38:49.600628: train_loss -0.1816 
2025-11-22 04:38:49.600873: val_loss -0.1589 
2025-11-22 04:38:49.601156: Pseudo dice [0.6347, 0.0575, 0.0, 0.4976, 0.5512, 0.0009, 0.8499, 0.8463] 
2025-11-22 04:38:49.601333: Epoch time: 101.46 s 
2025-11-22 04:38:51.357334:  
2025-11-22 04:38:51.357674: Epoch 101 
2025-11-22 04:38:51.357870: Current learning rate: 0.00909 
2025-11-22 04:40:33.237050: train_loss -0.1914 
2025-11-22 04:40:33.237277: val_loss -0.139 
2025-11-22 04:40:33.237580: Pseudo dice [0.0, 0.6337, 0.3446, 0.6163, 0.0, 0.5572, 0.7609, 0.7458] 
2025-11-22 04:40:33.237785: Epoch time: 101.88 s 
2025-11-22 04:40:35.930990:  
2025-11-22 04:40:35.931314: Epoch 102 
2025-11-22 04:40:35.931503: Current learning rate: 0.00908 
2025-11-22 04:42:18.119544: train_loss -0.186 
2025-11-22 04:42:18.119797: val_loss -0.1395 
2025-11-22 04:42:18.119984: Pseudo dice [0.0, 0.4176, 0.0125, 0.6105, 0.6323, 0.0, 0.7829, 0.7118] 
2025-11-22 04:42:18.120114: Epoch time: 102.19 s 
2025-11-22 04:42:20.362925:  
2025-11-22 04:42:20.363279: Epoch 103 
2025-11-22 04:42:20.363441: Current learning rate: 0.00907 
2025-11-22 04:44:01.994929: train_loss -0.1879 
2025-11-22 04:44:01.995144: val_loss -0.1467 
2025-11-22 04:44:01.995311: Pseudo dice [0.0, 0.6004, 0.0012, 0.632, 0.6732, 0.097, 0.808, 0.735] 
2025-11-22 04:44:01.995455: Epoch time: 101.63 s 
2025-11-22 04:44:03.691006:  
2025-11-22 04:44:03.691342: Epoch 104 
2025-11-22 04:44:03.691525: Current learning rate: 0.00906 
2025-11-22 04:45:45.466859: train_loss -0.2006 
2025-11-22 04:45:45.467055: val_loss -0.1391 
2025-11-22 04:45:45.467261: Pseudo dice [0.0, 0.6398, 0.2779, 0.3039, 0.0, 0.5967, 0.8017, 0.7611] 
2025-11-22 04:45:45.467467: Epoch time: 101.78 s 
2025-11-22 04:45:47.325041:  
2025-11-22 04:45:47.325276: Epoch 105 
2025-11-22 04:45:47.325435: Current learning rate: 0.00905 
2025-11-22 04:47:29.151673: train_loss -0.1923 
2025-11-22 04:47:29.152031: val_loss -0.1808 
2025-11-22 04:47:29.152291: Pseudo dice [0.0, 0.6294, 0.5569, 0.0004, 0.0, 0.3772, 0.8533, 0.8506] 
2025-11-22 04:47:29.152476: Epoch time: 101.83 s 
2025-11-22 04:47:30.997260:  
2025-11-22 04:47:30.997539: Epoch 106 
2025-11-22 04:47:30.997685: Current learning rate: 0.00904 
2025-11-22 04:49:12.599114: train_loss -0.2014 
2025-11-22 04:49:12.599289: val_loss -0.1518 
2025-11-22 04:49:12.599477: Pseudo dice [0.0, 0.7012, 0.0738, 0.6312, 0.0, 0.652, 0.8284, 0.7321] 
2025-11-22 04:49:12.599655: Epoch time: 101.6 s 
2025-11-22 04:49:14.366817:  
2025-11-22 04:49:14.367151: Epoch 107 
2025-11-22 04:49:14.367326: Current learning rate: 0.00903 
2025-11-22 04:50:56.447736: train_loss -0.178 
2025-11-22 04:50:56.448013: val_loss -0.1421 
2025-11-22 04:50:56.448265: Pseudo dice [0.0114, 0.7313, 0.5534, 0.0, 0.0044, 0.8134, 0.8258, 0.8244] 
2025-11-22 04:50:56.448424: Epoch time: 102.08 s 
2025-11-22 04:50:58.275464:  
2025-11-22 04:50:58.275752: Epoch 108 
2025-11-22 04:50:58.275927: Current learning rate: 0.00902 
2025-11-22 04:52:40.246379: train_loss -0.1778 
2025-11-22 04:52:40.246590: val_loss -0.1391 
2025-11-22 04:52:40.246894: Pseudo dice [0.0, 0.6981, 0.0018, 0.6493, 0.3682, 0.0003, 0.7579, 0.7816] 
2025-11-22 04:52:40.247062: Epoch time: 101.97 s 
2025-11-22 04:52:42.094021:  
2025-11-22 04:52:42.094250: Epoch 109 
2025-11-22 04:52:42.094424: Current learning rate: 0.00901 
2025-11-22 04:54:24.232102: train_loss -0.1782 
2025-11-22 04:54:24.232346: val_loss -0.1427 
2025-11-22 04:54:24.232537: Pseudo dice [0.0, 0.6248, 0.0, 0.7028, 0.0, 0.725, 0.88, 0.7886] 
2025-11-22 04:54:24.232797: Epoch time: 102.14 s 
2025-11-22 04:54:26.081059:  
2025-11-22 04:54:26.081419: Epoch 110 
2025-11-22 04:54:26.081602: Current learning rate: 0.009 
2025-11-22 04:56:08.370540: train_loss -0.1892 
2025-11-22 04:56:08.370864: val_loss -0.1459 
2025-11-22 04:56:08.371120: Pseudo dice [0.0001, 0.5661, 0.359, 0.5681, 0.0, 0.8699, 0.8239, 0.8303] 
2025-11-22 04:56:08.371250: Epoch time: 102.29 s 
2025-11-22 04:56:10.152381:  
2025-11-22 04:56:10.152564: Epoch 111 
2025-11-22 04:56:10.152739: Current learning rate: 0.009 
2025-11-22 04:57:52.115686: train_loss -0.1853 
2025-11-22 04:57:52.116035: val_loss -0.1956 
2025-11-22 04:57:52.116307: Pseudo dice [0.7496, 0.0039, 0.773, 0.0, 0.6131, 0.1704, 0.8281, 0.831] 
2025-11-22 04:57:52.116486: Epoch time: 101.96 s 
2025-11-22 04:57:54.040482:  
2025-11-22 04:57:54.040854: Epoch 112 
2025-11-22 04:57:54.041020: Current learning rate: 0.00899 
2025-11-22 04:59:36.029814: train_loss -0.1758 
2025-11-22 04:59:36.030116: val_loss -0.1631 
2025-11-22 04:59:36.030320: Pseudo dice [0.0, 0.7583, 0.6245, 0.0, 0.0, 0.7592, 0.8662, 0.8363] 
2025-11-22 04:59:36.030494: Epoch time: 101.99 s 
2025-11-22 04:59:37.892588:  
2025-11-22 04:59:37.892930: Epoch 113 
2025-11-22 04:59:37.893093: Current learning rate: 0.00898 
2025-11-22 05:01:19.906560: train_loss -0.1902 
2025-11-22 05:01:19.906846: val_loss -0.1444 
2025-11-22 05:01:19.907077: Pseudo dice [0.6369, 0.0907, 0.6661, 0.0, 0.3674, 0.0197, 0.8429, 0.7972] 
2025-11-22 05:01:19.907399: Epoch time: 102.02 s 
2025-11-22 05:01:22.057684:  
2025-11-22 05:01:22.058030: Epoch 114 
2025-11-22 05:01:22.058219: Current learning rate: 0.00897 
2025-11-22 05:03:04.235883: train_loss -0.1902 
2025-11-22 05:03:04.236068: val_loss -0.193 
2025-11-22 05:03:04.236218: Pseudo dice [0.6669, 0.0028, 0.5237, 0.0, 0.0, 0.646, 0.8759, 0.8495] 
2025-11-22 05:03:04.236373: Epoch time: 102.18 s 
2025-11-22 05:03:06.053785:  
2025-11-22 05:03:06.054123: Epoch 115 
2025-11-22 05:03:06.054285: Current learning rate: 0.00896 
2025-11-22 05:04:48.117399: train_loss -0.205 
2025-11-22 05:04:48.117582: val_loss -0.139 
2025-11-22 05:04:48.117704: Pseudo dice [0.6354, 0.0006, 0.6792, 0.0, 0.4482, 0.009, 0.8238, 0.8102] 
2025-11-22 05:04:48.117862: Epoch time: 102.06 s 
2025-11-22 05:04:50.140256:  
2025-11-22 05:04:50.140598: Epoch 116 
2025-11-22 05:04:50.140800: Current learning rate: 0.00895 
2025-11-22 05:06:32.212756: train_loss -0.1971 
2025-11-22 05:06:32.213153: val_loss -0.1757 
2025-11-22 05:06:32.213382: Pseudo dice [0.6662, 0.0617, 0.6983, 0.0, 0.0, 0.6718, 0.8257, 0.7999] 
2025-11-22 05:06:32.213541: Epoch time: 102.07 s 
2025-11-22 05:06:34.403878:  
2025-11-22 05:06:34.404172: Epoch 117 
2025-11-22 05:06:34.404357: Current learning rate: 0.00894 
2025-11-22 05:08:15.903549: train_loss -0.2013 
2025-11-22 05:08:15.903887: val_loss -0.1586 
2025-11-22 05:08:15.904136: Pseudo dice [0.0, 0.6192, 0.7039, 0.0129, 0.7712, 0.0, 0.8043, 0.7783] 
2025-11-22 05:08:15.904295: Epoch time: 101.5 s 
2025-11-22 05:08:17.785016:  
2025-11-22 05:08:17.785319: Epoch 118 
2025-11-22 05:08:17.785497: Current learning rate: 0.00893 
2025-11-22 05:09:59.483016: train_loss -0.1818 
2025-11-22 05:09:59.483330: val_loss -0.1146 
2025-11-22 05:09:59.483672: Pseudo dice [0.4772, 0.3955, 0.5063, 0.0, 0.0099, 0.7305, 0.7559, 0.6207] 
2025-11-22 05:09:59.483871: Epoch time: 101.7 s 
2025-11-22 05:10:01.399354:  
2025-11-22 05:10:01.399695: Epoch 119 
2025-11-22 05:10:01.399884: Current learning rate: 0.00892 
2025-11-22 05:11:43.577492: train_loss -0.1839 
2025-11-22 05:11:43.577718: val_loss -0.132 
2025-11-22 05:11:43.577973: Pseudo dice [0.0545, 0.6519, 0.5032, 0.0, 0.4078, 0.016, 0.8192, 0.804] 
2025-11-22 05:11:43.578113: Epoch time: 102.18 s 
2025-11-22 05:11:45.513630:  
2025-11-22 05:11:45.513978: Epoch 120 
2025-11-22 05:11:45.514115: Current learning rate: 0.00891 
2025-11-22 05:13:27.358199: train_loss -0.1827 
2025-11-22 05:13:27.358441: val_loss -0.1648 
2025-11-22 05:13:27.358631: Pseudo dice [0.6265, 0.0002, 0.594, 0.0029, 0.1002, 0.4365, 0.8756, 0.8338] 
2025-11-22 05:13:27.358791: Epoch time: 101.85 s 
2025-11-22 05:13:29.148527:  
2025-11-22 05:13:29.148689: Epoch 121 
2025-11-22 05:13:29.148851: Current learning rate: 0.0089 
2025-11-22 05:15:10.800161: train_loss -0.2023 
2025-11-22 05:15:10.800391: val_loss -0.1744 
2025-11-22 05:15:10.800595: Pseudo dice [0.0252, 0.7386, 0.5947, 0.0, 0.4756, 0.0832, 0.8497, 0.7584] 
2025-11-22 05:15:10.800730: Epoch time: 101.65 s 
2025-11-22 05:15:12.620269:  
2025-11-22 05:15:12.620577: Epoch 122 
2025-11-22 05:15:12.620711: Current learning rate: 0.00889 
2025-11-22 05:16:53.510142: train_loss -0.1917 
2025-11-22 05:16:53.510428: val_loss -0.1412 
2025-11-22 05:16:53.510653: Pseudo dice [0.0, 0.6406, 0.7335, 0.0, 0.2884, 0.0, 0.821, 0.7844] 
2025-11-22 05:16:53.510869: Epoch time: 100.89 s 
2025-11-22 05:16:55.329014:  
2025-11-22 05:16:55.329247: Epoch 123 
2025-11-22 05:16:55.329451: Current learning rate: 0.00889 
2025-11-22 05:18:36.025550: train_loss -0.1886 
2025-11-22 05:18:36.025792: val_loss -0.1486 
2025-11-22 05:18:36.025985: Pseudo dice [0.0095, 0.7673, 0.1478, 0.693, 0.0, 0.769, 0.7566, 0.8351] 
2025-11-22 05:18:36.026128: Epoch time: 100.7 s 
2025-11-22 05:18:39.414147:  
2025-11-22 05:18:39.414448: Epoch 124 
2025-11-22 05:18:39.414615: Current learning rate: 0.00888 
2025-11-22 05:20:20.936160: train_loss -0.189 
2025-11-22 05:20:20.936471: val_loss -0.1675 
2025-11-22 05:20:20.936686: Pseudo dice [0.093, 0.6407, 0.6549, 0.0, 0.5772, 0.0001, 0.858, 0.8448] 
2025-11-22 05:20:20.936818: Epoch time: 101.52 s 
2025-11-22 05:20:22.789719:  
2025-11-22 05:20:22.790115: Epoch 125 
2025-11-22 05:20:22.790306: Current learning rate: 0.00887 
2025-11-22 05:22:03.928330: train_loss -0.1901 
2025-11-22 05:22:03.928559: val_loss -0.1522 
2025-11-22 05:22:03.928757: Pseudo dice [0.0142, 0.6392, 0.6651, 0.0026, 0.0, 0.7684, 0.7489, 0.8327] 
2025-11-22 05:22:03.928919: Epoch time: 101.14 s 
2025-11-22 05:22:05.898602:  
2025-11-22 05:22:05.899021: Epoch 126 
2025-11-22 05:22:05.899198: Current learning rate: 0.00886 
2025-11-22 05:23:46.784924: train_loss -0.1739 
2025-11-22 05:23:46.785185: val_loss -0.1596 
2025-11-22 05:23:46.785422: Pseudo dice [0.2273, 0.5459, 0.005, 0.5578, 0.5776, 0.0442, 0.8501, 0.7798] 
2025-11-22 05:23:46.785587: Epoch time: 100.89 s 
2025-11-22 05:23:48.870855:  
2025-11-22 05:23:48.871243: Epoch 127 
2025-11-22 05:23:48.871438: Current learning rate: 0.00885 
2025-11-22 05:25:30.498494: train_loss -0.1916 
2025-11-22 05:25:30.498713: val_loss -0.1748 
2025-11-22 05:25:30.498957: Pseudo dice [0.0019, 0.6606, 0.0857, 0.4272, 0.0, 0.7972, 0.8786, 0.861] 
2025-11-22 05:25:30.499154: Epoch time: 101.63 s 
2025-11-22 05:25:32.976553:  
2025-11-22 05:25:32.976888: Epoch 128 
2025-11-22 05:25:32.977059: Current learning rate: 0.00884 
2025-11-22 05:27:15.030772: train_loss -0.1902 
2025-11-22 05:27:15.031177: val_loss -0.1686 
2025-11-22 05:27:15.031450: Pseudo dice [0.0, 0.6371, 0.0111, 0.5278, 0.0, 0.6185, 0.8358, 0.8324] 
2025-11-22 05:27:15.031741: Epoch time: 102.06 s 
2025-11-22 05:27:17.169168:  
2025-11-22 05:27:17.169375: Epoch 129 
2025-11-22 05:27:17.169586: Current learning rate: 0.00883 
2025-11-22 05:28:59.378392: train_loss -0.1917 
2025-11-22 05:28:59.378817: val_loss -0.1559 
2025-11-22 05:28:59.379176: Pseudo dice [0.0001, 0.5246, 0.6188, 0.214, 0.6627, 0.0223, 0.826, 0.7967] 
2025-11-22 05:28:59.379327: Epoch time: 102.21 s 
2025-11-22 05:29:01.590979:  
2025-11-22 05:29:01.591383: Epoch 130 
2025-11-22 05:29:01.591577: Current learning rate: 0.00882 
2025-11-22 05:30:44.037896: train_loss -0.1888 
2025-11-22 05:30:44.038135: val_loss -0.1522 
2025-11-22 05:30:44.038298: Pseudo dice [0.0, 0.6713, 0.6663, 0.0, 0.0, 0.844, 0.7498, 0.7863] 
2025-11-22 05:30:44.038477: Epoch time: 102.45 s 
2025-11-22 05:30:45.966055:  
2025-11-22 05:30:45.966374: Epoch 131 
2025-11-22 05:30:45.966542: Current learning rate: 0.00881 
2025-11-22 05:32:28.202026: train_loss -0.1912 
2025-11-22 05:32:28.202312: val_loss -0.1621 
2025-11-22 05:32:28.202543: Pseudo dice [0.4559, 0.0227, 0.5453, 0.0, 0.4915, 0.0079, 0.8429, 0.8037] 
2025-11-22 05:32:28.202873: Epoch time: 102.24 s 
2025-11-22 05:32:30.546985:  
2025-11-22 05:32:30.547293: Epoch 132 
2025-11-22 05:32:30.547478: Current learning rate: 0.0088 
2025-11-22 05:34:12.382103: train_loss -0.1969 
2025-11-22 05:34:12.382374: val_loss -0.1615 
2025-11-22 05:34:12.382567: Pseudo dice [0.1709, 0.6634, 0.0101, 0.6737, 0.6542, 0.0018, 0.8485, 0.8161] 
2025-11-22 05:34:12.382691: Epoch time: 101.84 s 
2025-11-22 05:34:14.707360:  
2025-11-22 05:34:14.707671: Epoch 133 
2025-11-22 05:34:14.707869: Current learning rate: 0.00879 
2025-11-22 05:35:56.931643: train_loss -0.1905 
2025-11-22 05:35:56.931972: val_loss -0.165 
2025-11-22 05:35:56.932177: Pseudo dice [0.5728, 0.0017, 0.0986, 0.6913, 0.802, 0.0, 0.8327, 0.7717] 
2025-11-22 05:35:56.932322: Epoch time: 102.23 s 
2025-11-22 05:35:59.329456:  
2025-11-22 05:35:59.329834: Epoch 134 
2025-11-22 05:35:59.330024: Current learning rate: 0.00879 
2025-11-22 05:37:41.586710: train_loss -0.1922 
2025-11-22 05:37:41.586984: val_loss -0.1411 
2025-11-22 05:37:41.587353: Pseudo dice [0.5932, 0.0179, 0.0085, 0.6471, 0.5709, 0.2558, 0.7926, 0.7871] 
2025-11-22 05:37:41.587537: Epoch time: 102.26 s 
2025-11-22 05:37:43.726757:  
2025-11-22 05:37:43.727130: Epoch 135 
2025-11-22 05:37:43.727305: Current learning rate: 0.00878 
2025-11-22 05:39:26.236244: train_loss -0.1755 
2025-11-22 05:39:26.236547: val_loss -0.13 
2025-11-22 05:39:26.236802: Pseudo dice [0.4605, 0.4962, 0.0003, 0.5035, 0.306, 0.0406, 0.8129, 0.7971] 
2025-11-22 05:39:26.236958: Epoch time: 102.51 s 
2025-11-22 05:39:28.514064:  
2025-11-22 05:39:28.514396: Epoch 136 
2025-11-22 05:39:28.514560: Current learning rate: 0.00877 
2025-11-22 05:41:10.329490: train_loss -0.197 
2025-11-22 05:41:10.329712: val_loss -0.1592 
2025-11-22 05:41:10.330011: Pseudo dice [0.0045, 0.5461, 0.0, 0.6347, 0.0002, 0.5881, 0.7882, 0.8493] 
2025-11-22 05:41:10.330160: Epoch time: 101.82 s 
2025-11-22 05:41:12.310736:  
2025-11-22 05:41:12.311069: Epoch 137 
2025-11-22 05:41:12.311233: Current learning rate: 0.00876 
2025-11-22 05:42:54.085975: train_loss -0.1913 
2025-11-22 05:42:54.086218: val_loss -0.1401 
2025-11-22 05:42:54.086445: Pseudo dice [0.5113, 0.003, 0.4946, 0.0, 0.7422, 0.0125, 0.813, 0.7629] 
2025-11-22 05:42:54.086638: Epoch time: 101.78 s 
2025-11-22 05:42:56.131298:  
2025-11-22 05:42:56.131618: Epoch 138 
2025-11-22 05:42:56.131806: Current learning rate: 0.00875 
2025-11-22 05:44:38.565404: train_loss -0.201 
2025-11-22 05:44:38.565709: val_loss -0.1367 
2025-11-22 05:44:38.565969: Pseudo dice [0.5279, 0.0694, 0.1962, 0.5274, 0.676, 0.0365, 0.7933, 0.7859] 
2025-11-22 05:44:38.566120: Epoch time: 102.44 s 
2025-11-22 05:44:40.991190:  
2025-11-22 05:44:40.991502: Epoch 139 
2025-11-22 05:44:40.991678: Current learning rate: 0.00874 
2025-11-22 05:46:23.140216: train_loss -0.1859 
2025-11-22 05:46:23.140532: val_loss -0.1698 
2025-11-22 05:46:23.140678: Pseudo dice [0.6065, 0.0331, 0.5052, 0.0, 0.0, 0.654, 0.8406, 0.8379] 
2025-11-22 05:46:23.140805: Epoch time: 102.15 s 
2025-11-22 05:46:25.122317:  
2025-11-22 05:46:25.122546: Epoch 140 
2025-11-22 05:46:25.122730: Current learning rate: 0.00873 
2025-11-22 05:48:07.454642: train_loss -0.1941 
2025-11-22 05:48:07.454921: val_loss -0.1448 
2025-11-22 05:48:07.455247: Pseudo dice [0.5901, 0.0002, 0.5979, 0.0, 0.0, 0.713, 0.8527, 0.7927] 
2025-11-22 05:48:07.455542: Epoch time: 102.33 s 
2025-11-22 05:48:09.706916:  
2025-11-22 05:48:09.707310: Epoch 141 
2025-11-22 05:48:09.707504: Current learning rate: 0.00872 
2025-11-22 05:49:52.042851: train_loss -0.2082 
2025-11-22 05:49:52.043151: val_loss -0.1615 
2025-11-22 05:49:52.043574: Pseudo dice [0.5697, 0.0854, 0.5064, 0.0039, 0.5605, 0.0, 0.7794, 0.8197] 
2025-11-22 05:49:52.043731: Epoch time: 102.34 s 
2025-11-22 05:49:53.998982:  
2025-11-22 05:49:53.999281: Epoch 142 
2025-11-22 05:49:53.999538: Current learning rate: 0.00871 
2025-11-22 05:51:36.272316: train_loss -0.1883 
2025-11-22 05:51:36.272585: val_loss -0.1796 
2025-11-22 05:51:36.272905: Pseudo dice [0.0, 0.6229, 0.0001, 0.5108, 0.0, 0.6132, 0.873, 0.8619] 
2025-11-22 05:51:36.273085: Epoch time: 102.27 s 
2025-11-22 05:51:38.315444:  
2025-11-22 05:51:38.315801: Epoch 143 
2025-11-22 05:51:38.316010: Current learning rate: 0.0087 
2025-11-22 05:53:20.786534: train_loss -0.196 
2025-11-22 05:53:20.786834: val_loss -0.1324 
2025-11-22 05:53:20.787075: Pseudo dice [0.0145, 0.6196, 0.7463, 0.0, 0.0, 0.7673, 0.8503, 0.7369] 
2025-11-22 05:53:20.787225: Epoch time: 102.47 s 
2025-11-22 05:53:23.041660:  
2025-11-22 05:53:23.042021: Epoch 144 
2025-11-22 05:53:23.042201: Current learning rate: 0.00869 
2025-11-22 05:55:05.065209: train_loss -0.1848 
2025-11-22 05:55:05.065441: val_loss -0.1622 
2025-11-22 05:55:05.065703: Pseudo dice [0.0, 0.6988, 0.6706, 0.0002, 0.3903, 0.0, 0.8597, 0.823] 
2025-11-22 05:55:05.065854: Epoch time: 102.03 s 
2025-11-22 05:55:08.189761:  
2025-11-22 05:55:08.190162: Epoch 145 
2025-11-22 05:55:08.190322: Current learning rate: 0.00868 
2025-11-22 05:56:49.784915: train_loss -0.1956 
2025-11-22 05:56:49.785436: val_loss -0.145 
2025-11-22 05:56:49.785675: Pseudo dice [0.6498, 0.0, 0.069, 0.6656, 0.0, 0.7279, 0.8435, 0.7168] 
2025-11-22 05:56:49.785932: Epoch time: 101.6 s 
2025-11-22 05:56:51.730490:  
2025-11-22 05:56:51.730783: Epoch 146 
2025-11-22 05:56:51.730991: Current learning rate: 0.00868 
2025-11-22 05:58:33.459294: train_loss -0.2055 
2025-11-22 05:58:33.459663: val_loss -0.1802 
2025-11-22 05:58:33.459910: Pseudo dice [0.0001, 0.5998, 0.0176, 0.6293, 0.703, 0.0, 0.8654, 0.7773] 
2025-11-22 05:58:33.460052: Epoch time: 101.73 s 
2025-11-22 05:58:35.319733:  
2025-11-22 05:58:35.320119: Epoch 147 
2025-11-22 05:58:35.320302: Current learning rate: 0.00867 
2025-11-22 06:00:17.154095: train_loss -0.1894 
2025-11-22 06:00:17.154416: val_loss -0.1348 
2025-11-22 06:00:17.154615: Pseudo dice [0.5165, 0.0034, 0.6302, 0.0073, 0.0, 0.5769, 0.771, 0.7537] 
2025-11-22 06:00:17.154782: Epoch time: 101.84 s 
2025-11-22 06:00:18.985236:  
2025-11-22 06:00:18.985580: Epoch 148 
2025-11-22 06:00:18.985749: Current learning rate: 0.00866 
2025-11-22 06:02:00.266561: train_loss -0.1871 
2025-11-22 06:02:00.266741: val_loss -0.1605 
2025-11-22 06:02:00.266942: Pseudo dice [0.6385, 0.001, 0.0093, 0.4978, 0.6861, 0.0, 0.8504, 0.6894] 
2025-11-22 06:02:00.267093: Epoch time: 101.28 s 
2025-11-22 06:02:02.050868:  
2025-11-22 06:02:02.051062: Epoch 149 
2025-11-22 06:02:02.051214: Current learning rate: 0.00865 
2025-11-22 06:03:43.448243: train_loss -0.2095 
2025-11-22 06:03:43.448466: val_loss -0.1508 
2025-11-22 06:03:43.448648: Pseudo dice [0.0, 0.6591, 0.0, 0.7919, 0.0, 0.5907, 0.7878, 0.779] 
2025-11-22 06:03:43.448799: Epoch time: 101.4 s 
2025-11-22 06:03:46.271236:  
2025-11-22 06:03:46.271500: Epoch 150 
2025-11-22 06:03:46.271727: Current learning rate: 0.00864 
2025-11-22 06:05:27.728761: train_loss -0.1982 
2025-11-22 06:05:27.729008: val_loss -0.1799 
2025-11-22 06:05:27.729185: Pseudo dice [0.0, 0.6612, 0.0022, 0.6935, 0.5672, 0.0225, 0.8864, 0.8341] 
2025-11-22 06:05:27.729339: Epoch time: 101.46 s 
2025-11-22 06:05:29.718275:  
2025-11-22 06:05:29.718519: Epoch 151 
2025-11-22 06:05:29.718707: Current learning rate: 0.00863 
2025-11-22 06:07:11.178058: train_loss -0.2056 
2025-11-22 06:07:11.178434: val_loss -0.1731 
2025-11-22 06:07:11.178809: Pseudo dice [0.4917, 0.009, 0.6016, 0.0, 0.0, 0.7792, 0.8485, 0.7953] 
2025-11-22 06:07:11.178978: Epoch time: 101.46 s 
2025-11-22 06:07:12.986437:  
2025-11-22 06:07:12.986776: Epoch 152 
2025-11-22 06:07:12.986951: Current learning rate: 0.00862 
2025-11-22 06:08:54.848220: train_loss -0.2057 
2025-11-22 06:08:54.848532: val_loss -0.1767 
2025-11-22 06:08:54.848679: Pseudo dice [0.0, 0.7294, 0.0193, 0.7473, 0.7712, 0.0002, 0.8741, 0.8598] 
2025-11-22 06:08:54.848841: Epoch time: 101.86 s 
2025-11-22 06:08:56.777411:  
2025-11-22 06:08:56.777738: Epoch 153 
2025-11-22 06:08:56.777923: Current learning rate: 0.00861 
2025-11-22 06:10:38.530664: train_loss -0.1887 
2025-11-22 06:10:38.530970: val_loss -0.1605 
2025-11-22 06:10:38.531265: Pseudo dice [0.7062, 0.0799, 0.6052, 0.0, 0.0, 0.6751, 0.8579, 0.8156] 
2025-11-22 06:10:38.531430: Epoch time: 101.76 s 
2025-11-22 06:10:40.457732:  
2025-11-22 06:10:40.458101: Epoch 154 
2025-11-22 06:10:40.458282: Current learning rate: 0.0086 
2025-11-22 06:12:22.393686: train_loss -0.2048 
2025-11-22 06:12:22.394055: val_loss -0.1877 
2025-11-22 06:12:22.394248: Pseudo dice [0.0, 0.6562, 0.0, 0.7044, 0.5504, 0.1187, 0.862, 0.8408] 
2025-11-22 06:12:22.394363: Epoch time: 101.94 s 
2025-11-22 06:12:24.364414:  
2025-11-22 06:12:24.364756: Epoch 155 
2025-11-22 06:12:24.364947: Current learning rate: 0.00859 
2025-11-22 06:14:05.736668: train_loss -0.2048 
2025-11-22 06:14:05.736881: val_loss -0.1892 
2025-11-22 06:14:05.737027: Pseudo dice [0.0002, 0.6458, 0.5842, 0.0, 0.0, 0.6985, 0.8465, 0.7843] 
2025-11-22 06:14:05.737116: Epoch time: 101.37 s 
2025-11-22 06:14:07.657041:  
2025-11-22 06:14:07.657371: Epoch 156 
2025-11-22 06:14:07.657538: Current learning rate: 0.00858 
2025-11-22 06:15:49.578242: train_loss -0.2056 
2025-11-22 06:15:49.578479: val_loss -0.156 
2025-11-22 06:15:49.578685: Pseudo dice [0.6232, 0.0035, 0.5918, 0.0, 0.5575, 0.0129, 0.881, 0.8445] 
2025-11-22 06:15:49.578867: Epoch time: 101.92 s 
2025-11-22 06:15:51.907549:  
2025-11-22 06:15:51.907867: Epoch 157 
2025-11-22 06:15:51.908029: Current learning rate: 0.00858 
2025-11-22 06:17:33.323620: train_loss -0.1998 
2025-11-22 06:17:33.323939: val_loss -0.1432 
2025-11-22 06:17:33.324099: Pseudo dice [0.0044, 0.7491, 0.6434, 0.0, 0.0, 0.745, 0.8574, 0.702] 
2025-11-22 06:17:33.324256: Epoch time: 101.42 s 
2025-11-22 06:17:35.169663:  
2025-11-22 06:17:35.169976: Epoch 158 
2025-11-22 06:17:35.170129: Current learning rate: 0.00857 
2025-11-22 06:19:16.903117: train_loss -0.199 
2025-11-22 06:19:16.903559: val_loss -0.1543 
2025-11-22 06:19:16.903854: Pseudo dice [0.6534, 0.0003, 0.0032, 0.5618, 0.0, 0.6863, 0.8518, 0.7848] 
2025-11-22 06:19:16.904010: Epoch time: 101.73 s 
2025-11-22 06:19:18.819855:  
2025-11-22 06:19:18.820119: Epoch 159 
2025-11-22 06:19:18.820271: Current learning rate: 0.00856 
2025-11-22 06:21:00.029893: train_loss -0.1923 
2025-11-22 06:21:00.030177: val_loss -0.1761 
2025-11-22 06:21:00.030422: Pseudo dice [0.0, 0.7524, 0.0002, 0.7472, 0.4978, 0.0353, 0.867, 0.8372] 
2025-11-22 06:21:00.030572: Epoch time: 101.21 s 
2025-11-22 06:21:02.343352:  
2025-11-22 06:21:02.343717: Epoch 160 
2025-11-22 06:21:02.343902: Current learning rate: 0.00855 
2025-11-22 06:22:43.583918: train_loss -0.2022 
2025-11-22 06:22:43.584177: val_loss -0.1541 
2025-11-22 06:22:43.584424: Pseudo dice [0.3547, 0.4667, 0.0, 0.6732, 0.636, 0.0029, 0.854, 0.8055] 
2025-11-22 06:22:43.584706: Epoch time: 101.24 s 
2025-11-22 06:22:45.596073:  
2025-11-22 06:22:45.596397: Epoch 161 
2025-11-22 06:22:45.596567: Current learning rate: 0.00854 
2025-11-22 06:24:26.862317: train_loss -0.1958 
2025-11-22 06:24:26.862563: val_loss -0.1597 
2025-11-22 06:24:26.862750: Pseudo dice [0.0233, 0.5524, 0.0, 0.7131, 0.6384, 0.1286, 0.8416, 0.7828] 
2025-11-22 06:24:26.862915: Epoch time: 101.27 s 
2025-11-22 06:24:28.883651:  
2025-11-22 06:24:28.883879: Epoch 162 
2025-11-22 06:24:28.884119: Current learning rate: 0.00853 
2025-11-22 06:26:10.686877: train_loss -0.2004 
2025-11-22 06:26:10.687115: val_loss -0.1493 
2025-11-22 06:26:10.687313: Pseudo dice [0.5406, 0.0008, 0.0, 0.534, 0.5527, 0.3425, 0.8591, 0.8101] 
2025-11-22 06:26:10.687471: Epoch time: 101.8 s 
2025-11-22 06:26:12.577972:  
2025-11-22 06:26:12.578213: Epoch 163 
2025-11-22 06:26:12.578384: Current learning rate: 0.00852 
2025-11-22 06:27:53.949044: train_loss -0.2031 
2025-11-22 06:27:53.949289: val_loss -0.1762 
2025-11-22 06:27:53.949497: Pseudo dice [0.3931, 0.2877, 0.6016, 0.0015, 0.5984, 0.0569, 0.8828, 0.8234] 
2025-11-22 06:27:53.949739: Epoch time: 101.37 s 
2025-11-22 06:27:55.948786:  
2025-11-22 06:27:55.949059: Epoch 164 
2025-11-22 06:27:55.949262: Current learning rate: 0.00851 
2025-11-22 06:29:37.600116: train_loss -0.2073 
2025-11-22 06:29:37.600435: val_loss -0.1933 
2025-11-22 06:29:37.600720: Pseudo dice [0.0, 0.5975, 0.0041, 0.7114, 0.0, 0.7075, 0.8385, 0.8518] 
2025-11-22 06:29:37.601033: Epoch time: 101.65 s 
2025-11-22 06:29:40.691926:  
2025-11-22 06:29:40.692268: Epoch 165 
2025-11-22 06:29:40.692430: Current learning rate: 0.0085 
2025-11-22 06:31:22.810562: train_loss -0.1945 
2025-11-22 06:31:22.810884: val_loss -0.1608 
2025-11-22 06:31:22.811176: Pseudo dice [0.7472, 0.0001, 0.0153, 0.6697, 0.5692, 0.2338, 0.8622, 0.7887] 
2025-11-22 06:31:22.811468: Epoch time: 102.12 s 
2025-11-22 06:31:24.707083:  
2025-11-22 06:31:24.707340: Epoch 166 
2025-11-22 06:31:24.707503: Current learning rate: 0.00849 
2025-11-22 06:33:06.782232: train_loss -0.202 
2025-11-22 06:33:06.782534: val_loss -0.1854 
2025-11-22 06:33:06.782726: Pseudo dice [0.6029, 0.1495, 0.0039, 0.5977, 0.0, 0.3918, 0.8933, 0.8709] 
2025-11-22 06:33:06.782882: Epoch time: 102.08 s 
2025-11-22 06:33:08.543549:  
2025-11-22 06:33:08.543889: Epoch 167 
2025-11-22 06:33:08.544051: Current learning rate: 0.00848 
2025-11-22 06:34:50.479789: train_loss -0.1845 
2025-11-22 06:34:50.480033: val_loss -0.1471 
2025-11-22 06:34:50.480230: Pseudo dice [0.0, 0.6525, 0.0011, 0.5508, 0.5413, 0.0, 0.8674, 0.8238] 
2025-11-22 06:34:50.480355: Epoch time: 101.94 s 
2025-11-22 06:34:52.333275:  
2025-11-22 06:34:52.333634: Epoch 168 
2025-11-22 06:34:52.333841: Current learning rate: 0.00847 
2025-11-22 06:36:34.623058: train_loss -0.1946 
2025-11-22 06:36:34.623490: val_loss -0.1659 
2025-11-22 06:36:34.623686: Pseudo dice [0.6445, 0.0118, 0.3539, 0.5875, 0.0, 0.713, 0.8499, 0.7925] 
2025-11-22 06:36:34.623815: Epoch time: 102.29 s 
2025-11-22 06:36:36.552820:  
2025-11-22 06:36:36.553126: Epoch 169 
2025-11-22 06:36:36.553294: Current learning rate: 0.00847 
2025-11-22 06:38:18.442654: train_loss -0.201 
2025-11-22 06:38:18.442917: val_loss -0.1789 
2025-11-22 06:38:18.443140: Pseudo dice [0.5208, 0.233, 0.0022, 0.6737, 0.0, 0.7928, 0.8905, 0.8266] 
2025-11-22 06:38:18.443304: Epoch time: 101.89 s 
2025-11-22 06:38:18.443410: Yayy! New best EMA pseudo Dice: 0.4614 
2025-11-22 06:38:21.539865:  
2025-11-22 06:38:21.540193: Epoch 170 
2025-11-22 06:38:21.540354: Current learning rate: 0.00846 
2025-11-22 06:40:03.340106: train_loss -0.192 
2025-11-22 06:40:03.340352: val_loss -0.1621 
2025-11-22 06:40:03.340508: Pseudo dice [0.6427, 0.0488, 0.1026, 0.5629, 0.6223, 0.0191, 0.8658, 0.8185] 
2025-11-22 06:40:03.340665: Epoch time: 101.8 s 
2025-11-22 06:40:05.681072:  
2025-11-22 06:40:05.681418: Epoch 171 
2025-11-22 06:40:05.681587: Current learning rate: 0.00845 
2025-11-22 06:41:47.447819: train_loss -0.1979 
2025-11-22 06:41:47.448126: val_loss -0.1537 
2025-11-22 06:41:47.448371: Pseudo dice [0.2679, 0.4485, 0.0, 0.527, 0.0284, 0.7291, 0.8519, 0.8444] 
2025-11-22 06:41:47.448520: Epoch time: 101.77 s 
2025-11-22 06:41:49.436097:  
2025-11-22 06:41:49.436452: Epoch 172 
2025-11-22 06:41:49.436644: Current learning rate: 0.00844 
2025-11-22 06:43:31.247636: train_loss -0.2017 
2025-11-22 06:43:31.247899: val_loss -0.1448 
2025-11-22 06:43:31.248141: Pseudo dice [0.5282, 0.0072, 0.4547, 0.0, 0.0003, 0.0487, 0.866, 0.7733] 
2025-11-22 06:43:31.248299: Epoch time: 101.81 s 
2025-11-22 06:43:33.268340:  
2025-11-22 06:43:33.268640: Epoch 173 
2025-11-22 06:43:33.268824: Current learning rate: 0.00843 
2025-11-22 06:45:15.415806: train_loss -0.1945 
2025-11-22 06:45:15.416092: val_loss -0.167 
2025-11-22 06:45:15.416313: Pseudo dice [0.7677, 0.0887, 0.367, 0.5275, 0.6124, 0.0458, 0.8384, 0.8234] 
2025-11-22 06:45:15.416445: Epoch time: 102.15 s 
2025-11-22 06:45:17.306386:  
2025-11-22 06:45:17.306700: Epoch 174 
2025-11-22 06:45:17.306937: Current learning rate: 0.00842 
2025-11-22 06:46:59.063396: train_loss -0.2047 
2025-11-22 06:46:59.063659: val_loss -0.169 
2025-11-22 06:46:59.063906: Pseudo dice [0.7646, 0.0087, 0.7965, 0.0, 0.0, 0.439, 0.8696, 0.8333] 
2025-11-22 06:46:59.064113: Epoch time: 101.76 s 
2025-11-22 06:47:00.868604:  
2025-11-22 06:47:00.868939: Epoch 175 
2025-11-22 06:47:00.869112: Current learning rate: 0.00841 
2025-11-22 06:48:42.520129: train_loss -0.1882 
2025-11-22 06:48:42.520368: val_loss -0.152 
2025-11-22 06:48:42.520574: Pseudo dice [0.5904, 0.0002, 0.0077, 0.5447, 0.409, 0.1192, 0.8245, 0.8344] 
2025-11-22 06:48:42.520710: Epoch time: 101.65 s 
2025-11-22 06:48:44.568941:  
2025-11-22 06:48:44.569257: Epoch 176 
2025-11-22 06:48:44.569425: Current learning rate: 0.0084 
2025-11-22 06:50:25.956272: train_loss -0.1941 
2025-11-22 06:50:25.956496: val_loss -0.1447 
2025-11-22 06:50:25.956824: Pseudo dice [0.5909, 0.257, 0.4881, 0.0987, 0.6472, 0.0, 0.8313, 0.7739] 
2025-11-22 06:50:25.956978: Epoch time: 101.39 s 
2025-11-22 06:50:27.879581:  
2025-11-22 06:50:27.879874: Epoch 177 
2025-11-22 06:50:27.880071: Current learning rate: 0.00839 
2025-11-22 06:52:09.520346: train_loss -0.2026 
2025-11-22 06:52:09.520615: val_loss -0.1619 
2025-11-22 06:52:09.520965: Pseudo dice [0.0005, 0.5715, 0.0, 0.5104, 0.6027, 0.0089, 0.795, 0.845] 
2025-11-22 06:52:09.521162: Epoch time: 101.64 s 
2025-11-22 06:52:11.536865:  
2025-11-22 06:52:11.537211: Epoch 178 
2025-11-22 06:52:11.537376: Current learning rate: 0.00838 
2025-11-22 06:53:52.733905: train_loss -0.2009 
2025-11-22 06:53:52.734178: val_loss -0.1719 
2025-11-22 06:53:52.734450: Pseudo dice [0.0, 0.7365, 0.0002, 0.64, 0.0, 0.6078, 0.891, 0.7842] 
2025-11-22 06:53:52.734559: Epoch time: 101.2 s 
2025-11-22 06:53:55.028171:  
2025-11-22 06:53:55.028516: Epoch 179 
2025-11-22 06:53:55.028672: Current learning rate: 0.00837 
2025-11-22 06:55:36.298799: train_loss -0.2085 
2025-11-22 06:55:36.299046: val_loss -0.176 
2025-11-22 06:55:36.299231: Pseudo dice [0.0, 0.651, 0.0, 0.6964, 0.0, 0.8026, 0.8356, 0.8457] 
2025-11-22 06:55:36.299348: Epoch time: 101.27 s 
2025-11-22 06:55:38.689753:  
2025-11-22 06:55:38.690048: Epoch 180 
2025-11-22 06:55:38.690198: Current learning rate: 0.00836 
2025-11-22 06:57:19.783053: train_loss -0.1938 
2025-11-22 06:57:19.783283: val_loss -0.1663 
2025-11-22 06:57:19.783470: Pseudo dice [0.6005, 0.0593, 0.0, 0.8227, 0.7209, 0.0995, 0.8427, 0.7313] 
2025-11-22 06:57:19.783576: Epoch time: 101.1 s 
2025-11-22 06:57:21.635376:  
2025-11-22 06:57:21.635677: Epoch 181 
2025-11-22 06:57:21.635856: Current learning rate: 0.00836 
2025-11-22 06:59:03.027289: train_loss -0.2119 
2025-11-22 06:59:03.027560: val_loss -0.1742 
2025-11-22 06:59:03.027843: Pseudo dice [0.6442, 0.0001, 0.4584, 0.0063, 0.8175, 0.0494, 0.8497, 0.7858] 
2025-11-22 06:59:03.027976: Epoch time: 101.39 s 
2025-11-22 06:59:05.224992:  
2025-11-22 06:59:05.225307: Epoch 182 
2025-11-22 06:59:05.225491: Current learning rate: 0.00835 
2025-11-22 07:00:46.592910: train_loss -0.1999 
2025-11-22 07:00:46.593338: val_loss -0.1607 
2025-11-22 07:00:46.593623: Pseudo dice [0.6571, 0.0061, 0.7374, 0.0003, 0.0, 0.772, 0.8378, 0.8317] 
2025-11-22 07:00:46.593897: Epoch time: 101.37 s 
2025-11-22 07:00:48.504228:  
2025-11-22 07:00:48.504535: Epoch 183 
2025-11-22 07:00:48.504696: Current learning rate: 0.00834 
2025-11-22 07:02:30.057904: train_loss -0.2101 
2025-11-22 07:02:30.058251: val_loss -0.1726 
2025-11-22 07:02:30.058524: Pseudo dice [0.2502, 0.5161, 0.0, 0.5524, 0.7748, 0.0, 0.8621, 0.8139] 
2025-11-22 07:02:30.058808: Epoch time: 101.56 s 
2025-11-22 07:02:32.008298:  
2025-11-22 07:02:32.008499: Epoch 184 
2025-11-22 07:02:32.008658: Current learning rate: 0.00833 
2025-11-22 07:04:13.733686: train_loss -0.1997 
2025-11-22 07:04:13.733950: val_loss -0.1606 
2025-11-22 07:04:13.734128: Pseudo dice [0.5445, 0.0025, 0.5704, 0.0061, 0.0, 0.7717, 0.8143, 0.855] 
2025-11-22 07:04:13.734241: Epoch time: 101.73 s 
2025-11-22 07:04:16.955883:  
2025-11-22 07:04:16.956235: Epoch 185 
2025-11-22 07:04:16.956425: Current learning rate: 0.00832 
2025-11-22 07:05:58.918162: train_loss -0.2013 
2025-11-22 07:05:58.918388: val_loss -0.1632 
2025-11-22 07:05:58.918578: Pseudo dice [0.6519, 0.0001, 0.7157, 0.0, 0.0, 0.6194, 0.8164, 0.7685] 
2025-11-22 07:05:58.918707: Epoch time: 101.96 s 
2025-11-22 07:06:00.788733:  
2025-11-22 07:06:00.789006: Epoch 186 
2025-11-22 07:06:00.789178: Current learning rate: 0.00831 
2025-11-22 07:07:42.837059: train_loss -0.1999 
2025-11-22 07:07:42.837365: val_loss -0.1805 
2025-11-22 07:07:42.837627: Pseudo dice [0.5677, 0.1959, 0.606, 0.0, 0.7645, 0.0, 0.8779, 0.8014] 
2025-11-22 07:07:42.837816: Epoch time: 102.05 s 
2025-11-22 07:07:45.098189:  
2025-11-22 07:07:45.098486: Epoch 187 
2025-11-22 07:07:45.098683: Current learning rate: 0.0083 
2025-11-22 07:09:26.955982: train_loss -0.1934 
2025-11-22 07:09:26.956222: val_loss -0.1715 
2025-11-22 07:09:26.956426: Pseudo dice [0.0001, 0.7226, 0.0002, 0.6904, 0.551, 0.0003, 0.8655, 0.7582] 
2025-11-22 07:09:26.956705: Epoch time: 101.86 s 
2025-11-22 07:09:28.821395:  
2025-11-22 07:09:28.821734: Epoch 188 
2025-11-22 07:09:28.821927: Current learning rate: 0.00829 
2025-11-22 07:11:10.391996: train_loss -0.2034 
2025-11-22 07:11:10.392246: val_loss -0.1791 
2025-11-22 07:11:10.392469: Pseudo dice [0.0, 0.7013, 0.6636, 0.0067, 0.5626, 0.0875, 0.8919, 0.8023] 
2025-11-22 07:11:10.392689: Epoch time: 101.57 s 
2025-11-22 07:11:12.217819:  
2025-11-22 07:11:12.218154: Epoch 189 
2025-11-22 07:11:12.218322: Current learning rate: 0.00828 
2025-11-22 07:12:54.185595: train_loss -0.2153 
2025-11-22 07:12:54.185852: val_loss -0.1578 
2025-11-22 07:12:54.186131: Pseudo dice [0.0, 0.6535, 0.001, 0.5121, 0.5684, 0.0, 0.8633, 0.8054] 
2025-11-22 07:12:54.186288: Epoch time: 101.97 s 
2025-11-22 07:12:56.120302:  
2025-11-22 07:12:56.120665: Epoch 190 
2025-11-22 07:12:56.120870: Current learning rate: 0.00827 
2025-11-22 07:14:37.804136: train_loss -0.1968 
2025-11-22 07:14:37.804445: val_loss -0.1896 
2025-11-22 07:14:37.804663: Pseudo dice [0.0167, 0.6911, 0.0037, 0.5881, 0.0, 0.6884, 0.8585, 0.8857] 
2025-11-22 07:14:37.804821: Epoch time: 101.69 s 
2025-11-22 07:14:39.677274:  
2025-11-22 07:14:39.677624: Epoch 191 
2025-11-22 07:14:39.677824: Current learning rate: 0.00826 
2025-11-22 07:16:21.374393: train_loss -0.2086 
2025-11-22 07:16:21.374621: val_loss -0.1528 
2025-11-22 07:16:21.374919: Pseudo dice [0.0, 0.6255, 0.0005, 0.7188, 0.5247, 0.0, 0.8226, 0.6198] 
2025-11-22 07:16:21.375153: Epoch time: 101.7 s 
2025-11-22 07:16:23.246860:  
2025-11-22 07:16:23.247177: Epoch 192 
2025-11-22 07:16:23.247352: Current learning rate: 0.00825 
2025-11-22 07:18:05.258611: train_loss -0.2042 
2025-11-22 07:18:05.258884: val_loss -0.1394 
2025-11-22 07:18:05.259120: Pseudo dice [0.0, 0.7562, 0.1906, 0.6494, 0.0, 0.7685, 0.8487, 0.7703] 
2025-11-22 07:18:05.259247: Epoch time: 102.01 s 
2025-11-22 07:18:07.200212:  
2025-11-22 07:18:07.200522: Epoch 193 
2025-11-22 07:18:07.200694: Current learning rate: 0.00824 
2025-11-22 07:19:49.153640: train_loss -0.1937 
2025-11-22 07:19:49.153930: val_loss -0.1432 
2025-11-22 07:19:49.154142: Pseudo dice [0.0004, 0.6284, 0.5684, 0.0006, 0.7877, 0.0146, 0.8431, 0.791] 
2025-11-22 07:19:49.154283: Epoch time: 101.95 s 
2025-11-22 07:19:51.476862:  
2025-11-22 07:19:51.477164: Epoch 194 
2025-11-22 07:19:51.477320: Current learning rate: 0.00824 
2025-11-22 07:21:33.112623: train_loss -0.2094 
2025-11-22 07:21:33.112961: val_loss -0.1777 
2025-11-22 07:21:33.113159: Pseudo dice [0.0, 0.7306, 0.007, 0.6295, 0.0, 0.645, 0.852, 0.7883] 
2025-11-22 07:21:33.113301: Epoch time: 101.64 s 
2025-11-22 07:21:35.000035:  
2025-11-22 07:21:35.000400: Epoch 195 
2025-11-22 07:21:35.000589: Current learning rate: 0.00823 
2025-11-22 07:23:16.534647: train_loss -0.207 
2025-11-22 07:23:16.534955: val_loss -0.1661 
2025-11-22 07:23:16.535270: Pseudo dice [0.0001, 0.6691, 0.6213, 0.0514, 0.5095, 0.012, 0.8424, 0.8021] 
2025-11-22 07:23:16.535418: Epoch time: 101.54 s 
2025-11-22 07:23:18.424796:  
2025-11-22 07:23:18.424938: Epoch 196 
2025-11-22 07:23:18.425139: Current learning rate: 0.00822 
2025-11-22 07:24:59.656811: train_loss -0.1978 
2025-11-22 07:24:59.657098: val_loss -0.1689 
2025-11-22 07:24:59.657304: Pseudo dice [0.6568, 0.0001, 0.7272, 0.0, 0.6694, 0.0008, 0.8586, 0.8005] 
2025-11-22 07:24:59.657432: Epoch time: 101.23 s 
2025-11-22 07:25:01.988234:  
2025-11-22 07:25:01.988544: Epoch 197 
2025-11-22 07:25:01.988701: Current learning rate: 0.00821 
2025-11-22 07:26:43.475575: train_loss -0.1955 
2025-11-22 07:26:43.476032: val_loss -0.1526 
2025-11-22 07:26:43.476272: Pseudo dice [0.578, 0.013, 0.0195, 0.7687, 0.0, 0.8115, 0.8923, 0.761] 
2025-11-22 07:26:43.476407: Epoch time: 101.49 s 
2025-11-22 07:26:45.858963:  
2025-11-22 07:26:45.859310: Epoch 198 
2025-11-22 07:26:45.859485: Current learning rate: 0.0082 
2025-11-22 07:28:27.713210: train_loss -0.2043 
2025-11-22 07:28:27.713495: val_loss -0.1687 
2025-11-22 07:28:27.713665: Pseudo dice [0.0001, 0.6567, 0.0044, 0.5142, 0.0, 0.595, 0.8685, 0.7648] 
2025-11-22 07:28:27.713835: Epoch time: 101.86 s 
2025-11-22 07:28:30.104432:  
2025-11-22 07:28:30.104720: Epoch 199 
2025-11-22 07:28:30.104899: Current learning rate: 0.00819 
2025-11-22 07:30:11.412807: train_loss -0.1958 
2025-11-22 07:30:11.413078: val_loss -0.1511 
2025-11-22 07:30:11.413305: Pseudo dice [0.0002, 0.4832, 0.0, 0.5752, 0.3752, 0.0235, 0.8316, 0.7793] 
2025-11-22 07:30:11.413568: Epoch time: 101.31 s 
2025-11-22 07:30:14.273658:  
2025-11-22 07:30:14.274015: Epoch 200 
2025-11-22 07:30:14.274262: Current learning rate: 0.00818 
2025-11-22 07:31:55.787461: train_loss -0.1989 
2025-11-22 07:31:55.787714: val_loss -0.1503 
2025-11-22 07:31:55.787973: Pseudo dice [0.0, 0.6899, 0.5201, 0.0, 0.6219, 0.0001, 0.8663, 0.7776] 
2025-11-22 07:31:55.788178: Epoch time: 101.52 s 
2025-11-22 07:31:57.997116:  
2025-11-22 07:31:57.997322: Epoch 201 
2025-11-22 07:31:57.997495: Current learning rate: 0.00817 
2025-11-22 07:33:39.946229: train_loss -0.2 
2025-11-22 07:33:39.946495: val_loss -0.1735 
2025-11-22 07:33:39.946705: Pseudo dice [0.0143, 0.4619, 0.5688, 0.0, 0.0, 0.3529, 0.8504, 0.826] 
2025-11-22 07:33:39.946883: Epoch time: 101.95 s 
2025-11-22 07:33:41.936579:  
2025-11-22 07:33:41.936936: Epoch 202 
2025-11-22 07:33:41.937100: Current learning rate: 0.00816 
2025-11-22 07:35:23.670116: train_loss -0.2065 
2025-11-22 07:35:23.670336: val_loss -0.165 
2025-11-22 07:35:23.670533: Pseudo dice [0.0306, 0.6664, 0.0, 0.5928, 0.1143, 0.0, 0.8898, 0.756] 
2025-11-22 07:35:23.670660: Epoch time: 101.74 s 
2025-11-22 07:35:25.526497:  
2025-11-22 07:35:25.526636: Epoch 203 
2025-11-22 07:35:25.526821: Current learning rate: 0.00815 
2025-11-22 07:37:07.392393: train_loss -0.2108 
2025-11-22 07:37:07.392602: val_loss -0.1583 
2025-11-22 07:37:07.392806: Pseudo dice [0.6301, 0.0017, 0.0009, 0.5605, 0.6008, 0.0, 0.7232, 0.8231] 
2025-11-22 07:37:07.392932: Epoch time: 101.87 s 
2025-11-22 07:37:09.444793:  
2025-11-22 07:37:09.445080: Epoch 204 
2025-11-22 07:37:09.445243: Current learning rate: 0.00814 
2025-11-22 07:38:51.438360: train_loss -0.1981 
2025-11-22 07:38:51.438564: val_loss -0.1343 
2025-11-22 07:38:51.438794: Pseudo dice [0.6398, 0.0067, 0.6301, 0.0, 0.0, 0.7697, 0.8642, 0.7575] 
2025-11-22 07:38:51.439047: Epoch time: 102.0 s 
2025-11-22 07:38:53.343605:  
2025-11-22 07:38:53.343948: Epoch 205 
2025-11-22 07:38:53.344137: Current learning rate: 0.00813 
2025-11-22 07:40:34.654746: train_loss -0.2042 
2025-11-22 07:40:34.655040: val_loss -0.1544 
2025-11-22 07:40:34.655380: Pseudo dice [0.7462, 0.0001, 0.5101, 0.0, 0.4568, 0.0615, 0.8483, 0.75] 
2025-11-22 07:40:34.655588: Epoch time: 101.31 s 
2025-11-22 07:40:37.384085:  
2025-11-22 07:40:37.384432: Epoch 206 
2025-11-22 07:40:37.384598: Current learning rate: 0.00813 
2025-11-22 07:42:18.560877: train_loss -0.208 
2025-11-22 07:42:18.561140: val_loss -0.1691 
2025-11-22 07:42:18.561348: Pseudo dice [0.6788, 0.0012, 0.6074, 0.0, 0.7094, 0.0473, 0.8754, 0.7628] 
2025-11-22 07:42:18.561492: Epoch time: 101.18 s 
2025-11-22 07:42:20.542960:  
2025-11-22 07:42:20.543260: Epoch 207 
2025-11-22 07:42:20.543452: Current learning rate: 0.00812 
2025-11-22 07:44:02.211279: train_loss -0.2049 
2025-11-22 07:44:02.211571: val_loss -0.1659 
2025-11-22 07:44:02.211812: Pseudo dice [0.1626, 0.6135, 0.0, 0.6256, 0.0, 0.8533, 0.8704, 0.7223] 
2025-11-22 07:44:02.211951: Epoch time: 101.67 s 
2025-11-22 07:44:04.057648:  
2025-11-22 07:44:04.057963: Epoch 208 
2025-11-22 07:44:04.058164: Current learning rate: 0.00811 
2025-11-22 07:45:45.731232: train_loss -0.2079 
2025-11-22 07:45:45.731457: val_loss -0.1565 
2025-11-22 07:45:45.731645: Pseudo dice [0.0844, 0.6201, 0.001, 0.5041, 0.7584, 0.0736, 0.8491, 0.8289] 
2025-11-22 07:45:45.731817: Epoch time: 101.67 s 
2025-11-22 07:45:47.445535:  
2025-11-22 07:45:47.445810: Epoch 209 
2025-11-22 07:45:47.445944: Current learning rate: 0.0081 
2025-11-22 07:47:28.840725: train_loss -0.2016 
2025-11-22 07:47:28.841110: val_loss -0.1495 
2025-11-22 07:47:28.841354: Pseudo dice [0.0, 0.6798, 0.577, 0.0021, 0.0, 0.8547, 0.8494, 0.7006] 
2025-11-22 07:47:28.841525: Epoch time: 101.4 s 
2025-11-22 07:47:30.575280:  
2025-11-22 07:47:30.575532: Epoch 210 
2025-11-22 07:47:30.575747: Current learning rate: 0.00809 
2025-11-22 07:49:11.778725: train_loss -0.2018 
2025-11-22 07:49:11.778971: val_loss -0.1831 
2025-11-22 07:49:11.779169: Pseudo dice [0.0, 0.5567, 0.5845, 0.0, 0.0, 0.6172, 0.8811, 0.8053] 
2025-11-22 07:49:11.779300: Epoch time: 101.2 s 
2025-11-22 07:49:14.006807:  
2025-11-22 07:49:14.007136: Epoch 211 
2025-11-22 07:49:14.007293: Current learning rate: 0.00808 
2025-11-22 07:50:55.459301: train_loss -0.1961 
2025-11-22 07:50:55.459705: val_loss -0.1576 
2025-11-22 07:50:55.459907: Pseudo dice [0.0163, 0.6566, 0.0006, 0.603, 0.4925, 0.0019, 0.8661, 0.7762] 
2025-11-22 07:50:55.460017: Epoch time: 101.45 s 
2025-11-22 07:50:57.344978:  
2025-11-22 07:50:57.345299: Epoch 212 
2025-11-22 07:50:57.345460: Current learning rate: 0.00807 
2025-11-22 07:52:38.934865: train_loss -0.2129 
2025-11-22 07:52:38.935185: val_loss -0.1725 
2025-11-22 07:52:38.935352: Pseudo dice [0.0, 0.7008, 0.719, 0.0, 0.5498, 0.154, 0.837, 0.8399] 
2025-11-22 07:52:38.935472: Epoch time: 101.59 s 
2025-11-22 07:52:40.721621:  
2025-11-22 07:52:40.721955: Epoch 213 
2025-11-22 07:52:40.722120: Current learning rate: 0.00806 
2025-11-22 07:54:22.540123: train_loss -0.1916 
2025-11-22 07:54:22.540477: val_loss -0.1481 
2025-11-22 07:54:22.540827: Pseudo dice [0.0, 0.5628, 0.0, 0.6608, 0.0, 0.6594, 0.8678, 0.7773] 
2025-11-22 07:54:22.541005: Epoch time: 101.82 s 
2025-11-22 07:54:24.289013:  
2025-11-22 07:54:24.289400: Epoch 214 
2025-11-22 07:54:24.289571: Current learning rate: 0.00805 
2025-11-22 07:56:06.219038: train_loss -0.2042 
2025-11-22 07:56:06.219473: val_loss -0.1522 
2025-11-22 07:56:06.219681: Pseudo dice [0.0, 0.6287, 0.0, 0.6367, 0.0, 0.727, 0.8618, 0.8311] 
2025-11-22 07:56:06.219826: Epoch time: 101.93 s 
2025-11-22 07:56:08.020420:  
2025-11-22 07:56:08.020618: Epoch 215 
2025-11-22 07:56:08.020798: Current learning rate: 0.00804 
2025-11-22 07:57:49.806057: train_loss -0.2 
2025-11-22 07:57:49.806299: val_loss -0.1821 
2025-11-22 07:57:49.806495: Pseudo dice [0.0, 0.6884, 0.7246, 0.0, 0.0, 0.4917, 0.8905, 0.8609] 
2025-11-22 07:57:49.806649: Epoch time: 101.79 s 
2025-11-22 07:57:51.635316:  
2025-11-22 07:57:51.635638: Epoch 216 
2025-11-22 07:57:51.635829: Current learning rate: 0.00803 
2025-11-22 07:59:33.594890: train_loss -0.2082 
2025-11-22 07:59:33.595204: val_loss -0.1876 
2025-11-22 07:59:33.595404: Pseudo dice [0.0, 0.6711, 0.0, 0.6258, 0.5312, 0.0279, 0.8921, 0.8312] 
2025-11-22 07:59:33.595541: Epoch time: 101.96 s 
2025-11-22 07:59:35.356948:  
2025-11-22 07:59:35.357230: Epoch 217 
2025-11-22 07:59:35.357384: Current learning rate: 0.00802 
2025-11-22 08:01:17.434602: train_loss -0.2056 
2025-11-22 08:01:17.434823: val_loss -0.1671 
2025-11-22 08:01:17.435049: Pseudo dice [0.0, 0.5738, 0.0468, 0.6873, 0.0009, 0.7526, 0.8339, 0.776] 
2025-11-22 08:01:17.435294: Epoch time: 102.08 s 
2025-11-22 08:01:19.237770:  
2025-11-22 08:01:19.238084: Epoch 218 
2025-11-22 08:01:19.238250: Current learning rate: 0.00801 
2025-11-22 08:03:00.860096: train_loss -0.2138 
2025-11-22 08:03:00.860422: val_loss -0.1637 
2025-11-22 08:03:00.860693: Pseudo dice [0.5406, 0.0011, 0.5228, 0.0183, 0.0, 0.5393, 0.8565, 0.8096] 
2025-11-22 08:03:00.860921: Epoch time: 101.62 s 
2025-11-22 08:03:02.674440:  
2025-11-22 08:03:02.674821: Epoch 219 
2025-11-22 08:03:02.674981: Current learning rate: 0.00801 
2025-11-22 08:04:44.479569: train_loss -0.2096 
2025-11-22 08:04:44.479869: val_loss -0.1586 
2025-11-22 08:04:44.480065: Pseudo dice [0.5116, 0.0006, 0.6248, 0.0165, 0.4219, 0.0004, 0.8456, 0.8076] 
2025-11-22 08:04:44.480208: Epoch time: 101.81 s 
2025-11-22 08:04:46.216646:  
2025-11-22 08:04:46.216893: Epoch 220 
2025-11-22 08:04:46.217113: Current learning rate: 0.008 
2025-11-22 08:06:27.987661: train_loss -0.1833 
2025-11-22 08:06:27.987998: val_loss -0.1541 
2025-11-22 08:06:27.988201: Pseudo dice [0.5455, 0.0512, 0.0006, 0.4882, 0.6055, 0.0024, 0.8948, 0.8487] 
2025-11-22 08:06:27.988339: Epoch time: 101.77 s 
2025-11-22 08:06:29.826998:  
2025-11-22 08:06:29.827334: Epoch 221 
2025-11-22 08:06:29.827505: Current learning rate: 0.00799 
2025-11-22 08:08:11.371977: train_loss -0.2019 
2025-11-22 08:08:11.372242: val_loss -0.1602 
2025-11-22 08:08:11.372372: Pseudo dice [0.59, 0.0828, 0.6093, 0.0, 0.0, 0.5318, 0.845, 0.7944] 
2025-11-22 08:08:11.372459: Epoch time: 101.55 s 
2025-11-22 08:08:13.189228:  
2025-11-22 08:08:13.189564: Epoch 222 
2025-11-22 08:08:13.189732: Current learning rate: 0.00798 
2025-11-22 08:09:54.226314: train_loss -0.1978 
2025-11-22 08:09:54.226572: val_loss -0.1581 
2025-11-22 08:09:54.226868: Pseudo dice [0.0, 0.666, 0.0022, 0.5055, 0.6141, 0.0019, 0.8945, 0.8423] 
2025-11-22 08:09:54.227036: Epoch time: 101.04 s 
2025-11-22 08:09:56.036882:  
2025-11-22 08:09:56.037197: Epoch 223 
2025-11-22 08:09:56.037372: Current learning rate: 0.00797 
2025-11-22 08:11:37.419925: train_loss -0.2102 
2025-11-22 08:11:37.420169: val_loss -0.1682 
2025-11-22 08:11:37.420378: Pseudo dice [0.0, 0.5027, 0.0, 0.4831, 0.0, 0.4881, 0.8849, 0.8539] 
2025-11-22 08:11:37.420575: Epoch time: 101.38 s 
2025-11-22 08:11:39.446529:  
2025-11-22 08:11:39.446840: Epoch 224 
2025-11-22 08:11:39.447004: Current learning rate: 0.00796 
2025-11-22 08:13:20.736547: train_loss -0.2132 
2025-11-22 08:13:20.736885: val_loss -0.1676 
2025-11-22 08:13:20.737116: Pseudo dice [0.4728, 0.1354, 0.3923, 0.6124, 0.025, 0.7322, 0.8993, 0.8228] 
2025-11-22 08:13:20.737260: Epoch time: 101.29 s 
2025-11-22 08:13:23.030591:  
2025-11-22 08:13:23.030924: Epoch 225 
2025-11-22 08:13:23.031080: Current learning rate: 0.00795 
2025-11-22 08:15:04.889919: train_loss -0.2059 
2025-11-22 08:15:04.890140: val_loss -0.1759 
2025-11-22 08:15:04.890334: Pseudo dice [0.0013, 0.6489, 0.001, 0.5429, 0.0, 0.6007, 0.8552, 0.821] 
2025-11-22 08:15:04.890471: Epoch time: 101.86 s 
2025-11-22 08:15:06.796653:  
2025-11-22 08:15:06.796914: Epoch 226 
2025-11-22 08:15:06.797095: Current learning rate: 0.00794 
2025-11-22 08:16:48.177272: train_loss -0.2138 
2025-11-22 08:16:48.177536: val_loss -0.1826 
2025-11-22 08:16:48.177828: Pseudo dice [0.6221, 0.0481, 0.7055, 0.0, 0.0, 0.8073, 0.8681, 0.7948] 
2025-11-22 08:16:48.178070: Epoch time: 101.38 s 
2025-11-22 08:16:50.942289:  
2025-11-22 08:16:50.942698: Epoch 227 
2025-11-22 08:16:50.942911: Current learning rate: 0.00793 
2025-11-22 08:18:32.626604: train_loss -0.192 
2025-11-22 08:18:32.626855: val_loss -0.2074 
2025-11-22 08:18:32.627043: Pseudo dice [0.3507, 0.5467, 0.0027, 0.5793, 0.7235, 0.0227, 0.8998, 0.8801] 
2025-11-22 08:18:32.627182: Epoch time: 101.69 s 
2025-11-22 08:18:34.412683:  
2025-11-22 08:18:34.413089: Epoch 228 
2025-11-22 08:18:34.413282: Current learning rate: 0.00792 
2025-11-22 08:20:15.808602: train_loss -0.2132 
2025-11-22 08:20:15.808850: val_loss -0.1636 
2025-11-22 08:20:15.809041: Pseudo dice [0.0, 0.6445, 0.0624, 0.5577, 0.0, 0.4749, 0.8447, 0.7773] 
2025-11-22 08:20:15.809177: Epoch time: 101.4 s 
2025-11-22 08:20:17.817841:  
2025-11-22 08:20:17.818291: Epoch 229 
2025-11-22 08:20:17.818464: Current learning rate: 0.00791 
2025-11-22 08:21:59.747579: train_loss -0.2007 
2025-11-22 08:21:59.747874: val_loss -0.1781 
2025-11-22 08:21:59.748110: Pseudo dice [0.0012, 0.7748, 0.4665, 0.3758, 0.0, 0.6824, 0.8996, 0.7984] 
2025-11-22 08:21:59.748248: Epoch time: 101.93 s 
2025-11-22 08:22:01.523673:  
2025-11-22 08:22:01.524030: Epoch 230 
2025-11-22 08:22:01.524194: Current learning rate: 0.0079 
2025-11-22 08:23:43.353271: train_loss -0.2114 
2025-11-22 08:23:43.353498: val_loss -0.1753 
2025-11-22 08:23:43.353686: Pseudo dice [0.0, 0.5519, 0.6052, 0.0, 0.6411, 0.0, 0.8486, 0.8314] 
2025-11-22 08:23:43.353915: Epoch time: 101.83 s 
2025-11-22 08:23:45.093164:  
2025-11-22 08:23:45.093520: Epoch 231 
2025-11-22 08:23:45.093683: Current learning rate: 0.00789 
2025-11-22 08:25:27.313955: train_loss -0.2064 
2025-11-22 08:25:27.314207: val_loss -0.1571 
2025-11-22 08:25:27.314374: Pseudo dice [0.594, 0.0015, 0.0912, 0.5752, 0.0, 0.7043, 0.8843, 0.7311] 
2025-11-22 08:25:27.314505: Epoch time: 102.22 s 
2025-11-22 08:25:29.104692:  
2025-11-22 08:25:29.104916: Epoch 232 
2025-11-22 08:25:29.105067: Current learning rate: 0.00789 
2025-11-22 08:27:11.174542: train_loss -0.2046 
2025-11-22 08:27:11.174965: val_loss -0.1891 
2025-11-22 08:27:11.175112: Pseudo dice [0.6426, 0.001, 0.0081, 0.5788, 0.5725, 0.0, 0.8489, 0.8067] 
2025-11-22 08:27:11.175203: Epoch time: 102.07 s 
2025-11-22 08:27:13.133447:  
2025-11-22 08:27:13.133676: Epoch 233 
2025-11-22 08:27:13.133871: Current learning rate: 0.00788 
2025-11-22 08:28:54.801282: train_loss -0.2123 
2025-11-22 08:28:54.801531: val_loss -0.1457 
2025-11-22 08:28:54.801747: Pseudo dice [0.0025, 0.6915, 0.6101, 0.0, 0.5966, 0.0595, 0.7684, 0.7779] 
2025-11-22 08:28:54.801928: Epoch time: 101.67 s 
2025-11-22 08:28:56.682376:  
2025-11-22 08:28:56.682673: Epoch 234 
2025-11-22 08:28:56.682856: Current learning rate: 0.00787 
2025-11-22 08:30:38.484202: train_loss -0.2111 
2025-11-22 08:30:38.484489: val_loss -0.1734 
2025-11-22 08:30:38.484762: Pseudo dice [0.7214, 0.0, 0.1857, 0.5981, 0.0, 0.8372, 0.8747, 0.8321] 
2025-11-22 08:30:38.484951: Epoch time: 101.8 s 
2025-11-22 08:30:40.499046:  
2025-11-22 08:30:40.499287: Epoch 235 
2025-11-22 08:30:40.499483: Current learning rate: 0.00786 
2025-11-22 08:32:22.062852: train_loss -0.1988 
2025-11-22 08:32:22.063162: val_loss -0.1246 
2025-11-22 08:32:22.063648: Pseudo dice [0.5719, 0.0005, 0.4698, 0.0, 0.0, 0.566, 0.839, 0.8048] 
2025-11-22 08:32:22.063852: Epoch time: 101.57 s 
2025-11-22 08:32:23.870365:  
2025-11-22 08:32:23.870677: Epoch 236 
2025-11-22 08:32:23.870869: Current learning rate: 0.00785 
2025-11-22 08:34:05.375567: train_loss -0.206 
2025-11-22 08:34:05.376040: val_loss -0.1819 
2025-11-22 08:34:05.376250: Pseudo dice [0.6695, 0.1126, 0.5979, 0.0, 0.5288, 0.0, 0.8804, 0.8445] 
2025-11-22 08:34:05.376386: Epoch time: 101.51 s 
2025-11-22 08:34:07.274289:  
2025-11-22 08:34:07.274588: Epoch 237 
2025-11-22 08:34:07.274754: Current learning rate: 0.00784 
2025-11-22 08:35:48.445151: train_loss -0.1952 
2025-11-22 08:35:48.445419: val_loss -0.1714 
2025-11-22 08:35:48.445645: Pseudo dice [0.6052, 0.364, 0.6294, 0.0123, 0.0, 0.56, 0.9029, 0.8225] 
2025-11-22 08:35:48.445833: Epoch time: 101.17 s 
2025-11-22 08:35:50.216422:  
2025-11-22 08:35:50.216625: Epoch 238 
2025-11-22 08:35:50.216813: Current learning rate: 0.00783 
2025-11-22 08:37:30.944514: train_loss -0.2209 
2025-11-22 08:37:30.944795: val_loss -0.1771 
2025-11-22 08:37:30.945037: Pseudo dice [0.0036, 0.6414, 0.3402, 0.7279, 0.4466, 0.0023, 0.8979, 0.7286] 
2025-11-22 08:37:30.945181: Epoch time: 100.73 s 
2025-11-22 08:37:32.872344:  
2025-11-22 08:37:32.872733: Epoch 239 
2025-11-22 08:37:32.872947: Current learning rate: 0.00782 
2025-11-22 08:39:13.705260: train_loss -0.218 
2025-11-22 08:39:13.705558: val_loss -0.1659 
2025-11-22 08:39:13.705752: Pseudo dice [0.0122, 0.6963, 0.4815, 0.0, 0.0, 0.7577, 0.9062, 0.7428] 
2025-11-22 08:39:13.705928: Epoch time: 100.83 s 
2025-11-22 08:39:15.470128:  
2025-11-22 08:39:15.470550: Epoch 240 
2025-11-22 08:39:15.470744: Current learning rate: 0.00781 
2025-11-22 08:40:56.376701: train_loss -0.2089 
2025-11-22 08:40:56.377016: val_loss -0.1723 
2025-11-22 08:40:56.377251: Pseudo dice [0.6146, 0.0002, 0.4486, 0.2571, 0.6656, 0.0981, 0.8518, 0.8083] 
2025-11-22 08:40:56.377410: Epoch time: 100.91 s 
2025-11-22 08:40:58.201490:  
2025-11-22 08:40:58.201836: Epoch 241 
2025-11-22 08:40:58.202006: Current learning rate: 0.0078 
2025-11-22 08:42:38.780541: train_loss -0.1985 
2025-11-22 08:42:38.780789: val_loss -0.1568 
2025-11-22 08:42:38.780979: Pseudo dice [0.5384, 0.1241, 0.0, 0.6278, 0.3899, 0.6775, 0.8385, 0.7846] 
2025-11-22 08:42:38.781124: Epoch time: 100.58 s 
2025-11-22 08:42:40.610108:  
2025-11-22 08:42:40.610426: Epoch 242 
2025-11-22 08:42:40.610598: Current learning rate: 0.00779 
2025-11-22 08:44:21.542136: train_loss -0.2089 
2025-11-22 08:44:21.542423: val_loss -0.2059 
2025-11-22 08:44:21.542719: Pseudo dice [0.0, 0.7367, 0.6415, 0.0, 0.0, 0.8431, 0.8936, 0.8626] 
2025-11-22 08:44:21.542889: Epoch time: 100.93 s 
2025-11-22 08:44:21.543017: Yayy! New best EMA pseudo Dice: 0.464 
2025-11-22 08:44:24.489146:  
2025-11-22 08:44:24.489503: Epoch 243 
2025-11-22 08:44:24.489682: Current learning rate: 0.00778 
2025-11-22 08:46:05.600812: train_loss -0.2185 
2025-11-22 08:46:05.601268: val_loss -0.1638 
2025-11-22 08:46:05.601430: Pseudo dice [0.0, 0.673, 0.0003, 0.4682, 0.0, 0.7107, 0.889, 0.8108] 
2025-11-22 08:46:05.601553: Epoch time: 101.11 s 
2025-11-22 08:46:07.856069:  
2025-11-22 08:46:07.856361: Epoch 244 
2025-11-22 08:46:07.856518: Current learning rate: 0.00777 
2025-11-22 08:47:49.353969: train_loss -0.2147 
2025-11-22 08:47:49.354198: val_loss -0.1727 
2025-11-22 08:47:49.354403: Pseudo dice [0.7306, 0.0006, 0.5404, 0.0, 0.0, 0.7166, 0.8976, 0.7847] 
2025-11-22 08:47:49.354538: Epoch time: 101.5 s 
2025-11-22 08:47:51.186512:  
2025-11-22 08:47:51.186809: Epoch 245 
2025-11-22 08:47:51.186980: Current learning rate: 0.00777 
2025-11-22 08:49:32.455380: train_loss -0.2019 
2025-11-22 08:49:32.455689: val_loss -0.2022 
2025-11-22 08:49:32.455919: Pseudo dice [0.0, 0.5661, 0.5059, 0.0403, 0.6268, 0.0022, 0.8854, 0.8199] 
2025-11-22 08:49:32.456078: Epoch time: 101.27 s 
2025-11-22 08:49:34.675867:  
2025-11-22 08:49:34.676190: Epoch 246 
2025-11-22 08:49:34.676346: Current learning rate: 0.00776 
2025-11-22 08:51:16.079028: train_loss -0.2091 
2025-11-22 08:51:16.079302: val_loss -0.1848 
2025-11-22 08:51:16.079509: Pseudo dice [0.6719, 0.0, 0.3631, 0.7683, 0.7515, 0.0, 0.8993, 0.8133] 
2025-11-22 08:51:16.079752: Epoch time: 101.41 s 
2025-11-22 08:51:16.079909: Yayy! New best EMA pseudo Dice: 0.4661 
2025-11-22 08:51:19.096111:  
2025-11-22 08:51:19.096250: Epoch 247 
2025-11-22 08:51:19.096401: Current learning rate: 0.00775 
2025-11-22 08:53:00.678199: train_loss -0.2084 
2025-11-22 08:53:00.678561: val_loss -0.1816 
2025-11-22 08:53:00.678802: Pseudo dice [0.5568, 0.1067, 0.5937, 0.0, 0.6253, 0.0, 0.8876, 0.8064] 
2025-11-22 08:53:00.679012: Epoch time: 101.58 s 
2025-11-22 08:53:02.635500:  
2025-11-22 08:53:02.635844: Epoch 248 
2025-11-22 08:53:02.636035: Current learning rate: 0.00774 
2025-11-22 08:54:43.922895: train_loss -0.2205 
2025-11-22 08:54:43.923233: val_loss -0.1501 
2025-11-22 08:54:43.923444: Pseudo dice [0.0, 0.5589, 0.0, 0.4561, 0.0, 0.4783, 0.8865, 0.8029] 
2025-11-22 08:54:43.923566: Epoch time: 101.29 s 
2025-11-22 08:54:46.674428:  
2025-11-22 08:54:46.674783: Epoch 249 
2025-11-22 08:54:46.674992: Current learning rate: 0.00773 
2025-11-22 08:56:28.295844: train_loss -0.2105 
2025-11-22 08:56:28.296146: val_loss -0.1658 
2025-11-22 08:56:28.296300: Pseudo dice [0.5095, 0.0386, 0.0002, 0.5833, 0.6629, 0.0, 0.8205, 0.8106] 
2025-11-22 08:56:28.296404: Epoch time: 101.62 s 
2025-11-22 08:56:31.465406:  
2025-11-22 08:56:31.465808: Epoch 250 
2025-11-22 08:56:31.465982: Current learning rate: 0.00772 
2025-11-22 08:58:12.602953: train_loss -0.2068 
2025-11-22 08:58:12.603409: val_loss -0.1603 
2025-11-22 08:58:12.603614: Pseudo dice [0.6077, 0.0036, 0.5349, 0.0, 0.7023, 0.0047, 0.8746, 0.7705] 
2025-11-22 08:58:12.603740: Epoch time: 101.14 s 
2025-11-22 08:58:14.474636:  
2025-11-22 08:58:14.475024: Epoch 251 
2025-11-22 08:58:14.475192: Current learning rate: 0.00771 
2025-11-22 08:59:55.555088: train_loss -0.2094 
2025-11-22 08:59:55.555356: val_loss -0.1789 
2025-11-22 08:59:55.555635: Pseudo dice [0.6366, 0.0001, 0.5876, 0.0359, 0.4593, 0.0, 0.8599, 0.8446] 
2025-11-22 08:59:55.555818: Epoch time: 101.08 s 
2025-11-22 08:59:57.360234:  
2025-11-22 08:59:57.360579: Epoch 252 
2025-11-22 08:59:57.360745: Current learning rate: 0.0077 
2025-11-22 09:01:38.552418: train_loss -0.2046 
2025-11-22 09:01:38.552647: val_loss -0.1711 
2025-11-22 09:01:38.552861: Pseudo dice [0.4829, 0.0013, 0.0, 0.7488, 0.507, 0.0, 0.8946, 0.8084] 
2025-11-22 09:01:38.552996: Epoch time: 101.19 s 
2025-11-22 09:01:40.794497:  
2025-11-22 09:01:40.794908: Epoch 253 
2025-11-22 09:01:40.795102: Current learning rate: 0.00769 
2025-11-22 09:03:21.501361: train_loss -0.2112 
2025-11-22 09:03:21.501607: val_loss -0.1773 
2025-11-22 09:03:21.501857: Pseudo dice [0.1752, 0.6637, 0.0, 0.4691, 0.6049, 0.2213, 0.9063, 0.8252] 
2025-11-22 09:03:21.502101: Epoch time: 100.71 s 
2025-11-22 09:03:23.692795:  
2025-11-22 09:03:23.693270: Epoch 254 
2025-11-22 09:03:23.693455: Current learning rate: 0.00768 
2025-11-22 09:05:04.752710: train_loss -0.1977 
2025-11-22 09:05:04.752966: val_loss -0.1873 
2025-11-22 09:05:04.753148: Pseudo dice [0.0, 0.674, 0.4985, 0.0557, 0.597, 0.1476, 0.8891, 0.8464] 
2025-11-22 09:05:04.753266: Epoch time: 101.06 s 
2025-11-22 09:05:06.886372:  
2025-11-22 09:05:06.886722: Epoch 255 
2025-11-22 09:05:06.886923: Current learning rate: 0.00767 
2025-11-22 09:06:48.105009: train_loss -0.201 
2025-11-22 09:06:48.105323: val_loss -0.1685 
2025-11-22 09:06:48.105549: Pseudo dice [0.6019, 0.1362, 0.1667, 0.6032, 0.5598, 0.0258, 0.8594, 0.8618] 
2025-11-22 09:06:48.105855: Epoch time: 101.22 s 
2025-11-22 09:06:50.346498:  
2025-11-22 09:06:50.346879: Epoch 256 
2025-11-22 09:06:50.347043: Current learning rate: 0.00766 
2025-11-22 09:08:31.249810: train_loss -0.2065 
2025-11-22 09:08:31.250086: val_loss -0.172 
2025-11-22 09:08:31.250321: Pseudo dice [0.6118, 0.0049, 0.4012, 0.448, 0.4258, 0.4663, 0.8882, 0.8144] 
2025-11-22 09:08:31.250458: Epoch time: 100.91 s 
2025-11-22 09:08:33.096305:  
2025-11-22 09:08:33.096681: Epoch 257 
2025-11-22 09:08:33.096883: Current learning rate: 0.00765 
2025-11-22 09:10:14.179996: train_loss -0.2151 
2025-11-22 09:10:14.180267: val_loss -0.1801 
2025-11-22 09:10:14.180537: Pseudo dice [0.0011, 0.7849, 0.0014, 0.6809, 0.4231, 0.6792, 0.8463, 0.7322] 
2025-11-22 09:10:14.180690: Epoch time: 101.09 s 
2025-11-22 09:10:14.180811: Yayy! New best EMA pseudo Dice: 0.4664 
2025-11-22 09:10:17.286330:  
2025-11-22 09:10:17.286646: Epoch 258 
2025-11-22 09:10:17.286823: Current learning rate: 0.00764 
2025-11-22 09:11:58.863758: train_loss -0.2123 
2025-11-22 09:11:58.864202: val_loss -0.1691 
2025-11-22 09:11:58.864455: Pseudo dice [0.0, 0.699, 0.6745, 0.0045, 0.0, 0.5899, 0.8249, 0.7829] 
2025-11-22 09:11:58.864575: Epoch time: 101.58 s 
2025-11-22 09:12:00.730429:  
2025-11-22 09:12:00.730787: Epoch 259 
2025-11-22 09:12:00.730952: Current learning rate: 0.00764 
2025-11-22 09:13:42.237744: train_loss -0.2037 
2025-11-22 09:13:42.238169: val_loss -0.15 
2025-11-22 09:13:42.238389: Pseudo dice [0.4833, 0.3693, 0.0, 0.5455, 0.0, 0.6312, 0.878, 0.7553] 
2025-11-22 09:13:42.238541: Epoch time: 101.51 s 
2025-11-22 09:13:43.984113:  
2025-11-22 09:13:43.984444: Epoch 260 
2025-11-22 09:13:43.984621: Current learning rate: 0.00763 
2025-11-22 09:15:25.097968: train_loss -0.1977 
2025-11-22 09:15:25.098242: val_loss -0.168 
2025-11-22 09:15:25.098477: Pseudo dice [0.6178, 0.0008, 0.0037, 0.6238, 0.4027, 0.0145, 0.8829, 0.7696] 
2025-11-22 09:15:25.098629: Epoch time: 101.12 s 
2025-11-22 09:15:26.964954:  
2025-11-22 09:15:26.965292: Epoch 261 
2025-11-22 09:15:26.965489: Current learning rate: 0.00762 
2025-11-22 09:17:07.812331: train_loss -0.208 
2025-11-22 09:17:07.812633: val_loss -0.1564 
2025-11-22 09:17:07.812881: Pseudo dice [0.4238, 0.2768, 0.004, 0.7251, 0.0, 0.6973, 0.8883, 0.7476] 
2025-11-22 09:17:07.813042: Epoch time: 100.85 s 
2025-11-22 09:17:09.744940:  
2025-11-22 09:17:09.745270: Epoch 262 
2025-11-22 09:17:09.745464: Current learning rate: 0.00761 
2025-11-22 09:18:50.829490: train_loss -0.2001 
2025-11-22 09:18:50.829910: val_loss -0.1938 
2025-11-22 09:18:50.830128: Pseudo dice [0.6115, 0.1296, 0.5785, 0.0, 0.0, 0.7568, 0.8962, 0.8478] 
2025-11-22 09:18:50.830254: Epoch time: 101.09 s 
2025-11-22 09:18:52.674867:  
2025-11-22 09:18:52.675189: Epoch 263 
2025-11-22 09:18:52.675374: Current learning rate: 0.0076 
2025-11-22 09:20:33.344950: train_loss -0.2146 
2025-11-22 09:20:33.345228: val_loss -0.1684 
2025-11-22 09:20:33.345436: Pseudo dice [0.0031, 0.5906, 0.7438, 0.0, 0.7376, 0.0001, 0.8545, 0.7046] 
2025-11-22 09:20:33.345747: Epoch time: 100.67 s 
2025-11-22 09:20:35.172508:  
2025-11-22 09:20:35.172876: Epoch 264 
2025-11-22 09:20:35.173062: Current learning rate: 0.00759 
2025-11-22 09:22:15.973408: train_loss -0.198 
2025-11-22 09:22:15.973710: val_loss -0.1497 
2025-11-22 09:22:15.974015: Pseudo dice [0.547, 0.2087, 0.0034, 0.6519, 0.0, 0.6677, 0.8616, 0.7955] 
2025-11-22 09:22:15.974194: Epoch time: 100.8 s 
2025-11-22 09:22:18.239551:  
2025-11-22 09:22:18.239861: Epoch 265 
2025-11-22 09:22:18.240022: Current learning rate: 0.00758 
2025-11-22 09:23:59.432307: train_loss -0.2096 
2025-11-22 09:23:59.432626: val_loss -0.1463 
2025-11-22 09:23:59.432858: Pseudo dice [0.0, 0.5083, 0.0, 0.45, 0.235, 0.6821, 0.8584, 0.7855] 
2025-11-22 09:23:59.433043: Epoch time: 101.19 s 
2025-11-22 09:24:01.209498:  
2025-11-22 09:24:01.209829: Epoch 266 
2025-11-22 09:24:01.210031: Current learning rate: 0.00757 
2025-11-22 09:25:42.640221: train_loss -0.212 
2025-11-22 09:25:42.640508: val_loss -0.1632 
2025-11-22 09:25:42.640691: Pseudo dice [0.0, 0.5936, 0.0, 0.6827, 0.6427, 0.0006, 0.8774, 0.7433] 
2025-11-22 09:25:42.640843: Epoch time: 101.43 s 
2025-11-22 09:25:44.604347:  
2025-11-22 09:25:44.604665: Epoch 267 
2025-11-22 09:25:44.604866: Current learning rate: 0.00756 
2025-11-22 09:27:25.846689: train_loss -0.206 
2025-11-22 09:27:25.847024: val_loss -0.168 
2025-11-22 09:27:25.847200: Pseudo dice [0.0315, 0.6791, 0.0, 0.6717, 0.0, 0.6235, 0.8941, 0.806] 
2025-11-22 09:27:25.847374: Epoch time: 101.24 s 
2025-11-22 09:27:27.725392:  
2025-11-22 09:27:27.725700: Epoch 268 
2025-11-22 09:27:27.725886: Current learning rate: 0.00755 
2025-11-22 09:29:09.271423: train_loss -0.1876 
2025-11-22 09:29:09.271747: val_loss -0.1539 
2025-11-22 09:29:09.272045: Pseudo dice [0.0058, 0.73, 0.0, 0.65, 0.551, 0.026, 0.8576, 0.8071] 
2025-11-22 09:29:09.272175: Epoch time: 101.55 s 
2025-11-22 09:29:11.618478:  
2025-11-22 09:29:11.618838: Epoch 269 
2025-11-22 09:29:11.618989: Current learning rate: 0.00754 
2025-11-22 09:30:53.089729: train_loss -0.1938 
2025-11-22 09:30:53.090010: val_loss -0.1751 
2025-11-22 09:30:53.090238: Pseudo dice [0.6156, 0.2, 0.6967, 0.0, 0.446, 0.1193, 0.8692, 0.7817] 
2025-11-22 09:30:53.090373: Epoch time: 101.47 s 
2025-11-22 09:30:54.848644:  
2025-11-22 09:30:54.849026: Epoch 270 
2025-11-22 09:30:54.849216: Current learning rate: 0.00753 
2025-11-22 09:32:36.634903: train_loss -0.2063 
2025-11-22 09:32:36.635252: val_loss -0.168 
2025-11-22 09:32:36.635547: Pseudo dice [0.6854, 0.0143, 0.0, 0.4984, 0.0, 0.6484, 0.8342, 0.8083] 
2025-11-22 09:32:36.635712: Epoch time: 101.79 s 
2025-11-22 09:32:39.862217:  
2025-11-22 09:32:39.862440: Epoch 271 
2025-11-22 09:32:39.862677: Current learning rate: 0.00752 
2025-11-22 09:34:21.450369: train_loss -0.2049 
2025-11-22 09:34:21.450610: val_loss -0.1718 
2025-11-22 09:34:21.450836: Pseudo dice [0.6438, 0.0002, 0.0, 0.5891, 0.6302, 0.0077, 0.8554, 0.8567] 
2025-11-22 09:34:21.450965: Epoch time: 101.59 s 
2025-11-22 09:34:23.265617:  
2025-11-22 09:34:23.266068: Epoch 272 
2025-11-22 09:34:23.266261: Current learning rate: 0.00751 
2025-11-22 09:36:04.501372: train_loss -0.2086 
2025-11-22 09:36:04.501664: val_loss -0.1668 
2025-11-22 09:36:04.501896: Pseudo dice [0.6095, 0.0019, 0.7875, 0.0, 0.0, 0.5733, 0.8849, 0.8439] 
2025-11-22 09:36:04.502068: Epoch time: 101.24 s 
2025-11-22 09:36:06.419598:  
2025-11-22 09:36:06.419941: Epoch 273 
2025-11-22 09:36:06.420100: Current learning rate: 0.00751 
2025-11-22 09:37:48.337322: train_loss -0.2119 
2025-11-22 09:37:48.337583: val_loss -0.1744 
2025-11-22 09:37:48.337814: Pseudo dice [0.0, 0.5849, 0.5794, 0.0, 0.0, 0.6188, 0.9092, 0.864] 
2025-11-22 09:37:48.338297: Epoch time: 101.92 s 
2025-11-22 09:37:50.584171:  
2025-11-22 09:37:50.584430: Epoch 274 
2025-11-22 09:37:50.584626: Current learning rate: 0.0075 
2025-11-22 09:39:32.248322: train_loss -0.2159 
2025-11-22 09:39:32.248567: val_loss -0.187 
2025-11-22 09:39:32.248744: Pseudo dice [0.0, 0.6719, 0.0029, 0.6543, 0.4876, 0.0, 0.8792, 0.798] 
2025-11-22 09:39:32.248968: Epoch time: 101.67 s 
2025-11-22 09:39:34.064865:  
2025-11-22 09:39:34.065183: Epoch 275 
2025-11-22 09:39:34.065380: Current learning rate: 0.00749 
2025-11-22 09:41:15.673259: train_loss -0.212 
2025-11-22 09:41:15.673568: val_loss -0.18 
2025-11-22 09:41:15.673832: Pseudo dice [0.0, 0.6438, 0.7001, 0.0007, 0.0, 0.8047, 0.8792, 0.807] 
2025-11-22 09:41:15.674000: Epoch time: 101.61 s 
2025-11-22 09:41:17.600609:  
2025-11-22 09:41:17.600978: Epoch 276 
2025-11-22 09:41:17.601163: Current learning rate: 0.00748 
2025-11-22 09:42:59.472754: train_loss -0.2123 
2025-11-22 09:42:59.473033: val_loss -0.1966 
2025-11-22 09:42:59.473222: Pseudo dice [0.0016, 0.6657, 0.5754, 0.0, 0.0, 0.7176, 0.9105, 0.8555] 
2025-11-22 09:42:59.473381: Epoch time: 101.87 s 
2025-11-22 09:43:01.665876:  
2025-11-22 09:43:01.666253: Epoch 277 
2025-11-22 09:43:01.666442: Current learning rate: 0.00747 
2025-11-22 09:44:43.514295: train_loss -0.2136 
2025-11-22 09:44:43.514515: val_loss -0.1458 
2025-11-22 09:44:43.514711: Pseudo dice [0.0, 0.6487, 0.4708, 0.0, 0.5694, 0.0, 0.8734, 0.7568] 
2025-11-22 09:44:43.514868: Epoch time: 101.85 s 
2025-11-22 09:44:45.782677:  
2025-11-22 09:44:45.782974: Epoch 278 
2025-11-22 09:44:45.783153: Current learning rate: 0.00746 
2025-11-22 09:46:27.381084: train_loss -0.2175 
2025-11-22 09:46:27.381425: val_loss -0.1539 
2025-11-22 09:46:27.381678: Pseudo dice [0.5886, 0.0, 0.6408, 0.0, 0.5932, 0.0, 0.8889, 0.8316] 
2025-11-22 09:46:27.381927: Epoch time: 101.6 s 
2025-11-22 09:46:29.341213:  
2025-11-22 09:46:29.341557: Epoch 279 
2025-11-22 09:46:29.341720: Current learning rate: 0.00745 
2025-11-22 09:48:11.482105: train_loss -0.212 
2025-11-22 09:48:11.482480: val_loss -0.1999 
2025-11-22 09:48:11.482681: Pseudo dice [0.628, 0.0776, 0.0, 0.7533, 0.0, 0.7263, 0.9141, 0.8151] 
2025-11-22 09:48:11.482865: Epoch time: 102.14 s 
2025-11-22 09:48:13.306804:  
2025-11-22 09:48:13.307010: Epoch 280 
2025-11-22 09:48:13.307163: Current learning rate: 0.00744 
2025-11-22 09:49:54.750503: train_loss -0.2195 
2025-11-22 09:49:54.750812: val_loss -0.2046 
2025-11-22 09:49:54.751110: Pseudo dice [0.6853, 0.0003, 0.4419, 0.3692, 0.4267, 0.5086, 0.8809, 0.8549] 
2025-11-22 09:49:54.751245: Epoch time: 101.44 s 
2025-11-22 09:49:56.846730:  
2025-11-22 09:49:56.846981: Epoch 281 
2025-11-22 09:49:56.847218: Current learning rate: 0.00743 
2025-11-22 09:51:38.366499: train_loss -0.221 
2025-11-22 09:51:38.366736: val_loss -0.1417 
2025-11-22 09:51:38.366969: Pseudo dice [0.6392, 0.001, 0.5553, 0.4054, 0.6017, 0.0, 0.8644, 0.7428] 
2025-11-22 09:51:38.367116: Epoch time: 101.52 s 
2025-11-22 09:51:40.347189:  
2025-11-22 09:51:40.347565: Epoch 282 
2025-11-22 09:51:40.347734: Current learning rate: 0.00742 
2025-11-22 09:53:22.109504: train_loss -0.2143 
2025-11-22 09:53:22.109781: val_loss -0.1962 
2025-11-22 09:53:22.110171: Pseudo dice [0.5677, 0.0016, 0.0, 0.7227, 0.5315, 0.0, 0.872, 0.8112] 
2025-11-22 09:53:22.110316: Epoch time: 101.76 s 
2025-11-22 09:53:23.904259:  
2025-11-22 09:53:23.904623: Epoch 283 
2025-11-22 09:53:23.904819: Current learning rate: 0.00741 
2025-11-22 09:55:05.640944: train_loss -0.2133 
2025-11-22 09:55:05.641293: val_loss -0.1886 
2025-11-22 09:55:05.641484: Pseudo dice [0.4733, 0.6484, 0.0032, 0.5284, 0.0, 0.5753, 0.8586, 0.8061] 
2025-11-22 09:55:05.641614: Epoch time: 101.74 s 
2025-11-22 09:55:07.593003:  
2025-11-22 09:55:07.593341: Epoch 284 
2025-11-22 09:55:07.593560: Current learning rate: 0.0074 
2025-11-22 09:56:49.255244: train_loss -0.2027 
2025-11-22 09:56:49.255494: val_loss -0.1803 
2025-11-22 09:56:49.255733: Pseudo dice [0.6389, 0.0107, 0.0008, 0.6182, 0.4682, 0.0082, 0.8859, 0.7886] 
2025-11-22 09:56:49.255925: Epoch time: 101.66 s 
2025-11-22 09:56:50.986675:  
2025-11-22 09:56:50.987021: Epoch 285 
2025-11-22 09:56:50.987194: Current learning rate: 0.00739 
2025-11-22 09:58:32.806337: train_loss -0.203 
2025-11-22 09:58:32.806611: val_loss -0.162 
2025-11-22 09:58:32.806881: Pseudo dice [0.0, 0.5703, 0.0075, 0.6628, 0.3781, 0.0073, 0.8453, 0.8225] 
2025-11-22 09:58:32.807170: Epoch time: 101.82 s 
2025-11-22 09:58:34.924239:  
2025-11-22 09:58:34.924545: Epoch 286 
2025-11-22 09:58:34.924729: Current learning rate: 0.00738 
2025-11-22 10:00:16.479912: train_loss -0.2004 
2025-11-22 10:00:16.480322: val_loss -0.182 
2025-11-22 10:00:16.480516: Pseudo dice [0.5882, 0.2259, 0.0093, 0.6658, 0.7121, 0.0, 0.8376, 0.7896] 
2025-11-22 10:00:16.480645: Epoch time: 101.56 s 
2025-11-22 10:00:18.298922:  
2025-11-22 10:00:18.299320: Epoch 287 
2025-11-22 10:00:18.299494: Current learning rate: 0.00738 
2025-11-22 10:01:59.939898: train_loss -0.2162 
2025-11-22 10:01:59.940130: val_loss -0.1952 
2025-11-22 10:01:59.940352: Pseudo dice [0.0, 0.7476, 0.5409, 0.3525, 0.4738, 0.0263, 0.8817, 0.8338] 
2025-11-22 10:01:59.940610: Epoch time: 101.64 s 
2025-11-22 10:02:01.743380:  
2025-11-22 10:02:01.743750: Epoch 288 
2025-11-22 10:02:01.743961: Current learning rate: 0.00737 
2025-11-22 10:03:43.054083: train_loss -0.2147 
2025-11-22 10:03:43.054474: val_loss -0.1698 
2025-11-22 10:03:43.054688: Pseudo dice [0.0054, 0.5458, 0.0, 0.4599, 0.0, 0.5284, 0.8997, 0.869] 
2025-11-22 10:03:43.054850: Epoch time: 101.31 s 
2025-11-22 10:03:44.967463:  
2025-11-22 10:03:44.967730: Epoch 289 
2025-11-22 10:03:44.967916: Current learning rate: 0.00736 
2025-11-22 10:05:26.574435: train_loss -0.2133 
2025-11-22 10:05:26.574736: val_loss -0.1544 
2025-11-22 10:05:26.575242: Pseudo dice [0.569, 0.0163, 0.7543, 0.0, 0.0001, 0.6528, 0.8383, 0.8219] 
2025-11-22 10:05:26.575447: Epoch time: 101.61 s 
2025-11-22 10:05:28.378177:  
2025-11-22 10:05:28.378464: Epoch 290 
2025-11-22 10:05:28.378614: Current learning rate: 0.00735 
2025-11-22 10:07:10.440412: train_loss -0.2143 
2025-11-22 10:07:10.440710: val_loss -0.1856 
2025-11-22 10:07:10.440921: Pseudo dice [0.6048, 0.002, 0.2256, 0.6148, 0.0, 0.7611, 0.8565, 0.8459] 
2025-11-22 10:07:10.441121: Epoch time: 102.06 s 
2025-11-22 10:07:12.248202:  
2025-11-22 10:07:12.248502: Epoch 291 
2025-11-22 10:07:12.248667: Current learning rate: 0.00734 
2025-11-22 10:08:53.569602: train_loss -0.2001 
2025-11-22 10:08:53.569865: val_loss -0.1746 
2025-11-22 10:08:53.570070: Pseudo dice [0.5449, 0.2881, 0.7264, 0.0, 0.4897, 0.0, 0.8991, 0.8753] 
2025-11-22 10:08:53.570212: Epoch time: 101.32 s 
2025-11-22 10:08:55.357485:  
2025-11-22 10:08:55.357755: Epoch 292 
2025-11-22 10:08:55.357945: Current learning rate: 0.00733 
2025-11-22 10:10:37.302613: train_loss -0.2095 
2025-11-22 10:10:37.302890: val_loss -0.1482 
2025-11-22 10:10:37.303214: Pseudo dice [0.6184, 0.0007, 0.0913, 0.6723, 0.5418, 0.117, 0.8109, 0.7367] 
2025-11-22 10:10:37.303414: Epoch time: 101.95 s 
2025-11-22 10:10:40.155542:  
2025-11-22 10:10:40.155853: Epoch 293 
2025-11-22 10:10:40.156036: Current learning rate: 0.00732 
2025-11-22 10:12:22.053736: train_loss -0.1952 
2025-11-22 10:12:22.054042: val_loss -0.1648 
2025-11-22 10:12:22.054279: Pseudo dice [0.6458, 0.0061, 0.0, 0.5841, 0.5152, 0.0532, 0.8752, 0.7875] 
2025-11-22 10:12:22.054413: Epoch time: 101.9 s 
2025-11-22 10:12:23.839632:  
2025-11-22 10:12:23.839994: Epoch 294 
2025-11-22 10:12:23.840176: Current learning rate: 0.00731 
2025-11-22 10:14:05.711193: train_loss -0.2162 
2025-11-22 10:14:05.711435: val_loss -0.1597 
2025-11-22 10:14:05.711668: Pseudo dice [0.5359, 0.082, 0.0001, 0.6631, 0.0, 0.503, 0.8813, 0.7979] 
2025-11-22 10:14:05.711843: Epoch time: 101.87 s 
2025-11-22 10:14:07.570372:  
2025-11-22 10:14:07.570781: Epoch 295 
2025-11-22 10:14:07.570968: Current learning rate: 0.0073 
2025-11-22 10:15:48.696382: train_loss -0.2036 
2025-11-22 10:15:48.696801: val_loss -0.1798 
2025-11-22 10:15:48.697029: Pseudo dice [0.0057, 0.5144, 0.6925, 0.0, 0.0, 0.5386, 0.9021, 0.7904] 
2025-11-22 10:15:48.697175: Epoch time: 101.13 s 
2025-11-22 10:15:50.579413:  
2025-11-22 10:15:50.579793: Epoch 296 
2025-11-22 10:15:50.579959: Current learning rate: 0.00729 
2025-11-22 10:17:31.780284: train_loss -0.2042 
2025-11-22 10:17:31.780635: val_loss -0.1467 
2025-11-22 10:17:31.780933: Pseudo dice [0.4973, 0.1283, 0.4736, 0.0, 0.5695, 0.0001, 0.7925, 0.6659] 
2025-11-22 10:17:31.781053: Epoch time: 101.2 s 
2025-11-22 10:17:34.031031:  
2025-11-22 10:17:34.031367: Epoch 297 
2025-11-22 10:17:34.031539: Current learning rate: 0.00728 
2025-11-22 10:19:14.875685: train_loss -0.2217 
2025-11-22 10:19:14.875966: val_loss -0.1928 
2025-11-22 10:19:14.876142: Pseudo dice [0.6466, 0.1016, 0.6211, 0.0, 0.0, 0.6052, 0.8691, 0.7903] 
2025-11-22 10:19:14.876266: Epoch time: 100.85 s 
2025-11-22 10:19:16.720872:  
2025-11-22 10:19:16.721194: Epoch 298 
2025-11-22 10:19:16.721385: Current learning rate: 0.00727 
2025-11-22 10:20:57.673369: train_loss -0.2095 
2025-11-22 10:20:57.673611: val_loss -0.1751 
2025-11-22 10:20:57.673858: Pseudo dice [0.5319, 0.1835, 0.0348, 0.6529, 0.4675, 0.0016, 0.8596, 0.7135] 
2025-11-22 10:20:57.673995: Epoch time: 100.95 s 
2025-11-22 10:20:59.457596:  
2025-11-22 10:20:59.457905: Epoch 299 
2025-11-22 10:20:59.458085: Current learning rate: 0.00726 
2025-11-22 10:22:40.958863: train_loss -0.1958 
2025-11-22 10:22:40.959204: val_loss -0.1597 
2025-11-22 10:22:40.959396: Pseudo dice [0.5887, 0.0098, 0.0, 0.5929, 0.6349, 0.0007, 0.855, 0.7697] 
2025-11-22 10:22:40.959556: Epoch time: 101.5 s 
2025-11-22 10:22:44.341652:  
2025-11-22 10:22:44.341999: Epoch 300 
2025-11-22 10:22:44.342157: Current learning rate: 0.00725 
2025-11-22 10:24:25.415709: train_loss -0.1959 
2025-11-22 10:24:25.416105: val_loss -0.1596 
2025-11-22 10:24:25.416381: Pseudo dice [0.0151, 0.5556, 0.0, 0.6672, 0.0, 0.7958, 0.8376, 0.7966] 
2025-11-22 10:24:25.416554: Epoch time: 101.08 s 
2025-11-22 10:24:27.307702:  
2025-11-22 10:24:27.308020: Epoch 301 
2025-11-22 10:24:27.308181: Current learning rate: 0.00724 
2025-11-22 10:26:08.261709: train_loss -0.203 
2025-11-22 10:26:08.261944: val_loss -0.1574 
2025-11-22 10:26:08.262160: Pseudo dice [0.7617, 0.0033, 0.5578, 0.0, 0.6857, 0.0, 0.8554, 0.7432] 
2025-11-22 10:26:08.262318: Epoch time: 100.96 s 
2025-11-22 10:26:10.257180:  
2025-11-22 10:26:10.257510: Epoch 302 
2025-11-22 10:26:10.257677: Current learning rate: 0.00724 
2025-11-22 10:27:51.099223: train_loss -0.2122 
2025-11-22 10:27:51.099422: val_loss -0.2 
2025-11-22 10:27:51.099579: Pseudo dice [0.6354, 0.0042, 0.0195, 0.7043, 0.0, 0.637, 0.8839, 0.8211] 
2025-11-22 10:27:51.099728: Epoch time: 100.84 s 
2025-11-22 10:27:53.139611:  
2025-11-22 10:27:53.139920: Epoch 303 
2025-11-22 10:27:53.140107: Current learning rate: 0.00723 
2025-11-22 10:29:34.211560: train_loss -0.2047 
2025-11-22 10:29:34.211926: val_loss -0.161 
2025-11-22 10:29:34.212140: Pseudo dice [0.0, 0.7053, 0.6492, 0.0, 0.7813, 0.0, 0.8757, 0.7727] 
2025-11-22 10:29:34.212290: Epoch time: 101.07 s 
2025-11-22 10:29:36.011441:  
2025-11-22 10:29:36.011756: Epoch 304 
2025-11-22 10:29:36.011950: Current learning rate: 0.00722 
2025-11-22 10:31:17.287833: train_loss -0.2119 
2025-11-22 10:31:17.288078: val_loss -0.1553 
2025-11-22 10:31:17.288267: Pseudo dice [0.6736, 0.0415, 0.0011, 0.5919, 0.0, 0.5485, 0.8281, 0.7628] 
2025-11-22 10:31:17.288409: Epoch time: 101.28 s 
2025-11-22 10:31:19.122685:  
2025-11-22 10:31:19.123025: Epoch 305 
2025-11-22 10:31:19.123205: Current learning rate: 0.00721 
2025-11-22 10:33:00.192291: train_loss -0.2073 
2025-11-22 10:33:00.192734: val_loss -0.1637 
2025-11-22 10:33:00.193032: Pseudo dice [0.0361, 0.6332, 0.002, 0.602, 0.0472, 0.6668, 0.9034, 0.8038] 
2025-11-22 10:33:00.193187: Epoch time: 101.07 s 
2025-11-22 10:33:02.486133:  
2025-11-22 10:33:02.486496: Epoch 306 
2025-11-22 10:33:02.486669: Current learning rate: 0.0072 
2025-11-22 10:34:43.555405: train_loss -0.2203 
2025-11-22 10:34:43.555739: val_loss -0.1852 
2025-11-22 10:34:43.556016: Pseudo dice [0.671, 0.002, 0.7009, 0.0, 0.6618, 0.0, 0.9032, 0.8598] 
2025-11-22 10:34:43.556153: Epoch time: 101.07 s 
2025-11-22 10:34:45.502210:  
2025-11-22 10:34:45.502585: Epoch 307 
2025-11-22 10:34:45.502755: Current learning rate: 0.00719 
2025-11-22 10:36:26.467321: train_loss -0.2044 
2025-11-22 10:36:26.467806: val_loss -0.1719 
2025-11-22 10:36:26.468049: Pseudo dice [0.6852, 0.001, 0.5567, 0.3619, 0.5555, 0.0, 0.8717, 0.7581] 
2025-11-22 10:36:26.468188: Epoch time: 100.97 s 
2025-11-22 10:36:28.400514:  
2025-11-22 10:36:28.400860: Epoch 308 
2025-11-22 10:36:28.401050: Current learning rate: 0.00718 
2025-11-22 10:38:09.816184: train_loss -0.2101 
2025-11-22 10:38:09.816430: val_loss -0.1978 
2025-11-22 10:38:09.816639: Pseudo dice [0.0, 0.6244, 0.0, 0.4881, 0.0, 0.8613, 0.8986, 0.7971] 
2025-11-22 10:38:09.816840: Epoch time: 101.42 s 
2025-11-22 10:38:11.941222:  
2025-11-22 10:38:11.941365: Epoch 309 
2025-11-22 10:38:11.941533: Current learning rate: 0.00717 
2025-11-22 10:39:53.454079: train_loss -0.2001 
2025-11-22 10:39:53.454373: val_loss -0.1667 
2025-11-22 10:39:53.454595: Pseudo dice [0.6443, 0.0006, 0.5458, 0.0, 0.4786, 0.0251, 0.8669, 0.8266] 
2025-11-22 10:39:53.454757: Epoch time: 101.51 s 
2025-11-22 10:39:55.248898:  
2025-11-22 10:39:55.249210: Epoch 310 
2025-11-22 10:39:55.249369: Current learning rate: 0.00716 
2025-11-22 10:41:36.883911: train_loss -0.198 
2025-11-22 10:41:36.884282: val_loss -0.1464 
2025-11-22 10:41:36.884553: Pseudo dice [0.5076, 0.0027, 0.5282, 0.0, 0.5105, 0.0, 0.8542, 0.7359] 
2025-11-22 10:41:36.884731: Epoch time: 101.64 s 
2025-11-22 10:41:38.689542:  
2025-11-22 10:41:38.689854: Epoch 311 
2025-11-22 10:41:38.690019: Current learning rate: 0.00715 
2025-11-22 10:43:20.068226: train_loss -0.213 
2025-11-22 10:43:20.068483: val_loss -0.1836 
2025-11-22 10:43:20.068694: Pseudo dice [0.2452, 0.6023, 0.0, 0.5057, 0.0, 0.802, 0.8754, 0.8102] 
2025-11-22 10:43:20.068896: Epoch time: 101.38 s 
2025-11-22 10:43:22.254212:  
2025-11-22 10:43:22.254462: Epoch 312 
2025-11-22 10:43:22.254640: Current learning rate: 0.00714 
2025-11-22 10:45:03.101751: train_loss -0.2041 
2025-11-22 10:45:03.102157: val_loss -0.1736 
2025-11-22 10:45:03.102402: Pseudo dice [0.6655, 0.0129, 0.0261, 0.5357, 0.0, 0.5857, 0.879, 0.8445] 
2025-11-22 10:45:03.102606: Epoch time: 100.85 s 
2025-11-22 10:45:04.898406:  
2025-11-22 10:45:04.898738: Epoch 313 
2025-11-22 10:45:04.898927: Current learning rate: 0.00713 
2025-11-22 10:46:46.330281: train_loss -0.211 
2025-11-22 10:46:46.330631: val_loss -0.1458 
2025-11-22 10:46:46.330861: Pseudo dice [0.0002, 0.6628, 0.0664, 0.6806, 0.0, 0.4639, 0.8204, 0.7858] 
2025-11-22 10:46:46.331046: Epoch time: 101.43 s 
2025-11-22 10:46:49.252117:  
2025-11-22 10:46:49.252462: Epoch 314 
2025-11-22 10:46:49.252662: Current learning rate: 0.00712 
2025-11-22 10:48:31.140977: train_loss -0.205 
2025-11-22 10:48:31.141199: val_loss -0.1326 
2025-11-22 10:48:31.141418: Pseudo dice [0.6417, 0.038, 0.0, 0.5641, 0.0, 0.727, 0.8303, 0.6518] 
2025-11-22 10:48:31.141537: Epoch time: 101.89 s 
2025-11-22 10:48:33.301988:  
2025-11-22 10:48:33.302214: Epoch 315 
2025-11-22 10:48:33.302395: Current learning rate: 0.00711 
2025-11-22 10:50:14.132238: train_loss -0.2078 
2025-11-22 10:50:14.132464: val_loss -0.151 
2025-11-22 10:50:14.132865: Pseudo dice [0.6043, 0.0087, 0.018, 0.5303, 0.6241, 0.0, 0.8595, 0.7859] 
2025-11-22 10:50:14.133099: Epoch time: 100.83 s 
2025-11-22 10:50:15.926281:  
2025-11-22 10:50:15.926539: Epoch 316 
2025-11-22 10:50:15.926692: Current learning rate: 0.0071 
2025-11-22 10:51:57.417855: train_loss -0.2039 
2025-11-22 10:51:57.418095: val_loss -0.156 
2025-11-22 10:51:57.418324: Pseudo dice [0.0, 0.6392, 0.0, 0.6885, 0.7912, 0.0001, 0.8145, 0.7948] 
2025-11-22 10:51:57.418622: Epoch time: 101.49 s 
2025-11-22 10:51:59.495837:  
2025-11-22 10:51:59.496151: Epoch 317 
2025-11-22 10:51:59.496312: Current learning rate: 0.0071 
2025-11-22 10:53:40.771647: train_loss -0.1865 
2025-11-22 10:53:40.771992: val_loss -0.1601 
2025-11-22 10:53:40.772224: Pseudo dice [0.0, 0.7492, 0.0005, 0.7042, 0.0, 0.6643, 0.8906, 0.7635] 
2025-11-22 10:53:40.772465: Epoch time: 101.28 s 
2025-11-22 10:53:43.120361:  
2025-11-22 10:53:43.120697: Epoch 318 
2025-11-22 10:53:43.120856: Current learning rate: 0.00709 
2025-11-22 10:55:24.552357: train_loss -0.1969 
2025-11-22 10:55:24.552621: val_loss -0.1523 
2025-11-22 10:55:24.552847: Pseudo dice [0.005, 0.7143, 0.0009, 0.6224, 0.4521, 0.0535, 0.8565, 0.7825] 
2025-11-22 10:55:24.552982: Epoch time: 101.43 s 
2025-11-22 10:55:26.345914:  
2025-11-22 10:55:26.346124: Epoch 319 
2025-11-22 10:55:26.346375: Current learning rate: 0.00708 
2025-11-22 10:57:08.131379: train_loss -0.2089 
2025-11-22 10:57:08.131659: val_loss -0.1839 
2025-11-22 10:57:08.131895: Pseudo dice [0.6883, 0.1211, 0.6742, 0.0, 0.0, 0.5325, 0.904, 0.83] 
2025-11-22 10:57:08.132031: Epoch time: 101.79 s 
2025-11-22 10:57:10.469920:  
2025-11-22 10:57:10.470404: Epoch 320 
2025-11-22 10:57:10.470593: Current learning rate: 0.00707 
2025-11-22 10:58:51.831076: train_loss -0.2083 
2025-11-22 10:58:51.831348: val_loss -0.1703 
2025-11-22 10:58:51.831519: Pseudo dice [0.7081, 0.0016, 0.7404, 0.0, 0.4, 0.3773, 0.8796, 0.738] 
2025-11-22 10:58:51.831626: Epoch time: 101.36 s 
2025-11-22 10:58:53.681985:  
2025-11-22 10:58:53.682353: Epoch 321 
2025-11-22 10:58:53.682531: Current learning rate: 0.00706 
2025-11-22 11:00:35.242343: train_loss -0.2169 
2025-11-22 11:00:35.242611: val_loss -0.1441 
2025-11-22 11:00:35.242837: Pseudo dice [0.0057, 0.5857, 0.6489, 0.0148, 0.0, 0.7188, 0.8842, 0.768] 
2025-11-22 11:00:35.242962: Epoch time: 101.56 s 
2025-11-22 11:00:37.089324:  
2025-11-22 11:00:37.089665: Epoch 322 
2025-11-22 11:00:37.089848: Current learning rate: 0.00705 
2025-11-22 11:02:18.709083: train_loss -0.2118 
2025-11-22 11:02:18.709284: val_loss -0.1903 
2025-11-22 11:02:18.709447: Pseudo dice [0.5524, 0.0007, 0.652, 0.1107, 0.5826, 0.0, 0.9112, 0.8321] 
2025-11-22 11:02:18.709567: Epoch time: 101.62 s 
2025-11-22 11:02:20.509505:  
2025-11-22 11:02:20.509887: Epoch 323 
2025-11-22 11:02:20.510054: Current learning rate: 0.00704 
2025-11-22 11:04:02.099893: train_loss -0.2119 
2025-11-22 11:04:02.100110: val_loss -0.1564 
2025-11-22 11:04:02.100337: Pseudo dice [0.6674, 0.0181, 0.1421, 0.5553, 0.5518, 0.0564, 0.8326, 0.717] 
2025-11-22 11:04:02.100475: Epoch time: 101.59 s 
2025-11-22 11:04:03.988546:  
2025-11-22 11:04:03.988899: Epoch 324 
2025-11-22 11:04:03.989074: Current learning rate: 0.00703 
2025-11-22 11:05:45.426136: train_loss -0.2119 
2025-11-22 11:05:45.426342: val_loss -0.157 
2025-11-22 11:05:45.426743: Pseudo dice [0.0001, 0.6008, 0.6625, 0.0, 0.2734, 0.3179, 0.8919, 0.7764] 
2025-11-22 11:05:45.426927: Epoch time: 101.44 s 
2025-11-22 11:05:47.348313:  
2025-11-22 11:05:47.348644: Epoch 325 
2025-11-22 11:05:47.348854: Current learning rate: 0.00702 
2025-11-22 11:07:28.920352: train_loss -0.2172 
2025-11-22 11:07:28.920624: val_loss -0.1603 
2025-11-22 11:07:28.920909: Pseudo dice [0.0, 0.506, 0.698, 0.0031, 0.0, 0.6582, 0.8459, 0.7856] 
2025-11-22 11:07:28.921107: Epoch time: 101.57 s 
2025-11-22 11:07:30.790535:  
2025-11-22 11:07:30.790885: Epoch 326 
2025-11-22 11:07:30.791078: Current learning rate: 0.00701 
2025-11-22 11:09:12.387890: train_loss -0.2209 
2025-11-22 11:09:12.388140: val_loss -0.1768 
2025-11-22 11:09:12.388355: Pseudo dice [0.5266, 0.0111, 0.5038, 0.0, 0.0, 0.8186, 0.8815, 0.7891] 
2025-11-22 11:09:12.388683: Epoch time: 101.6 s 
2025-11-22 11:09:14.292602:  
2025-11-22 11:09:14.292920: Epoch 327 
2025-11-22 11:09:14.293086: Current learning rate: 0.007 
2025-11-22 11:10:55.673168: train_loss -0.2285 
2025-11-22 11:10:55.673422: val_loss -0.1815 
2025-11-22 11:10:55.673595: Pseudo dice [0.3845, 0.3639, 0.0, 0.7055, 0.5138, 0.4671, 0.8723, 0.7507] 
2025-11-22 11:10:55.673706: Epoch time: 101.38 s 
2025-11-22 11:10:57.564692:  
2025-11-22 11:10:57.565050: Epoch 328 
2025-11-22 11:10:57.565250: Current learning rate: 0.00699 
2025-11-22 11:12:38.904598: train_loss -0.2148 
2025-11-22 11:12:38.905024: val_loss -0.1604 
2025-11-22 11:12:38.905247: Pseudo dice [0.0, 0.6261, 0.0, 0.5661, 0.0, 0.4617, 0.8501, 0.7998] 
2025-11-22 11:12:38.905384: Epoch time: 101.34 s 
2025-11-22 11:12:40.744098:  
2025-11-22 11:12:40.744466: Epoch 329 
2025-11-22 11:12:40.744672: Current learning rate: 0.00698 
2025-11-22 11:14:22.287996: train_loss -0.2186 
2025-11-22 11:14:22.288285: val_loss -0.173 
2025-11-22 11:14:22.288418: Pseudo dice [0.5621, 0.4469, 0.0065, 0.531, 0.6477, 0.0082, 0.8975, 0.7823] 
2025-11-22 11:14:22.288542: Epoch time: 101.55 s 
2025-11-22 11:14:24.591667:  
2025-11-22 11:14:24.591964: Epoch 330 
2025-11-22 11:14:24.592130: Current learning rate: 0.00697 
2025-11-22 11:16:05.900983: train_loss -0.2205 
2025-11-22 11:16:05.901202: val_loss -0.1825 
2025-11-22 11:16:05.901510: Pseudo dice [0.3315, 0.6131, 0.4835, 0.0003, 0.6014, 0.0676, 0.8994, 0.843] 
2025-11-22 11:16:05.901655: Epoch time: 101.31 s 
2025-11-22 11:16:07.719947:  
2025-11-22 11:16:07.720244: Epoch 331 
2025-11-22 11:16:07.720399: Current learning rate: 0.00696 
2025-11-22 11:17:49.311626: train_loss -0.2141 
2025-11-22 11:17:49.311903: val_loss -0.1644 
2025-11-22 11:17:49.312091: Pseudo dice [0.0, 0.5555, 0.0032, 0.5748, 0.0, 0.6279, 0.9101, 0.7569] 
2025-11-22 11:17:49.312268: Epoch time: 101.59 s 
2025-11-22 11:17:51.438986:  
2025-11-22 11:17:51.439259: Epoch 332 
2025-11-22 11:17:51.439423: Current learning rate: 0.00696 
2025-11-22 11:19:32.636169: train_loss -0.2112 
2025-11-22 11:19:32.636412: val_loss -0.1672 
2025-11-22 11:19:32.636683: Pseudo dice [0.0, 0.5797, 0.0, 0.6157, 0.6059, 0.3944, 0.7552, 0.7763] 
2025-11-22 11:19:32.637149: Epoch time: 101.2 s 
2025-11-22 11:19:34.511777:  
2025-11-22 11:19:34.512062: Epoch 333 
2025-11-22 11:19:34.512217: Current learning rate: 0.00695 
2025-11-22 11:21:16.105063: train_loss -0.1943 
2025-11-22 11:21:16.105368: val_loss -0.154 
2025-11-22 11:21:16.105563: Pseudo dice [0.0, 0.5649, 0.7171, 0.0, 0.0, 0.5263, 0.9281, 0.7844] 
2025-11-22 11:21:16.105697: Epoch time: 101.59 s 
2025-11-22 11:21:17.947358:  
2025-11-22 11:21:17.947686: Epoch 334 
2025-11-22 11:21:17.947884: Current learning rate: 0.00694 
2025-11-22 11:22:59.973381: train_loss -0.2068 
2025-11-22 11:22:59.973710: val_loss -0.1702 
2025-11-22 11:22:59.973995: Pseudo dice [0.0, 0.7044, 0.6151, 0.0, 0.0, 0.6261, 0.8294, 0.8023] 
2025-11-22 11:22:59.974185: Epoch time: 102.03 s 
2025-11-22 11:23:02.690228:  
2025-11-22 11:23:02.690586: Epoch 335 
2025-11-22 11:23:02.690778: Current learning rate: 0.00693 
2025-11-22 11:24:44.482637: train_loss -0.2095 
2025-11-22 11:24:44.482940: val_loss -0.1511 
2025-11-22 11:24:44.483165: Pseudo dice [0.6791, 0.0004, 0.6371, 0.0, 0.5891, 0.0, 0.851, 0.741] 
2025-11-22 11:24:44.483412: Epoch time: 101.79 s 
2025-11-22 11:24:46.377501:  
2025-11-22 11:24:46.377852: Epoch 336 
2025-11-22 11:24:46.378038: Current learning rate: 0.00692 
2025-11-22 11:26:28.162583: train_loss -0.2138 
2025-11-22 11:26:28.162920: val_loss -0.1645 
2025-11-22 11:26:28.163130: Pseudo dice [0.6015, 0.0684, 0.0003, 0.6643, 0.5195, 0.0701, 0.8124, 0.7207] 
2025-11-22 11:26:28.163296: Epoch time: 101.79 s 
2025-11-22 11:26:29.996487:  
2025-11-22 11:26:29.996857: Epoch 337 
2025-11-22 11:26:29.997019: Current learning rate: 0.00691 
2025-11-22 11:28:12.105089: train_loss -0.2117 
2025-11-22 11:28:12.105380: val_loss -0.1708 
2025-11-22 11:28:12.105607: Pseudo dice [0.734, 0.0004, 0.5551, 0.0993, 0.0, 0.5684, 0.8494, 0.8017] 
2025-11-22 11:28:12.105743: Epoch time: 102.11 s 
2025-11-22 11:28:13.929001:  
2025-11-22 11:28:13.929320: Epoch 338 
2025-11-22 11:28:13.929488: Current learning rate: 0.0069 
2025-11-22 11:29:55.695665: train_loss -0.2243 
2025-11-22 11:29:55.695976: val_loss -0.1703 
2025-11-22 11:29:55.696176: Pseudo dice [0.6385, 0.0027, 0.5629, 0.364, 0.7143, 0.0016, 0.8734, 0.8059] 
2025-11-22 11:29:55.696411: Epoch time: 101.77 s 
2025-11-22 11:29:57.626918:  
2025-11-22 11:29:57.627286: Epoch 339 
2025-11-22 11:29:57.627449: Current learning rate: 0.00689 
2025-11-22 11:31:39.831937: train_loss -0.2154 
2025-11-22 11:31:39.832163: val_loss -0.1355 
2025-11-22 11:31:39.832356: Pseudo dice [0.7272, 0.0012, 0.5459, 0.0019, 0.6174, 0.0084, 0.7521, 0.7282] 
2025-11-22 11:31:39.832497: Epoch time: 102.21 s 
2025-11-22 11:31:41.747018:  
2025-11-22 11:31:41.747313: Epoch 340 
2025-11-22 11:31:41.747474: Current learning rate: 0.00688 
2025-11-22 11:33:23.225370: train_loss -0.2144 
2025-11-22 11:33:23.225785: val_loss -0.1779 
2025-11-22 11:33:23.226065: Pseudo dice [0.6608, 0.0003, 0.0069, 0.6713, 0.1019, 0.6068, 0.8907, 0.7926] 
2025-11-22 11:33:23.226345: Epoch time: 101.48 s 
2025-11-22 11:33:25.091782:  
2025-11-22 11:33:25.092042: Epoch 341 
2025-11-22 11:33:25.092204: Current learning rate: 0.00687 
2025-11-22 11:35:07.136408: train_loss -0.2144 
2025-11-22 11:35:07.136701: val_loss -0.1746 
2025-11-22 11:35:07.136993: Pseudo dice [0.5968, 0.0789, 0.0, 0.6422, 0.4223, 0.0052, 0.8896, 0.7808] 
2025-11-22 11:35:07.137312: Epoch time: 102.05 s 
2025-11-22 11:35:09.509306:  
2025-11-22 11:35:09.509670: Epoch 342 
2025-11-22 11:35:09.509844: Current learning rate: 0.00686 
2025-11-22 11:36:51.469485: train_loss -0.2105 
2025-11-22 11:36:51.469850: val_loss -0.165 
2025-11-22 11:36:51.470082: Pseudo dice [0.0004, 0.5901, 0.0, 0.613, 0.0, 0.6072, 0.8206, 0.8376] 
2025-11-22 11:36:51.470220: Epoch time: 101.96 s 
2025-11-22 11:36:53.368132:  
2025-11-22 11:36:53.368473: Epoch 343 
2025-11-22 11:36:53.368662: Current learning rate: 0.00685 
2025-11-22 11:38:36.117658: train_loss -0.2159 
2025-11-22 11:38:36.118145: val_loss -0.1787 
2025-11-22 11:38:36.118361: Pseudo dice [0.0, 0.5769, 0.0, 0.552, 0.6103, 0.0045, 0.8956, 0.8035] 
2025-11-22 11:38:36.118490: Epoch time: 102.75 s 
2025-11-22 11:38:38.039174:  
2025-11-22 11:38:38.039511: Epoch 344 
2025-11-22 11:38:38.039686: Current learning rate: 0.00684 
2025-11-22 11:40:20.379931: train_loss -0.2159 
2025-11-22 11:40:20.380190: val_loss -0.1767 
2025-11-22 11:40:20.380477: Pseudo dice [0.6088, 0.1078, 0.4147, 0.0, 0.5832, 0.0001, 0.8697, 0.8276] 
2025-11-22 11:40:20.380647: Epoch time: 102.34 s 
2025-11-22 11:40:22.783206:  
2025-11-22 11:40:22.783513: Epoch 345 
2025-11-22 11:40:22.783670: Current learning rate: 0.00683 
2025-11-22 11:42:04.299841: train_loss -0.2173 
2025-11-22 11:42:04.300100: val_loss -0.1586 
2025-11-22 11:42:04.300302: Pseudo dice [0.6585, 0.0737, 0.6754, 0.0, 0.7051, 0.0118, 0.8716, 0.8288] 
2025-11-22 11:42:04.300502: Epoch time: 101.52 s 
2025-11-22 11:42:06.156938:  
2025-11-22 11:42:06.157262: Epoch 346 
2025-11-22 11:42:06.157418: Current learning rate: 0.00682 
2025-11-22 11:43:47.997036: train_loss -0.2247 
2025-11-22 11:43:47.997318: val_loss -0.1947 
2025-11-22 11:43:47.997560: Pseudo dice [0.6781, 0.0009, 0.6179, 0.0, 0.4207, 0.0018, 0.8985, 0.8103] 
2025-11-22 11:43:47.997753: Epoch time: 101.84 s 
2025-11-22 11:43:50.184480:  
2025-11-22 11:43:50.184783: Epoch 347 
2025-11-22 11:43:50.184961: Current learning rate: 0.00681 
2025-11-22 11:45:31.811395: train_loss -0.2157 
2025-11-22 11:45:31.811634: val_loss -0.1535 
2025-11-22 11:45:31.811881: Pseudo dice [0.0555, 0.684, 0.5372, 0.0, 0.5301, 0.6468, 0.8748, 0.8012] 
2025-11-22 11:45:31.812026: Epoch time: 101.63 s 
2025-11-22 11:45:33.756548:  
2025-11-22 11:45:33.756869: Epoch 348 
2025-11-22 11:45:33.757044: Current learning rate: 0.0068 
2025-11-22 11:47:15.077843: train_loss -0.2003 
2025-11-22 11:47:15.078156: val_loss -0.1603 
2025-11-22 11:47:15.078446: Pseudo dice [0.6433, 0.1357, 0.6015, 0.0, 0.4667, 0.0001, 0.8788, 0.7781] 
2025-11-22 11:47:15.078644: Epoch time: 101.32 s 
2025-11-22 11:47:16.969369:  
2025-11-22 11:47:16.969652: Epoch 349 
2025-11-22 11:47:16.969827: Current learning rate: 0.0068 
2025-11-22 11:48:58.523516: train_loss -0.2119 
2025-11-22 11:48:58.523808: val_loss -0.2 
2025-11-22 11:48:58.524044: Pseudo dice [0.0282, 0.639, 0.6342, 0.0, 0.0, 0.7443, 0.8693, 0.8746] 
2025-11-22 11:48:58.524228: Epoch time: 101.56 s 
2025-11-22 11:49:01.368869:  
2025-11-22 11:49:01.369295: Epoch 350 
2025-11-22 11:49:01.369465: Current learning rate: 0.00679 
2025-11-22 11:50:43.033501: train_loss -0.2118 
2025-11-22 11:50:43.033896: val_loss -0.1789 
2025-11-22 11:50:43.034074: Pseudo dice [0.2591, 0.5654, 0.1227, 0.6571, 0.3188, 0.1911, 0.8899, 0.8409] 
2025-11-22 11:50:43.034184: Epoch time: 101.67 s 
2025-11-22 11:50:45.311182:  
2025-11-22 11:50:45.311550: Epoch 351 
2025-11-22 11:50:45.311775: Current learning rate: 0.00678 
2025-11-22 11:52:26.541902: train_loss -0.2107 
2025-11-22 11:52:26.542213: val_loss -0.1702 
2025-11-22 11:52:26.542515: Pseudo dice [0.0024, 0.6448, 0.6521, 0.0, 0.0, 0.7216, 0.8867, 0.7251] 
2025-11-22 11:52:26.542661: Epoch time: 101.23 s 
2025-11-22 11:52:28.756112:  
2025-11-22 11:52:28.756409: Epoch 352 
2025-11-22 11:52:28.756577: Current learning rate: 0.00677 
2025-11-22 11:54:10.186417: train_loss -0.2037 
2025-11-22 11:54:10.186713: val_loss -0.1779 
2025-11-22 11:54:10.186965: Pseudo dice [0.0, 0.6293, 0.0, 0.6621, 0.7354, 0.0506, 0.8798, 0.8543] 
2025-11-22 11:54:10.187280: Epoch time: 101.43 s 
2025-11-22 11:54:12.057658:  
2025-11-22 11:54:12.058005: Epoch 353 
2025-11-22 11:54:12.058165: Current learning rate: 0.00676 
2025-11-22 11:55:53.975515: train_loss -0.2278 
2025-11-22 11:55:53.975833: val_loss -0.2082 
2025-11-22 11:55:53.976074: Pseudo dice [0.7408, 0.0006, 0.6594, 0.0, 0.7641, 0.0, 0.9123, 0.8072] 
2025-11-22 11:55:53.976250: Epoch time: 101.92 s 
2025-11-22 11:55:56.284585:  
2025-11-22 11:55:56.284901: Epoch 354 
2025-11-22 11:55:56.285055: Current learning rate: 0.00675 
2025-11-22 11:57:38.024209: train_loss -0.2101 
2025-11-22 11:57:38.024543: val_loss -0.1855 
2025-11-22 11:57:38.024847: Pseudo dice [0.4843, 0.084, 0.5395, 0.0535, 0.0, 0.8436, 0.9041, 0.8564] 
2025-11-22 11:57:38.025017: Epoch time: 101.74 s 
2025-11-22 11:57:39.926544:  
2025-11-22 11:57:39.926875: Epoch 355 
2025-11-22 11:57:39.927055: Current learning rate: 0.00674 
2025-11-22 11:59:21.947737: train_loss -0.2112 
2025-11-22 11:59:21.947991: val_loss -0.1713 
2025-11-22 11:59:21.948185: Pseudo dice [0.0, 0.5803, 0.6511, 0.0, 0.7436, 0.2483, 0.8678, 0.7941] 
2025-11-22 11:59:21.948411: Epoch time: 102.02 s 
2025-11-22 11:59:24.727697:  
2025-11-22 11:59:24.728054: Epoch 356 
2025-11-22 11:59:24.728223: Current learning rate: 0.00673 
2025-11-22 12:01:06.924043: train_loss -0.2034 
2025-11-22 12:01:06.924343: val_loss -0.171 
2025-11-22 12:01:06.924562: Pseudo dice [0.0, 0.6368, 0.0087, 0.5737, 0.6585, 0.0037, 0.8716, 0.754] 
2025-11-22 12:01:06.924807: Epoch time: 102.2 s 
2025-11-22 12:01:08.903833:  
2025-11-22 12:01:08.904153: Epoch 357 
2025-11-22 12:01:08.904327: Current learning rate: 0.00672 
2025-11-22 12:02:50.983902: train_loss -0.2052 
2025-11-22 12:02:50.984194: val_loss -0.2006 
2025-11-22 12:02:50.984371: Pseudo dice [0.0, 0.74, 0.6181, 0.0, 0.6627, 0.4848, 0.8835, 0.887] 
2025-11-22 12:02:50.984536: Epoch time: 102.08 s 
2025-11-22 12:02:50.984669: Yayy! New best EMA pseudo Dice: 0.469 
2025-11-22 12:02:54.049460:  
2025-11-22 12:02:54.049849: Epoch 358 
2025-11-22 12:02:54.050022: Current learning rate: 0.00671 
2025-11-22 12:04:35.617022: train_loss -0.2172 
2025-11-22 12:04:35.617218: val_loss -0.1502 
2025-11-22 12:04:35.617390: Pseudo dice [0.0, 0.6013, 0.0, 0.5527, 0.0, 0.7747, 0.847, 0.7776] 
2025-11-22 12:04:35.617536: Epoch time: 101.57 s 
2025-11-22 12:04:37.820445:  
2025-11-22 12:04:37.820822: Epoch 359 
2025-11-22 12:04:37.821012: Current learning rate: 0.0067 
2025-11-22 12:06:19.599096: train_loss -0.2163 
2025-11-22 12:06:19.599400: val_loss -0.185 
2025-11-22 12:06:19.599619: Pseudo dice [0.7525, 0.0687, 0.0005, 0.5963, 0.6971, 0.0005, 0.8888, 0.8011] 
2025-11-22 12:06:19.599783: Epoch time: 101.78 s 
2025-11-22 12:06:21.480593:  
2025-11-22 12:06:21.480864: Epoch 360 
2025-11-22 12:06:21.481057: Current learning rate: 0.00669 
2025-11-22 12:08:03.455033: train_loss -0.2262 
2025-11-22 12:08:03.455281: val_loss -0.1841 
2025-11-22 12:08:03.455477: Pseudo dice [0.6448, 0.0568, 0.0, 0.5929, 0.2111, 0.5408, 0.8711, 0.8316] 
2025-11-22 12:08:03.455793: Epoch time: 101.98 s 
2025-11-22 12:08:05.333865:  
2025-11-22 12:08:05.334256: Epoch 361 
2025-11-22 12:08:05.334415: Current learning rate: 0.00668 
2025-11-22 12:09:47.215168: train_loss -0.2185 
2025-11-22 12:09:47.215410: val_loss -0.1557 
2025-11-22 12:09:47.215637: Pseudo dice [0.0, 0.6904, 0.6726, 0.0, 0.6869, 0.0764, 0.853, 0.7855] 
2025-11-22 12:09:47.215826: Epoch time: 101.88 s 
2025-11-22 12:09:49.104786:  
2025-11-22 12:09:49.105070: Epoch 362 
2025-11-22 12:09:49.105247: Current learning rate: 0.00667 
2025-11-22 12:11:30.689666: train_loss -0.217 
2025-11-22 12:11:30.690012: val_loss -0.2005 
2025-11-22 12:11:30.690210: Pseudo dice [0.1461, 0.627, 0.0, 0.5702, 0.5752, 0.6489, 0.9103, 0.8741] 
2025-11-22 12:11:30.690337: Epoch time: 101.59 s 
2025-11-22 12:11:30.690440: Yayy! New best EMA pseudo Dice: 0.4755 
2025-11-22 12:11:33.769615:  
2025-11-22 12:11:33.769944: Epoch 363 
2025-11-22 12:11:33.770116: Current learning rate: 0.00666 
2025-11-22 12:13:15.466476: train_loss -0.2084 
2025-11-22 12:13:15.466726: val_loss -0.1726 
2025-11-22 12:13:15.466935: Pseudo dice [0.0006, 0.6256, 0.0, 0.5402, 0.5039, 0.3957, 0.8909, 0.8161] 
2025-11-22 12:13:15.467052: Epoch time: 101.7 s 
2025-11-22 12:13:17.774813:  
2025-11-22 12:13:17.775160: Epoch 364 
2025-11-22 12:13:17.775335: Current learning rate: 0.00665 
2025-11-22 12:14:59.253813: train_loss -0.2122 
2025-11-22 12:14:59.254054: val_loss -0.1858 
2025-11-22 12:14:59.254367: Pseudo dice [0.0, 0.7233, 0.0007, 0.6176, 0.5175, 0.0739, 0.8952, 0.8336] 
2025-11-22 12:14:59.255124: Epoch time: 101.48 s 
2025-11-22 12:15:01.124404:  
2025-11-22 12:15:01.124783: Epoch 365 
2025-11-22 12:15:01.124953: Current learning rate: 0.00665 
2025-11-22 12:16:42.857874: train_loss -0.2051 
2025-11-22 12:16:42.858087: val_loss -0.1592 
2025-11-22 12:16:42.858297: Pseudo dice [0.6097, 0.0289, 0.6839, 0.0677, 0.5249, 0.0002, 0.8895, 0.7901] 
2025-11-22 12:16:42.858427: Epoch time: 101.74 s 
2025-11-22 12:16:44.866917:  
2025-11-22 12:16:44.867249: Epoch 366 
2025-11-22 12:16:44.867420: Current learning rate: 0.00664 
2025-11-22 12:18:26.931807: train_loss -0.2177 
2025-11-22 12:18:26.932130: val_loss -0.1519 
2025-11-22 12:18:26.932332: Pseudo dice [0.6326, 0.0583, 0.393, 0.5224, 0.5547, 0.0003, 0.8182, 0.7704] 
2025-11-22 12:18:26.932452: Epoch time: 102.07 s 
2025-11-22 12:18:28.793618:  
2025-11-22 12:18:28.793974: Epoch 367 
2025-11-22 12:18:28.794159: Current learning rate: 0.00663 
2025-11-22 12:20:11.367136: train_loss -0.2043 
2025-11-22 12:20:11.367546: val_loss -0.1527 
2025-11-22 12:20:11.367809: Pseudo dice [0.6742, 0.0002, 0.3521, 0.6014, 0.0012, 0.7282, 0.8576, 0.7534] 
2025-11-22 12:20:11.367949: Epoch time: 102.57 s 
2025-11-22 12:20:13.335260:  
2025-11-22 12:20:13.335506: Epoch 368 
2025-11-22 12:20:13.335666: Current learning rate: 0.00662 
2025-11-22 12:21:55.303295: train_loss -0.2082 
2025-11-22 12:21:55.303555: val_loss -0.1666 
2025-11-22 12:21:55.303840: Pseudo dice [0.6599, 0.0249, 0.013, 0.6257, 0.5098, 0.02, 0.8561, 0.7604] 
2025-11-22 12:21:55.303996: Epoch time: 101.97 s 
2025-11-22 12:21:57.242523:  
2025-11-22 12:21:57.242777: Epoch 369 
2025-11-22 12:21:57.243007: Current learning rate: 0.00661 
2025-11-22 12:23:39.453944: train_loss -0.2149 
2025-11-22 12:23:39.454159: val_loss -0.158 
2025-11-22 12:23:39.454317: Pseudo dice [0.5774, 0.0155, 0.6276, 0.0, 0.0, 0.7003, 0.8641, 0.7982] 
2025-11-22 12:23:39.454422: Epoch time: 102.21 s 
2025-11-22 12:23:41.311014:  
2025-11-22 12:23:41.311357: Epoch 370 
2025-11-22 12:23:41.311518: Current learning rate: 0.0066 
2025-11-22 12:25:23.176167: train_loss -0.2059 
2025-11-22 12:25:23.176452: val_loss -0.1447 
2025-11-22 12:25:23.176649: Pseudo dice [0.6307, 0.0047, 0.6592, 0.0001, 0.3657, 0.0153, 0.8478, 0.7553] 
2025-11-22 12:25:23.176814: Epoch time: 101.87 s 
2025-11-22 12:25:25.139487:  
2025-11-22 12:25:25.139707: Epoch 371 
2025-11-22 12:25:25.139977: Current learning rate: 0.00659 
2025-11-22 12:27:07.139983: train_loss -0.1824 
2025-11-22 12:27:07.140286: val_loss -0.1399 
2025-11-22 12:27:07.140596: Pseudo dice [0.2344, 0.6209, 0.0031, 0.6867, 0.5263, 0.5072, 0.8399, 0.6573] 
2025-11-22 12:27:07.140754: Epoch time: 102.0 s 
2025-11-22 12:27:09.220814:  
2025-11-22 12:27:09.221105: Epoch 372 
2025-11-22 12:27:09.221295: Current learning rate: 0.00658 
2025-11-22 12:28:50.477022: train_loss -0.199 
2025-11-22 12:28:50.477300: val_loss -0.1606 
2025-11-22 12:28:50.477518: Pseudo dice [0.0049, 0.6175, 0.2201, 0.5687, 0.6878, 0.0, 0.8808, 0.7679] 
2025-11-22 12:28:50.477719: Epoch time: 101.26 s 
2025-11-22 12:28:52.427649:  
2025-11-22 12:28:52.428049: Epoch 373 
2025-11-22 12:28:52.428237: Current learning rate: 0.00657 
2025-11-22 12:30:33.000414: train_loss -0.2048 
2025-11-22 12:30:33.000678: val_loss -0.1745 
2025-11-22 12:30:33.000947: Pseudo dice [0.0869, 0.7777, 0.1676, 0.6388, 0.6682, 0.5424, 0.9143, 0.8019] 
2025-11-22 12:30:33.001111: Epoch time: 100.57 s 
2025-11-22 12:30:33.001227: Yayy! New best EMA pseudo Dice: 0.4773 
2025-11-22 12:30:35.892749:  
2025-11-22 12:30:35.893087: Epoch 374 
2025-11-22 12:30:35.893250: Current learning rate: 0.00656 
2025-11-22 12:32:17.768808: train_loss -0.2031 
2025-11-22 12:32:17.769070: val_loss -0.1863 
2025-11-22 12:32:17.769424: Pseudo dice [0.6405, 0.0033, 0.594, 0.0, 0.2991, 0.6994, 0.9149, 0.8325] 
2025-11-22 12:32:17.769588: Epoch time: 101.88 s 
2025-11-22 12:32:17.769711: Yayy! New best EMA pseudo Dice: 0.4793 
2025-11-22 12:32:21.465025:  
2025-11-22 12:32:21.465391: Epoch 375 
2025-11-22 12:32:21.465581: Current learning rate: 0.00655 
2025-11-22 12:34:03.234939: train_loss -0.2143 
2025-11-22 12:34:03.235215: val_loss -0.159 
2025-11-22 12:34:03.235431: Pseudo dice [0.0023, 0.7205, 0.3961, 0.0762, 0.5051, 0.0001, 0.8644, 0.7858] 
2025-11-22 12:34:03.235577: Epoch time: 101.77 s 
2025-11-22 12:34:05.184790:  
2025-11-22 12:34:05.185155: Epoch 376 
2025-11-22 12:34:05.185319: Current learning rate: 0.00654 
2025-11-22 12:35:47.321394: train_loss -0.207 
2025-11-22 12:35:47.321791: val_loss -0.1657 
2025-11-22 12:35:47.322135: Pseudo dice [0.2524, 0.5144, 0.0, 0.5693, 0.0, 0.6924, 0.8689, 0.8154] 
2025-11-22 12:35:47.322306: Epoch time: 102.14 s 
2025-11-22 12:35:49.277195:  
2025-11-22 12:35:49.277531: Epoch 377 
2025-11-22 12:35:49.277693: Current learning rate: 0.00653 
2025-11-22 12:37:31.169583: train_loss -0.209 
2025-11-22 12:37:31.169849: val_loss -0.1754 
2025-11-22 12:37:31.170108: Pseudo dice [0.5449, 0.0048, 0.4476, 0.0, 0.486, 0.0848, 0.8832, 0.7586] 
2025-11-22 12:37:31.170382: Epoch time: 101.89 s 
2025-11-22 12:37:33.424778:  
2025-11-22 12:37:33.425098: Epoch 378 
2025-11-22 12:37:33.425266: Current learning rate: 0.00652 
2025-11-22 12:39:14.955111: train_loss -0.2162 
2025-11-22 12:39:14.955487: val_loss -0.1888 
2025-11-22 12:39:14.955725: Pseudo dice [0.6383, 0.1593, 0.6864, 0.0, 0.5017, 0.0, 0.9053, 0.8136] 
2025-11-22 12:39:14.955901: Epoch time: 101.53 s 
2025-11-22 12:39:16.967064:  
2025-11-22 12:39:16.967496: Epoch 379 
2025-11-22 12:39:16.967685: Current learning rate: 0.00651 
2025-11-22 12:40:58.494675: train_loss -0.2142 
2025-11-22 12:40:58.495028: val_loss -0.178 
2025-11-22 12:40:58.495257: Pseudo dice [0.5864, 0.0102, 0.703, 0.1375, 0.098, 0.5827, 0.8911, 0.7694] 
2025-11-22 12:40:58.495399: Epoch time: 101.53 s 
2025-11-22 12:41:00.550415:  
2025-11-22 12:41:00.550822: Epoch 380 
2025-11-22 12:41:00.551006: Current learning rate: 0.0065 
2025-11-22 12:42:42.190974: train_loss -0.2257 
2025-11-22 12:42:42.191316: val_loss -0.1937 
2025-11-22 12:42:42.191544: Pseudo dice [0.0212, 0.7229, 0.0, 0.7282, 0.5825, 0.7044, 0.8382, 0.7705] 
2025-11-22 12:42:42.191682: Epoch time: 101.64 s 
2025-11-22 12:42:44.264672:  
2025-11-22 12:42:44.265005: Epoch 381 
2025-11-22 12:42:44.265170: Current learning rate: 0.00649 
2025-11-22 12:44:25.911166: train_loss -0.2125 
2025-11-22 12:44:25.911456: val_loss -0.1459 
2025-11-22 12:44:25.911641: Pseudo dice [0.4675, 0.0756, 0.5221, 0.0, 0.5582, 0.6173, 0.8494, 0.81] 
2025-11-22 12:44:25.911798: Epoch time: 101.65 s 
2025-11-22 12:44:28.303253:  
2025-11-22 12:44:28.303498: Epoch 382 
2025-11-22 12:44:28.303658: Current learning rate: 0.00648 
2025-11-22 12:46:09.723570: train_loss -0.2177 
2025-11-22 12:46:09.723881: val_loss -0.1607 
2025-11-22 12:46:09.724108: Pseudo dice [0.0001, 0.6426, 0.0003, 0.5494, 0.462, 0.2018, 0.8301, 0.813] 
2025-11-22 12:46:09.724261: Epoch time: 101.42 s 
2025-11-22 12:46:11.721378:  
2025-11-22 12:46:11.721618: Epoch 383 
2025-11-22 12:46:11.721810: Current learning rate: 0.00648 
2025-11-22 12:47:53.450545: train_loss -0.1942 
2025-11-22 12:47:53.450856: val_loss -0.1867 
2025-11-22 12:47:53.451103: Pseudo dice [0.6703, 0.0677, 0.5569, 0.0, 0.3275, 0.5731, 0.883, 0.8157] 
2025-11-22 12:47:53.451271: Epoch time: 101.73 s 
2025-11-22 12:47:55.467404:  
2025-11-22 12:47:55.467624: Epoch 384 
2025-11-22 12:47:55.467861: Current learning rate: 0.00647 
2025-11-22 12:49:37.056872: train_loss -0.206 
2025-11-22 12:49:37.057250: val_loss -0.151 
2025-11-22 12:49:37.057487: Pseudo dice [0.3622, 0.6006, 0.0, 0.5836, 0.0048, 0.6137, 0.8237, 0.7659] 
2025-11-22 12:49:37.057653: Epoch time: 101.59 s 
2025-11-22 12:49:39.230959:  
2025-11-22 12:49:39.231272: Epoch 385 
2025-11-22 12:49:39.231453: Current learning rate: 0.00646 
2025-11-22 12:51:20.407112: train_loss -0.2041 
2025-11-22 12:51:20.407577: val_loss -0.184 
2025-11-22 12:51:20.407816: Pseudo dice [0.6592, 0.2669, 0.5099, 0.0, 0.6475, 0.0119, 0.8162, 0.8422] 
2025-11-22 12:51:20.407990: Epoch time: 101.18 s 
2025-11-22 12:51:22.438543:  
2025-11-22 12:51:22.438944: Epoch 386 
2025-11-22 12:51:22.439114: Current learning rate: 0.00645 
2025-11-22 12:53:04.462246: train_loss -0.2059 
2025-11-22 12:53:04.462466: val_loss -0.14 
2025-11-22 12:53:04.462819: Pseudo dice [0.6874, 0.0001, 0.746, 0.0, 0.7507, 0.0352, 0.8772, 0.698] 
2025-11-22 12:53:04.463060: Epoch time: 102.03 s 
2025-11-22 12:53:06.694402:  
2025-11-22 12:53:06.694732: Epoch 387 
2025-11-22 12:53:06.694948: Current learning rate: 0.00644 
2025-11-22 12:54:48.198210: train_loss -0.1875 
2025-11-22 12:54:48.198442: val_loss -0.152 
2025-11-22 12:54:48.198622: Pseudo dice [0.6689, 0.0137, 0.6303, 0.0, 0.1679, 0.4732, 0.8799, 0.7081] 
2025-11-22 12:54:48.198781: Epoch time: 101.51 s 
2025-11-22 12:54:50.176532:  
2025-11-22 12:54:50.176864: Epoch 388 
2025-11-22 12:54:50.177022: Current learning rate: 0.00643 
2025-11-22 12:56:31.806156: train_loss -0.207 
2025-11-22 12:56:31.806414: val_loss -0.1616 
2025-11-22 12:56:31.806624: Pseudo dice [0.2535, 0.5673, 0.0, 0.5977, 0.466, 0.2607, 0.8708, 0.817] 
2025-11-22 12:56:31.806794: Epoch time: 101.63 s 
2025-11-22 12:56:33.795384:  
2025-11-22 12:56:33.795718: Epoch 389 
2025-11-22 12:56:33.795908: Current learning rate: 0.00642 
2025-11-22 12:58:15.813750: train_loss -0.2141 
2025-11-22 12:58:15.814128: val_loss -0.1723 
2025-11-22 12:58:15.814342: Pseudo dice [0.4883, 0.3574, 0.0503, 0.7676, 0.5793, 0.0485, 0.8694, 0.8126] 
2025-11-22 12:58:15.814455: Epoch time: 102.02 s 
2025-11-22 12:58:17.945921:  
2025-11-22 12:58:17.946230: Epoch 390 
2025-11-22 12:58:17.946357: Current learning rate: 0.00641 
2025-11-22 12:59:59.652641: train_loss -0.2075 
2025-11-22 12:59:59.653036: val_loss -0.1823 
2025-11-22 12:59:59.653239: Pseudo dice [0.7028, 0.0078, 0.5834, 0.0873, 0.5032, 0.0059, 0.885, 0.8267] 
2025-11-22 12:59:59.653361: Epoch time: 101.71 s 
2025-11-22 13:00:01.948067:  
2025-11-22 13:00:01.948351: Epoch 391 
2025-11-22 13:00:01.948522: Current learning rate: 0.0064 
2025-11-22 13:01:43.393726: train_loss -0.2063 
2025-11-22 13:01:43.394079: val_loss -0.1998 
2025-11-22 13:01:43.394307: Pseudo dice [0.5849, 0.2266, 0.6157, 0.0, 0.0, 0.6501, 0.8922, 0.8342] 
2025-11-22 13:01:43.394449: Epoch time: 101.45 s 
2025-11-22 13:01:45.453804:  
2025-11-22 13:01:45.454153: Epoch 392 
2025-11-22 13:01:45.454337: Current learning rate: 0.00639 
2025-11-22 13:03:27.241977: train_loss -0.208 
2025-11-22 13:03:27.242484: val_loss -0.1708 
2025-11-22 13:03:27.242735: Pseudo dice [0.0186, 0.5446, 0.667, 0.2475, 0.0197, 0.8061, 0.873, 0.7858] 
2025-11-22 13:03:27.242948: Epoch time: 101.79 s 
2025-11-22 13:03:29.272186:  
2025-11-22 13:03:29.272542: Epoch 393 
2025-11-22 13:03:29.272736: Current learning rate: 0.00638 
2025-11-22 13:05:10.490538: train_loss -0.2164 
2025-11-22 13:05:10.490745: val_loss -0.1786 
2025-11-22 13:05:10.491010: Pseudo dice [0.0, 0.6187, 0.0, 0.4732, 0.0, 0.6226, 0.8431, 0.7925] 
2025-11-22 13:05:10.491246: Epoch time: 101.22 s 
2025-11-22 13:05:12.883027:  
2025-11-22 13:05:12.883434: Epoch 394 
2025-11-22 13:05:12.883634: Current learning rate: 0.00637 
2025-11-22 13:06:55.077968: train_loss -0.2204 
2025-11-22 13:06:55.078187: val_loss -0.1611 
2025-11-22 13:06:55.078447: Pseudo dice [0.0, 0.7228, 0.4497, 0.0142, 0.0, 0.7045, 0.8688, 0.842] 
2025-11-22 13:06:55.078607: Epoch time: 102.2 s 
2025-11-22 13:06:57.056417:  
2025-11-22 13:06:57.056720: Epoch 395 
2025-11-22 13:06:57.056898: Current learning rate: 0.00636 
2025-11-22 13:08:39.294796: train_loss -0.2154 
2025-11-22 13:08:39.295234: val_loss -0.185 
2025-11-22 13:08:39.295451: Pseudo dice [0.5683, 0.0073, 0.0, 0.678, 0.4968, 0.0321, 0.87, 0.8014] 
2025-11-22 13:08:39.295592: Epoch time: 102.24 s 
2025-11-22 13:08:42.528143:  
2025-11-22 13:08:42.528514: Epoch 396 
2025-11-22 13:08:42.528701: Current learning rate: 0.00635 
2025-11-22 13:10:25.125633: train_loss -0.2296 
2025-11-22 13:10:25.125901: val_loss -0.1992 
2025-11-22 13:10:25.126128: Pseudo dice [0.0, 0.5822, 0.0, 0.7356, 0.7374, 0.019, 0.9166, 0.8349] 
2025-11-22 13:10:25.126288: Epoch time: 102.6 s 
2025-11-22 13:10:27.127940:  
2025-11-22 13:10:27.128307: Epoch 397 
2025-11-22 13:10:27.128493: Current learning rate: 0.00634 
2025-11-22 13:12:08.736596: train_loss -0.2175 
2025-11-22 13:12:08.736901: val_loss -0.1994 
2025-11-22 13:12:08.737148: Pseudo dice [0.6024, 0.0052, 0.6207, 0.0, 0.0, 0.5925, 0.8969, 0.8733] 
2025-11-22 13:12:08.737295: Epoch time: 101.61 s 
2025-11-22 13:12:10.780538:  
2025-11-22 13:12:10.780897: Epoch 398 
2025-11-22 13:12:10.781076: Current learning rate: 0.00633 
2025-11-22 13:13:52.519459: train_loss -0.2243 
2025-11-22 13:13:52.519785: val_loss -0.1794 
2025-11-22 13:13:52.520115: Pseudo dice [0.0456, 0.7338, 0.3926, 0.0, 0.6496, 0.1536, 0.8192, 0.7315] 
2025-11-22 13:13:52.520268: Epoch time: 101.74 s 
2025-11-22 13:13:54.671173:  
2025-11-22 13:13:54.671523: Epoch 399 
2025-11-22 13:13:54.671705: Current learning rate: 0.00632 
2025-11-22 13:15:35.716721: train_loss -0.2252 
2025-11-22 13:15:35.717129: val_loss -0.1842 
2025-11-22 13:15:35.717494: Pseudo dice [0.6208, 0.0157, 0.6902, 0.1034, 0.4944, 0.1354, 0.8861, 0.812] 
2025-11-22 13:15:35.717650: Epoch time: 101.05 s 
2025-11-22 13:15:38.758934:  
2025-11-22 13:15:38.759247: Epoch 400 
2025-11-22 13:15:38.759405: Current learning rate: 0.00631 
2025-11-22 13:17:20.169541: train_loss -0.2233 
2025-11-22 13:17:20.169780: val_loss -0.1547 
2025-11-22 13:17:20.169992: Pseudo dice [0.59, 0.1356, 0.1566, 0.747, 0.8117, 0.0027, 0.8767, 0.6951] 
2025-11-22 13:17:20.170122: Epoch time: 101.41 s 
2025-11-22 13:17:22.129905:  
2025-11-22 13:17:22.130209: Epoch 401 
2025-11-22 13:17:22.130374: Current learning rate: 0.0063 
2025-11-22 13:19:03.530386: train_loss -0.214 
2025-11-22 13:19:03.530588: val_loss -0.163 
2025-11-22 13:19:03.530818: Pseudo dice [0.0139, 0.6484, 0.0004, 0.6274, 0.0015, 0.4974, 0.8895, 0.7735] 
2025-11-22 13:19:03.530978: Epoch time: 101.4 s 
2025-11-22 13:19:05.508901:  
2025-11-22 13:19:05.509206: Epoch 402 
2025-11-22 13:19:05.509372: Current learning rate: 0.0063 
2025-11-22 13:20:46.827099: train_loss -0.2245 
2025-11-22 13:20:46.827358: val_loss -0.1663 
2025-11-22 13:20:46.827609: Pseudo dice [0.6859, 0.0233, 0.7101, 0.0, 0.5822, 0.0034, 0.8574, 0.7945] 
2025-11-22 13:20:46.827736: Epoch time: 101.32 s 
2025-11-22 13:20:48.845479:  
2025-11-22 13:20:48.845834: Epoch 403 
2025-11-22 13:20:48.845994: Current learning rate: 0.00629 
2025-11-22 13:22:30.556670: train_loss -0.2188 
2025-11-22 13:22:30.556925: val_loss -0.1568 
2025-11-22 13:22:30.557171: Pseudo dice [0.0024, 0.6106, 0.0001, 0.4965, 0.0, 0.5874, 0.8004, 0.7429] 
2025-11-22 13:22:30.557305: Epoch time: 101.71 s 
2025-11-22 13:22:33.068335:  
2025-11-22 13:22:33.068693: Epoch 404 
2025-11-22 13:22:33.068874: Current learning rate: 0.00628 
2025-11-22 13:24:14.520658: train_loss -0.2158 
2025-11-22 13:24:14.520952: val_loss -0.1944 
2025-11-22 13:24:14.521137: Pseudo dice [0.126, 0.6057, 0.6901, 0.0074, 0.0, 0.4982, 0.9141, 0.8449] 
2025-11-22 13:24:14.521290: Epoch time: 101.45 s 
2025-11-22 13:24:16.850142:  
2025-11-22 13:24:16.850363: Epoch 405 
2025-11-22 13:24:16.850524: Current learning rate: 0.00627 
2025-11-22 13:25:58.648275: train_loss -0.2231 
2025-11-22 13:25:58.648519: val_loss -0.194 
2025-11-22 13:25:58.648823: Pseudo dice [0.0, 0.7358, 0.0005, 0.6741, 0.0, 0.7603, 0.904, 0.8355] 
2025-11-22 13:25:58.648996: Epoch time: 101.8 s 
2025-11-22 13:26:00.821935:  
2025-11-22 13:26:00.822210: Epoch 406 
2025-11-22 13:26:00.822381: Current learning rate: 0.00626 
