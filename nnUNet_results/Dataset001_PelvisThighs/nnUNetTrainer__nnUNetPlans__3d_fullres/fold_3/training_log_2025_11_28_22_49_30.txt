
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-11-28 22:49:31.904519: Using torch.compile... 
2025-11-28 22:49:36.309600: do_dummy_2d_data_aug: True 
2025-11-28 22:49:36.310278: Creating new 5-fold cross-validation split... 
2025-11-28 22:49:36.312961: Desired fold for training: 3 
2025-11-28 22:49:36.313174: This split has 19 training and 4 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [48, 384, 64], 'median_image_size_in_voxels': [158.0, 1284.0, 261.0], 'spacing': [1.26953125, 0.5, 1.26953125], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 7, 'features_per_stage': [32, 64, 128, 256, 320, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[1, 3, 1], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [1, 2, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2], [1, 2, 1]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset001_PelvisThighs', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.26953125, 0.5, 1.26953125], 'original_median_shape_after_transp': [184, 1284, 310], 'image_reader_writer': 'NibabelIO', 'transpose_forward': [1, 0, 2], 'transpose_backward': [1, 0, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 3071.0, 'mean': 613.2944946289062, 'median': 443.0, 'min': -136.0, 'percentile_00_5': 181.0, 'percentile_99_5': 1723.0, 'std': 426.4911193847656}}} 
 
2025-11-28 22:50:12.334282: Unable to plot network architecture: nnUNet_compile is enabled! 
2025-11-28 22:50:12.350944:  
2025-11-28 22:50:12.357290: Epoch 0 
2025-11-28 22:50:12.361795: Current learning rate: 0.01 
2025-11-28 22:54:25.736794: train_loss 0.3093 
2025-11-28 22:54:25.737303: val_loss 0.1596 
2025-11-28 22:54:25.737541: Pseudo dice [0.1535, 0.3409, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] 
2025-11-28 22:54:25.737685: Epoch time: 253.39 s 
2025-11-28 22:54:25.737819: Yayy! New best EMA pseudo Dice: 0.0618 
2025-11-28 22:54:27.973403:  
2025-11-28 22:54:27.973810: Epoch 1 
2025-11-28 22:54:27.973982: Current learning rate: 0.00999 
2025-11-28 22:56:03.320690: train_loss 0.156 
2025-11-28 22:56:03.320934: val_loss 0.1334 
2025-11-28 22:56:03.321161: Pseudo dice [0.0, 0.3871, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] 
2025-11-28 22:56:03.321341: Epoch time: 95.35 s 
2025-11-28 22:56:05.336200:  
2025-11-28 22:56:05.336551: Epoch 2 
2025-11-28 22:56:05.336733: Current learning rate: 0.00998 
2025-11-28 22:57:39.093565: train_loss 0.1377 
2025-11-28 22:57:39.093910: val_loss 0.1014 
2025-11-28 22:57:39.094094: Pseudo dice [0.5063, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] 
2025-11-28 22:57:39.094244: Epoch time: 93.76 s 
2025-11-28 22:57:41.092116:  
2025-11-28 22:57:41.092463: Epoch 3 
2025-11-28 22:57:41.092636: Current learning rate: 0.00997 
2025-11-28 22:59:14.776657: train_loss 0.1069 
2025-11-28 22:59:14.776901: val_loss 0.0998 
2025-11-28 22:59:14.777256: Pseudo dice [0.3015, 0.2935, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] 
2025-11-28 22:59:14.777384: Epoch time: 93.69 s 
2025-11-28 22:59:14.777538: Yayy! New best EMA pseudo Dice: 0.0621 
2025-11-28 22:59:17.557333:  
2025-11-28 22:59:17.557617: Epoch 4 
2025-11-28 22:59:17.557801: Current learning rate: 0.00996 
2025-11-28 23:00:51.374843: train_loss 0.1123 
2025-11-28 23:00:51.375101: val_loss 0.0808 
2025-11-28 23:00:51.375363: Pseudo dice [0.3256, 0.2789, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] 
2025-11-28 23:00:51.375524: Epoch time: 93.82 s 
2025-11-28 23:00:51.375792: Yayy! New best EMA pseudo Dice: 0.0635 
2025-11-28 23:00:54.206678:  
2025-11-28 23:00:54.206990: Epoch 5 
2025-11-28 23:00:54.207191: Current learning rate: 0.00995 
2025-11-28 23:02:28.797642: train_loss 0.116 
2025-11-28 23:02:28.797932: val_loss 0.0951 
2025-11-28 23:02:28.798238: Pseudo dice [0.3293, 0.0, 0.0115, 0.0, 0.0, 0.0, 0.0, 0.0] 
2025-11-28 23:02:28.798417: Epoch time: 94.59 s 
2025-11-28 23:02:30.640883:  
2025-11-28 23:02:30.641036: Epoch 6 
2025-11-28 23:02:30.641189: Current learning rate: 0.00995 
2025-11-28 23:04:05.030589: train_loss 0.0992 
2025-11-28 23:04:05.030921: val_loss 0.0935 
2025-11-28 23:04:05.031077: Pseudo dice [0.3847, 0.2352, 0.1941, 0.0, 0.0, 0.0, 0.0, 0.0] 
2025-11-28 23:04:05.031244: Epoch time: 94.39 s 
2025-11-28 23:04:05.031396: Yayy! New best EMA pseudo Dice: 0.0654 
2025-11-28 23:04:07.761201:  
2025-11-28 23:04:07.761527: Epoch 7 
2025-11-28 23:04:07.761720: Current learning rate: 0.00994 
2025-11-28 23:05:42.043736: train_loss 0.0918 
2025-11-28 23:05:42.044040: val_loss 0.0716 
2025-11-28 23:05:42.044266: Pseudo dice [0.0, 0.501, 0.0, 0.4014, 0.0, 0.0, 0.0, 0.0] 
2025-11-28 23:05:42.044525: Epoch time: 94.28 s 
2025-11-28 23:05:42.044663: Yayy! New best EMA pseudo Dice: 0.0702 
2025-11-28 23:05:44.797510:  
2025-11-28 23:05:44.797697: Epoch 8 
2025-11-28 23:05:44.797922: Current learning rate: 0.00993 
2025-11-28 23:07:18.908370: train_loss 0.0774 
2025-11-28 23:07:18.908608: val_loss 0.075 
2025-11-28 23:07:18.908780: Pseudo dice [0.0, 0.4979, 0.0, 0.3903, 0.0, 0.0, 0.0, 0.0] 
2025-11-28 23:07:18.908879: Epoch time: 94.11 s 
2025-11-28 23:07:18.908988: Yayy! New best EMA pseudo Dice: 0.0742 
2025-11-28 23:07:21.949652:  
2025-11-28 23:07:21.950039: Epoch 9 
2025-11-28 23:07:21.950243: Current learning rate: 0.00992 
2025-11-28 23:08:56.770633: train_loss 0.0748 
2025-11-28 23:08:56.770929: val_loss 0.0393 
2025-11-28 23:08:56.771185: Pseudo dice [0.0, 0.6561, 0.4467, 0.1614, 0.0, 0.0, 0.0, 0.0] 
2025-11-28 23:08:56.771363: Epoch time: 94.82 s 
2025-11-28 23:08:56.771500: Yayy! New best EMA pseudo Dice: 0.0826 
2025-11-28 23:08:59.525516:  
2025-11-28 23:08:59.525835: Epoch 10 
2025-11-28 23:08:59.526015: Current learning rate: 0.00991 
2025-11-28 23:10:34.270355: train_loss 0.0609 
2025-11-28 23:10:34.270775: val_loss 0.0529 
2025-11-28 23:10:34.271001: Pseudo dice [0.6071, 0.0, 0.1657, 0.3881, 0.0, 0.0, 0.0, 0.0] 
2025-11-28 23:10:34.271183: Epoch time: 94.75 s 
2025-11-28 23:10:34.271297: Yayy! New best EMA pseudo Dice: 0.0889 
2025-11-28 23:10:37.029366:  
2025-11-28 23:10:37.029727: Epoch 11 
2025-11-28 23:10:37.029910: Current learning rate: 0.0099 
2025-11-28 23:12:11.013518: train_loss 0.0546 
2025-11-28 23:12:11.013767: val_loss 0.0115 
2025-11-28 23:12:11.013968: Pseudo dice [0.0, 0.5675, 0.3797, 0.0013, 0.0, 0.0, 0.0, 0.0] 
2025-11-28 23:12:11.014126: Epoch time: 93.99 s 
2025-11-28 23:12:11.014277: Yayy! New best EMA pseudo Dice: 0.0918 
2025-11-28 23:12:13.688719:  
2025-11-28 23:12:13.689001: Epoch 12 
2025-11-28 23:12:13.689196: Current learning rate: 0.00989 
2025-11-28 23:13:48.031973: train_loss 0.0394 
2025-11-28 23:13:48.032242: val_loss 0.014 
2025-11-28 23:13:48.032431: Pseudo dice [0.6638, 0.0331, 0.0, 0.3655, 0.0, 0.0, 0.0088, 0.0009] 
2025-11-28 23:13:48.032577: Epoch time: 94.34 s 
2025-11-28 23:13:48.032672: Yayy! New best EMA pseudo Dice: 0.0961 
2025-11-28 23:13:50.710418:  
2025-11-28 23:13:50.710784: Epoch 13 
2025-11-28 23:13:50.710944: Current learning rate: 0.00988 
2025-11-28 23:15:24.644424: train_loss 0.0369 
2025-11-28 23:15:24.644691: val_loss 0.0257 
2025-11-28 23:15:24.644851: Pseudo dice [0.0739, 0.4586, 0.4641, 0.0, 0.0, 0.0, 0.0687, 0.1022] 
2025-11-28 23:15:24.644964: Epoch time: 93.94 s 
2025-11-28 23:15:24.645049: Yayy! New best EMA pseudo Dice: 0.101 
2025-11-28 23:15:27.571537:  
2025-11-28 23:15:27.571834: Epoch 14 
2025-11-28 23:15:27.572006: Current learning rate: 0.00987 
2025-11-28 23:17:02.507781: train_loss 0.0233 
2025-11-28 23:17:02.508074: val_loss 0.0252 
2025-11-28 23:17:02.508273: Pseudo dice [0.4746, 0.0, 0.3775, 0.0677, 0.0, 0.0, 0.0844, 0.0145] 
2025-11-28 23:17:02.508377: Epoch time: 94.94 s 
2025-11-28 23:17:02.508450: Yayy! New best EMA pseudo Dice: 0.1037 
2025-11-28 23:17:05.356922:  
2025-11-28 23:17:05.357151: Epoch 15 
2025-11-28 23:17:05.357358: Current learning rate: 0.00986 
2025-11-28 23:18:39.614762: train_loss 0.0206 
2025-11-28 23:18:39.614992: val_loss -0.0209 
2025-11-28 23:18:39.615431: Pseudo dice [0.0324, 0.6995, 0.0, 0.3555, 0.0, 0.0, 0.124, 0.1853] 
2025-11-28 23:18:39.615607: Epoch time: 94.26 s 
2025-11-28 23:18:39.615755: Yayy! New best EMA pseudo Dice: 0.1108 
2025-11-28 23:18:42.493109:  
2025-11-28 23:18:42.493482: Epoch 16 
2025-11-28 23:18:42.493669: Current learning rate: 0.00986 
2025-11-28 23:20:16.739187: train_loss 0.0109 
2025-11-28 23:20:16.739492: val_loss -0.023 
2025-11-28 23:20:16.739699: Pseudo dice [0.0, 0.5394, 0.5796, 0.0002, 0.0, 0.0, 0.0061, 0.4542] 
2025-11-28 23:20:16.739825: Epoch time: 94.25 s 
2025-11-28 23:20:16.739937: Yayy! New best EMA pseudo Dice: 0.1194 
2025-11-28 23:20:19.569142:  
2025-11-28 23:20:19.569482: Epoch 17 
2025-11-28 23:20:19.569657: Current learning rate: 0.00985 
2025-11-28 23:21:53.723542: train_loss -0.0103 
2025-11-28 23:21:53.723806: val_loss -0.0363 
2025-11-28 23:21:53.724066: Pseudo dice [0.539, 0.0, 0.5356, 0.0558, 0.0, 0.0, 0.3019, 0.6586] 
2025-11-28 23:21:53.724365: Epoch time: 94.16 s 
2025-11-28 23:21:53.724499: Yayy! New best EMA pseudo Dice: 0.1336 
2025-11-28 23:21:57.694989:  
2025-11-28 23:21:57.695333: Epoch 18 
2025-11-28 23:21:57.695509: Current learning rate: 0.00984 
2025-11-28 23:23:32.181249: train_loss -0.0254 
2025-11-28 23:23:32.181525: val_loss -0.0621 
2025-11-28 23:23:32.181769: Pseudo dice [0.63, 0.0, 0.5149, 0.0001, 0.0, 0.0, 0.1865, 0.7106] 
2025-11-28 23:23:32.181894: Epoch time: 94.49 s 
2025-11-28 23:23:32.181982: Yayy! New best EMA pseudo Dice: 0.1458 
2025-11-28 23:23:35.071805:  
2025-11-28 23:23:35.072155: Epoch 19 
2025-11-28 23:23:35.072340: Current learning rate: 0.00983 
2025-11-28 23:25:09.538982: train_loss -0.0286 
2025-11-28 23:25:09.539399: val_loss -0.0418 
2025-11-28 23:25:09.539603: Pseudo dice [0.0017, 0.653, 0.0039, 0.5592, 0.0, 0.4331, 0.1899, 0.6784] 
2025-11-28 23:25:09.539794: Epoch time: 94.47 s 
2025-11-28 23:25:09.539903: Yayy! New best EMA pseudo Dice: 0.1627 
2025-11-28 23:25:12.399204:  
2025-11-28 23:25:12.399513: Epoch 20 
2025-11-28 23:25:12.399679: Current learning rate: 0.00982 
2025-11-28 23:26:47.289941: train_loss -0.0429 
2025-11-28 23:26:47.290234: val_loss -0.0606 
2025-11-28 23:26:47.290612: Pseudo dice [0.5038, 0.0301, 0.6094, 0.0, 0.5706, 0.0, 0.4086, 0.7115] 
2025-11-28 23:26:47.290772: Epoch time: 94.89 s 
2025-11-28 23:26:47.290943: Yayy! New best EMA pseudo Dice: 0.1819 
2025-11-28 23:26:50.176279:  
2025-11-28 23:26:50.176595: Epoch 21 
2025-11-28 23:26:50.176827: Current learning rate: 0.00981 
2025-11-28 23:28:25.158748: train_loss -0.0529 
2025-11-28 23:28:25.158965: val_loss -0.0566 
2025-11-28 23:28:25.159175: Pseudo dice [0.4154, 0.4213, 0.4967, 0.2569, 0.0, 0.4713, 0.4731, 0.6975] 
2025-11-28 23:28:25.159310: Epoch time: 94.98 s 
2025-11-28 23:28:25.159394: Yayy! New best EMA pseudo Dice: 0.2041 
2025-11-28 23:28:27.814580:  
2025-11-28 23:28:27.814741: Epoch 22 
2025-11-28 23:28:27.814935: Current learning rate: 0.0098 
2025-11-28 23:30:02.478091: train_loss -0.0522 
2025-11-28 23:30:02.478470: val_loss -0.0348 
2025-11-28 23:30:02.478672: Pseudo dice [0.0, 0.5683, 0.5938, 0.0, 0.6191, 0.0, 0.3583, 0.6872] 
2025-11-28 23:30:02.478788: Epoch time: 94.66 s 
2025-11-28 23:30:02.478898: Yayy! New best EMA pseudo Dice: 0.219 
2025-11-28 23:30:05.258348:  
2025-11-28 23:30:05.258754: Epoch 23 
2025-11-28 23:30:05.258930: Current learning rate: 0.00979 
2025-11-28 23:31:39.721439: train_loss -0.0539 
2025-11-28 23:31:39.721722: val_loss -0.0969 
2025-11-28 23:31:39.721893: Pseudo dice [0.5771, 0.1041, 0.0, 0.5728, 0.0103, 0.6134, 0.6313, 0.8062] 
2025-11-28 23:31:39.721988: Epoch time: 94.46 s 
2025-11-28 23:31:39.722058: Yayy! New best EMA pseudo Dice: 0.2385 
2025-11-28 23:31:42.394155:  
2025-11-28 23:31:42.394432: Epoch 24 
2025-11-28 23:31:42.394617: Current learning rate: 0.00978 
2025-11-28 23:33:17.172530: train_loss -0.0772 
2025-11-28 23:33:17.172894: val_loss -0.1147 
2025-11-28 23:33:17.173204: Pseudo dice [0.557, 0.0019, 0.38, 0.4507, 0.0053, 0.7134, 0.6154, 0.8103] 
2025-11-28 23:33:17.173481: Epoch time: 94.78 s 
2025-11-28 23:33:17.173635: Yayy! New best EMA pseudo Dice: 0.2589 
2025-11-28 23:33:19.944688:  
2025-11-28 23:33:19.945094: Epoch 25 
2025-11-28 23:33:19.945302: Current learning rate: 0.00977 
2025-11-28 23:34:54.179961: train_loss -0.0811 
2025-11-28 23:34:54.180269: val_loss -0.0982 
2025-11-28 23:34:54.180612: Pseudo dice [0.5337, 0.0013, 0.6031, 0.2113, 0.0, 0.7422, 0.6147, 0.7097] 
2025-11-28 23:34:54.180761: Epoch time: 94.24 s 
2025-11-28 23:34:54.180868: Yayy! New best EMA pseudo Dice: 0.2757 
2025-11-28 23:34:56.776993:  
2025-11-28 23:34:56.777323: Epoch 26 
2025-11-28 23:34:56.777499: Current learning rate: 0.00977 
2025-11-28 23:36:31.234960: train_loss -0.0948 
2025-11-28 23:36:31.235259: val_loss -0.126 
2025-11-28 23:36:31.235514: Pseudo dice [0.0, 0.6829, 0.0, 0.544, 0.4976, 0.0, 0.7497, 0.8137] 
2025-11-28 23:36:31.235669: Epoch time: 94.46 s 
2025-11-28 23:36:31.235842: Yayy! New best EMA pseudo Dice: 0.2892 
2025-11-28 23:36:33.976555:  
2025-11-28 23:36:33.976897: Epoch 27 
2025-11-28 23:36:33.977067: Current learning rate: 0.00976 
2025-11-28 23:38:08.758865: train_loss -0.0954 
2025-11-28 23:38:08.759224: val_loss -0.1072 
2025-11-28 23:38:08.759390: Pseudo dice [0.0197, 0.5524, 0.4733, 0.3121, 0.0, 0.3907, 0.6422, 0.7681] 
2025-11-28 23:38:08.759492: Epoch time: 94.78 s 
2025-11-28 23:38:08.759564: Yayy! New best EMA pseudo Dice: 0.2998 
2025-11-28 23:38:11.715537:  
2025-11-28 23:38:11.715893: Epoch 28 
2025-11-28 23:38:11.716064: Current learning rate: 0.00975 
2025-11-28 23:39:46.188082: train_loss -0.09 
2025-11-28 23:39:46.188369: val_loss -0.1181 
2025-11-28 23:39:46.188621: Pseudo dice [0.0102, 0.5861, 0.5961, 0.0, 0.509, 0.1398, 0.7313, 0.759] 
2025-11-28 23:39:46.188788: Epoch time: 94.47 s 
2025-11-28 23:39:46.188912: Yayy! New best EMA pseudo Dice: 0.3114 
2025-11-28 23:39:49.159101:  
2025-11-28 23:39:49.159451: Epoch 29 
2025-11-28 23:39:49.159643: Current learning rate: 0.00974 
2025-11-28 23:41:24.041044: train_loss -0.1017 
2025-11-28 23:41:24.041397: val_loss -0.1095 
2025-11-28 23:41:24.041629: Pseudo dice [0.1008, 0.6904, 0.4298, 0.4091, 0.4837, 0.0466, 0.6582, 0.7828] 
2025-11-28 23:41:24.041750: Epoch time: 94.88 s 
2025-11-28 23:41:24.041825: Yayy! New best EMA pseudo Dice: 0.3253 
2025-11-28 23:41:26.906936:  
2025-11-28 23:41:26.907305: Epoch 30 
2025-11-28 23:41:26.907492: Current learning rate: 0.00973 
2025-11-28 23:43:01.155016: train_loss -0.1026 
2025-11-28 23:43:01.155293: val_loss -0.116 
2025-11-28 23:43:01.155483: Pseudo dice [0.7441, 0.0, 0.0, 0.5869, 0.7122, 0.0, 0.6087, 0.7801] 
2025-11-28 23:43:01.155609: Epoch time: 94.25 s 
2025-11-28 23:43:01.155742: Yayy! New best EMA pseudo Dice: 0.3357 
2025-11-28 23:43:03.970652:  
2025-11-28 23:43:03.970822: Epoch 31 
2025-11-28 23:43:03.971093: Current learning rate: 0.00972 
2025-11-28 23:44:38.175104: train_loss -0.1089 
2025-11-28 23:44:38.175393: val_loss -0.1496 
2025-11-28 23:44:38.175602: Pseudo dice [0.0, 0.5801, 0.4329, 0.4316, 0.0, 0.5111, 0.7076, 0.8176] 
2025-11-28 23:44:38.175747: Epoch time: 94.21 s 
2025-11-28 23:44:38.175874: Yayy! New best EMA pseudo Dice: 0.3456 
2025-11-28 23:44:41.079203:  
2025-11-28 23:44:41.079513: Epoch 32 
2025-11-28 23:44:41.079684: Current learning rate: 0.00971 
2025-11-28 23:46:15.440785: train_loss -0.1212 
2025-11-28 23:46:15.440981: val_loss -0.1349 
2025-11-28 23:46:15.441112: Pseudo dice [0.0, 0.5832, 0.0429, 0.6579, 0.532, 0.0, 0.7415, 0.8457] 
2025-11-28 23:46:15.441253: Epoch time: 94.36 s 
2025-11-28 23:46:15.441382: Yayy! New best EMA pseudo Dice: 0.3536 
2025-11-28 23:46:18.227694:  
2025-11-28 23:46:18.228044: Epoch 33 
2025-11-28 23:46:18.228244: Current learning rate: 0.0097 
2025-11-28 23:47:53.805427: train_loss -0.1255 
2025-11-28 23:47:53.805716: val_loss -0.1532 
2025-11-28 23:47:53.805932: Pseudo dice [0.5597, 0.0, 0.2957, 0.5866, 0.5923, 0.0, 0.7983, 0.8716] 
2025-11-28 23:47:53.806092: Epoch time: 95.58 s 
2025-11-28 23:47:53.806257: Yayy! New best EMA pseudo Dice: 0.3645 
2025-11-28 23:47:56.665974:  
2025-11-28 23:47:56.666351: Epoch 34 
2025-11-28 23:47:56.666542: Current learning rate: 0.00969 
2025-11-28 23:49:30.722389: train_loss -0.1105 
2025-11-28 23:49:30.722656: val_loss -0.155 
2025-11-28 23:49:30.723002: Pseudo dice [0.0, 0.5386, 0.0098, 0.6145, 0.659, 0.0634, 0.7774, 0.8407] 
2025-11-28 23:49:30.723193: Epoch time: 94.06 s 
2025-11-28 23:49:30.723364: Yayy! New best EMA pseudo Dice: 0.3719 
2025-11-28 23:49:33.520765:  
2025-11-28 23:49:33.521069: Epoch 35 
2025-11-28 23:49:33.521281: Current learning rate: 0.00968 
2025-11-28 23:51:08.118248: train_loss -0.1137 
2025-11-28 23:51:08.118494: val_loss -0.1474 
2025-11-28 23:51:08.118703: Pseudo dice [0.6124, 0.0054, 0.4299, 0.0, 0.0, 0.3481, 0.7472, 0.7576] 
2025-11-28 23:51:08.118865: Epoch time: 94.6 s 
2025-11-28 23:51:09.969948:  
2025-11-28 23:51:09.970095: Epoch 36 
2025-11-28 23:51:09.970279: Current learning rate: 0.00968 
2025-11-28 23:52:44.222348: train_loss -0.1249 
2025-11-28 23:52:44.222582: val_loss -0.1325 
2025-11-28 23:52:44.222771: Pseudo dice [0.0167, 0.6509, 0.0319, 0.5335, 0.0, 0.5584, 0.7885, 0.8333] 
2025-11-28 23:52:44.222922: Epoch time: 94.25 s 
2025-11-28 23:52:44.223021: Yayy! New best EMA pseudo Dice: 0.3765 
2025-11-28 23:52:46.997818:  
2025-11-28 23:52:46.998191: Epoch 37 
2025-11-28 23:52:46.998365: Current learning rate: 0.00967 
2025-11-28 23:54:21.333651: train_loss -0.1313 
2025-11-28 23:54:21.333946: val_loss -0.1295 
2025-11-28 23:54:21.334177: Pseudo dice [0.7467, 0.0, 0.6866, 0.0, 0.6098, 0.0, 0.7252, 0.8195] 
2025-11-28 23:54:21.334345: Epoch time: 94.34 s 
2025-11-28 23:54:21.334459: Yayy! New best EMA pseudo Dice: 0.3837 
2025-11-28 23:54:24.131392:  
2025-11-28 23:54:24.131708: Epoch 38 
2025-11-28 23:54:24.131883: Current learning rate: 0.00966 
2025-11-28 23:56:00.019358: train_loss -0.1243 
2025-11-28 23:56:00.019583: val_loss -0.1699 
2025-11-28 23:56:00.019737: Pseudo dice [0.032, 0.5678, 0.0365, 0.5397, 0.5638, 0.1987, 0.8066, 0.864] 
2025-11-28 23:56:00.019830: Epoch time: 95.89 s 
2025-11-28 23:56:00.019901: Yayy! New best EMA pseudo Dice: 0.3905 
2025-11-28 23:56:02.885720:  
2025-11-28 23:56:02.885997: Epoch 39 
2025-11-28 23:56:02.886184: Current learning rate: 0.00965 
2025-11-28 23:57:38.168525: train_loss -0.1394 
2025-11-28 23:57:38.168812: val_loss -0.1515 
2025-11-28 23:57:38.169327: Pseudo dice [0.0, 0.5874, 0.5817, 0.0062, 0.0057, 0.6693, 0.7507, 0.8667] 
2025-11-28 23:57:38.169479: Epoch time: 95.28 s 
2025-11-28 23:57:38.169594: Yayy! New best EMA pseudo Dice: 0.3948 
2025-11-28 23:57:41.041250:  
2025-11-28 23:57:41.041471: Epoch 40 
2025-11-28 23:57:41.041631: Current learning rate: 0.00964 
2025-11-28 23:59:15.750958: train_loss -0.1271 
2025-11-28 23:59:15.751216: val_loss -0.1503 
2025-11-28 23:59:15.751492: Pseudo dice [0.4522, 0.0002, 0.0542, 0.6197, 0.5148, 0.0, 0.7443, 0.8501] 
2025-11-28 23:59:15.751609: Epoch time: 94.71 s 
2025-11-28 23:59:15.751690: Yayy! New best EMA pseudo Dice: 0.3957 
2025-11-28 23:59:18.708008:  
2025-11-28 23:59:18.708336: Epoch 41 
2025-11-28 23:59:18.708498: Current learning rate: 0.00963 
2025-11-29 00:00:53.862485: train_loss -0.1383 
2025-11-29 00:00:53.862682: val_loss -0.1488 
2025-11-29 00:00:53.862881: Pseudo dice [0.0, 0.647, 0.6178, 0.0, 0.6724, 0.0, 0.8218, 0.8363] 
2025-11-29 00:00:53.863078: Epoch time: 95.16 s 
2025-11-29 00:00:53.863208: Yayy! New best EMA pseudo Dice: 0.4011 
2025-11-29 00:00:56.689595:  
2025-11-29 00:00:56.689967: Epoch 42 
2025-11-29 00:00:56.690163: Current learning rate: 0.00962 
2025-11-29 00:02:31.357025: train_loss -0.1285 
2025-11-29 00:02:31.357268: val_loss -0.1217 
2025-11-29 00:02:31.357418: Pseudo dice [0.0, 0.5322, 0.0, 0.4991, 0.0002, 0.4897, 0.8312, 0.8502] 
2025-11-29 00:02:31.357537: Epoch time: 94.67 s 
2025-11-29 00:02:33.419718:  
2025-11-29 00:02:33.420023: Epoch 43 
2025-11-29 00:02:33.420214: Current learning rate: 0.00961 
2025-11-29 00:04:07.672123: train_loss -0.1209 
2025-11-29 00:04:07.672420: val_loss -0.1571 
2025-11-29 00:04:07.672750: Pseudo dice [0.0, 0.5991, 0.6781, 0.0, 0.0, 0.6343, 0.7902, 0.8558] 
2025-11-29 00:04:07.673017: Epoch time: 94.25 s 
2025-11-29 00:04:07.673105: Yayy! New best EMA pseudo Dice: 0.4054 
2025-11-29 00:04:10.550048:  
2025-11-29 00:04:10.550396: Epoch 44 
2025-11-29 00:04:10.550584: Current learning rate: 0.0096 
2025-11-29 00:05:45.485365: train_loss -0.1433 
2025-11-29 00:05:45.485641: val_loss -0.1537 
2025-11-29 00:05:45.485840: Pseudo dice [0.0063, 0.6951, 0.6376, 0.0, 0.5331, 0.0424, 0.8389, 0.8541] 
2025-11-29 00:05:45.485968: Epoch time: 94.94 s 
2025-11-29 00:05:45.486133: Yayy! New best EMA pseudo Dice: 0.4099 
2025-11-29 00:05:48.249840:  
2025-11-29 00:05:48.250177: Epoch 45 
2025-11-29 00:05:48.250357: Current learning rate: 0.00959 
2025-11-29 00:07:23.985005: train_loss -0.1345 
2025-11-29 00:07:23.985362: val_loss -0.1533 
2025-11-29 00:07:23.985590: Pseudo dice [0.0, 0.5994, 0.5284, 0.0191, 0.0, 0.6312, 0.8369, 0.8747] 
2025-11-29 00:07:23.985728: Epoch time: 95.74 s 
2025-11-29 00:07:23.985836: Yayy! New best EMA pseudo Dice: 0.4126 
2025-11-29 00:07:26.753504:  
2025-11-29 00:07:26.753745: Epoch 46 
2025-11-29 00:07:26.753930: Current learning rate: 0.00959 
2025-11-29 00:09:01.812634: train_loss -0.1421 
2025-11-29 00:09:01.812881: val_loss -0.1656 
2025-11-29 00:09:01.813090: Pseudo dice [0.6853, 0.0029, 0.643, 0.0, 0.0, 0.7033, 0.8101, 0.8437] 
2025-11-29 00:09:01.813274: Epoch time: 95.06 s 
2025-11-29 00:09:01.813426: Yayy! New best EMA pseudo Dice: 0.4174 
2025-11-29 00:09:04.536542:  
2025-11-29 00:09:04.536871: Epoch 47 
2025-11-29 00:09:04.537079: Current learning rate: 0.00958 
2025-11-29 00:10:39.495213: train_loss -0.1489 
2025-11-29 00:10:39.495417: val_loss -0.1674 
2025-11-29 00:10:39.495618: Pseudo dice [0.6727, 0.0793, 0.6221, 0.0, 0.4867, 0.0004, 0.8358, 0.8667] 
2025-11-29 00:10:39.495788: Epoch time: 94.96 s 
2025-11-29 00:10:39.496001: Yayy! New best EMA pseudo Dice: 0.4202 
2025-11-29 00:10:42.257568:  
2025-11-29 00:10:42.257877: Epoch 48 
2025-11-29 00:10:42.258078: Current learning rate: 0.00957 
2025-11-29 00:12:17.170431: train_loss -0.1301 
2025-11-29 00:12:17.170679: val_loss -0.1582 
2025-11-29 00:12:17.170929: Pseudo dice [0.5691, 0.0001, 0.6097, 0.0181, 0.6624, 0.0, 0.8439, 0.8271] 
2025-11-29 00:12:17.171072: Epoch time: 94.91 s 
2025-11-29 00:12:17.171274: Yayy! New best EMA pseudo Dice: 0.4223 
2025-11-29 00:12:20.044611:  
2025-11-29 00:12:20.044980: Epoch 49 
2025-11-29 00:12:20.045187: Current learning rate: 0.00956 
2025-11-29 00:13:54.280584: train_loss -0.1533 
2025-11-29 00:13:54.280850: val_loss -0.152 
2025-11-29 00:13:54.281035: Pseudo dice [0.453, 0.0121, 0.4479, 0.1326, 0.4385, 0.0, 0.8298, 0.837] 
2025-11-29 00:13:54.281200: Epoch time: 94.24 s 
2025-11-29 00:13:56.724347:  
2025-11-29 00:13:56.724657: Epoch 50 
2025-11-29 00:13:56.724854: Current learning rate: 0.00955 
2025-11-29 00:15:30.925419: train_loss -0.1629 
2025-11-29 00:15:30.925703: val_loss -0.1783 
2025-11-29 00:15:30.925933: Pseudo dice [0.0, 0.657, 0.0, 0.6635, 0.6627, 0.0, 0.8007, 0.8625] 
2025-11-29 00:15:30.926107: Epoch time: 94.2 s 
2025-11-29 00:15:30.926273: Yayy! New best EMA pseudo Dice: 0.4231 
2025-11-29 00:15:33.609920:  
2025-11-29 00:15:33.610247: Epoch 51 
2025-11-29 00:15:33.610421: Current learning rate: 0.00954 
2025-11-29 00:17:07.541698: train_loss -0.1498 
2025-11-29 00:17:07.541934: val_loss -0.156 
2025-11-29 00:17:07.542184: Pseudo dice [0.0, 0.6243, 0.0377, 0.6526, 0.0, 0.6903, 0.7394, 0.8591] 
2025-11-29 00:17:07.542433: Epoch time: 93.93 s 
2025-11-29 00:17:07.542548: Yayy! New best EMA pseudo Dice: 0.4258 
2025-11-29 00:17:10.242492:  
2025-11-29 00:17:10.242680: Epoch 52 
2025-11-29 00:17:10.242846: Current learning rate: 0.00953 
2025-11-29 00:18:44.505636: train_loss -0.1522 
2025-11-29 00:18:44.505884: val_loss -0.1824 
2025-11-29 00:18:44.506193: Pseudo dice [0.556, 0.224, 0.5918, 0.0504, 0.6915, 0.2822, 0.8361, 0.8764] 
2025-11-29 00:18:44.506315: Epoch time: 94.26 s 
2025-11-29 00:18:44.506386: Yayy! New best EMA pseudo Dice: 0.4346 
2025-11-29 00:18:47.255885:  
2025-11-29 00:18:47.256252: Epoch 53 
2025-11-29 00:18:47.256448: Current learning rate: 0.00952 
2025-11-29 00:20:21.360358: train_loss -0.1483 
2025-11-29 00:20:21.360596: val_loss -0.1625 
2025-11-29 00:20:21.360799: Pseudo dice [0.6594, 0.0006, 0.0, 0.5856, 0.4805, 0.3358, 0.7819, 0.8323] 
2025-11-29 00:20:21.361044: Epoch time: 94.11 s 
2025-11-29 00:20:21.361165: Yayy! New best EMA pseudo Dice: 0.4371 
2025-11-29 00:20:24.070445:  
2025-11-29 00:20:24.070819: Epoch 54 
2025-11-29 00:20:24.070999: Current learning rate: 0.00951 
2025-11-29 00:21:58.656412: train_loss -0.1403 
2025-11-29 00:21:58.656773: val_loss -0.1295 
2025-11-29 00:21:58.657026: Pseudo dice [0.0, 0.6212, 0.7188, 0.0004, 0.569, 0.0946, 0.8176, 0.8074] 
2025-11-29 00:21:58.657226: Epoch time: 94.59 s 
2025-11-29 00:21:58.657354: Yayy! New best EMA pseudo Dice: 0.4388 
2025-11-29 00:22:01.501221:  
2025-11-29 00:22:01.501614: Epoch 55 
2025-11-29 00:22:01.501818: Current learning rate: 0.0095 
2025-11-29 00:23:36.312926: train_loss -0.1545 
2025-11-29 00:23:36.313342: val_loss -0.1728 
2025-11-29 00:23:36.313597: Pseudo dice [0.0, 0.604, 0.6869, 0.0, 0.0, 0.645, 0.7736, 0.809] 
2025-11-29 00:23:36.313766: Epoch time: 94.81 s 
2025-11-29 00:23:36.313898: Yayy! New best EMA pseudo Dice: 0.4389 
2025-11-29 00:23:39.112965:  
2025-11-29 00:23:39.113314: Epoch 56 
2025-11-29 00:23:39.113548: Current learning rate: 0.00949 
2025-11-29 00:25:14.423477: train_loss -0.1514 
2025-11-29 00:25:14.423743: val_loss -0.1734 
2025-11-29 00:25:14.423993: Pseudo dice [0.0, 0.5918, 0.6124, 0.0, 0.5378, 0.0001, 0.823, 0.8841] 
2025-11-29 00:25:14.424330: Epoch time: 95.31 s 
2025-11-29 00:25:16.437618:  
2025-11-29 00:25:16.437943: Epoch 57 
2025-11-29 00:25:16.438112: Current learning rate: 0.00949 
2025-11-29 00:26:51.723578: train_loss -0.1556 
2025-11-29 00:26:51.724016: val_loss -0.1577 
2025-11-29 00:26:51.724253: Pseudo dice [0.0, 0.6633, 0.5788, 0.0, 0.0, 0.517, 0.7658, 0.8461] 
2025-11-29 00:26:51.724394: Epoch time: 95.29 s 
2025-11-29 00:26:53.869996:  
2025-11-29 00:26:53.870416: Epoch 58 
2025-11-29 00:26:53.870610: Current learning rate: 0.00948 
2025-11-29 00:28:30.069260: train_loss -0.1406 
2025-11-29 00:28:30.069585: val_loss -0.1611 
2025-11-29 00:28:30.069866: Pseudo dice [0.0994, 0.6322, 0.0746, 0.5924, 0.6219, 0.0, 0.8313, 0.8645] 
2025-11-29 00:28:30.070073: Epoch time: 96.2 s 
2025-11-29 00:28:30.070225: Yayy! New best EMA pseudo Dice: 0.4392 
2025-11-29 00:28:33.075564:  
2025-11-29 00:28:33.075955: Epoch 59 
2025-11-29 00:28:33.076155: Current learning rate: 0.00947 
2025-11-29 00:30:08.153516: train_loss -0.1558 
2025-11-29 00:30:08.153784: val_loss -0.1753 
2025-11-29 00:30:08.154045: Pseudo dice [0.1092, 0.7159, 0.5894, 0.0, 0.5985, 0.0033, 0.8686, 0.8753] 
2025-11-29 00:30:08.154190: Epoch time: 95.08 s 
2025-11-29 00:30:08.154296: Yayy! New best EMA pseudo Dice: 0.4423 
2025-11-29 00:30:12.110599:  
2025-11-29 00:30:12.111021: Epoch 60 
2025-11-29 00:30:12.111234: Current learning rate: 0.00946 
2025-11-29 00:31:48.319591: train_loss -0.1515 
2025-11-29 00:31:48.319924: val_loss -0.1619 
2025-11-29 00:31:48.320223: Pseudo dice [0.6292, 0.0003, 0.4725, 0.4496, 0.0, 0.4871, 0.8051, 0.8721] 
2025-11-29 00:31:48.320403: Epoch time: 96.21 s 
2025-11-29 00:31:48.320544: Yayy! New best EMA pseudo Dice: 0.4445 
2025-11-29 00:31:51.144083:  
2025-11-29 00:31:51.144360: Epoch 61 
2025-11-29 00:31:51.144592: Current learning rate: 0.00945 
2025-11-29 00:33:27.925899: train_loss -0.1508 
2025-11-29 00:33:27.926131: val_loss -0.1816 
2025-11-29 00:33:27.926336: Pseudo dice [0.6134, 0.0006, 0.5664, 0.2104, 0.648, 0.2123, 0.7689, 0.8716] 
2025-11-29 00:33:27.926433: Epoch time: 96.78 s 
2025-11-29 00:33:27.926511: Yayy! New best EMA pseudo Dice: 0.4487 
2025-11-29 00:33:30.799469:  
2025-11-29 00:33:30.799837: Epoch 62 
2025-11-29 00:33:30.800012: Current learning rate: 0.00944 
2025-11-29 00:35:06.025293: train_loss -0.1542 
2025-11-29 00:35:06.025796: val_loss -0.1714 
2025-11-29 00:35:06.025998: Pseudo dice [0.0, 0.6537, 0.0, 0.4875, 0.0, 0.7816, 0.8264, 0.8591] 
2025-11-29 00:35:06.026131: Epoch time: 95.23 s 
2025-11-29 00:35:06.026647: Yayy! New best EMA pseudo Dice: 0.449 
2025-11-29 00:35:08.790409:  
2025-11-29 00:35:08.790819: Epoch 63 
2025-11-29 00:35:08.790991: Current learning rate: 0.00943 
2025-11-29 00:36:44.623136: train_loss -0.1834 
2025-11-29 00:36:44.623431: val_loss -0.1795 
2025-11-29 00:36:44.623657: Pseudo dice [0.0, 0.6243, 0.0, 0.4814, 0.6684, 0.0319, 0.8439, 0.8998] 
2025-11-29 00:36:44.623817: Epoch time: 95.83 s 
2025-11-29 00:36:46.631011:  
2025-11-29 00:36:46.631366: Epoch 64 
2025-11-29 00:36:46.631580: Current learning rate: 0.00942 
2025-11-29 00:38:22.388699: train_loss -0.1611 
2025-11-29 00:38:22.389010: val_loss -0.1733 
2025-11-29 00:38:22.389256: Pseudo dice [0.625, 0.0003, 0.6382, 0.0, 0.6816, 0.0003, 0.862, 0.8636] 
2025-11-29 00:38:22.389409: Epoch time: 95.76 s 
2025-11-29 00:38:22.389659: Yayy! New best EMA pseudo Dice: 0.4495 
2025-11-29 00:38:25.177633:  
2025-11-29 00:38:25.177932: Epoch 65 
2025-11-29 00:38:25.178216: Current learning rate: 0.00941 
2025-11-29 00:40:01.653538: train_loss -0.1605 
2025-11-29 00:40:01.653885: val_loss -0.1698 
2025-11-29 00:40:01.654223: Pseudo dice [0.5009, 0.0001, 0.0, 0.7449, 0.4396, 0.1006, 0.8324, 0.8775] 
2025-11-29 00:40:01.654469: Epoch time: 96.48 s 
2025-11-29 00:40:03.685515:  
2025-11-29 00:40:03.685891: Epoch 66 
2025-11-29 00:40:03.686062: Current learning rate: 0.0094 
2025-11-29 00:41:40.357099: train_loss -0.1594 
2025-11-29 00:41:40.357388: val_loss -0.1924 
2025-11-29 00:41:40.357619: Pseudo dice [0.222, 0.5522, 0.2798, 0.4549, 0.5116, 0.1257, 0.8819, 0.9161] 
2025-11-29 00:41:40.357936: Epoch time: 96.67 s 
2025-11-29 00:41:40.358059: Yayy! New best EMA pseudo Dice: 0.4527 
2025-11-29 00:41:43.144356:  
2025-11-29 00:41:43.144739: Epoch 67 
2025-11-29 00:41:43.144938: Current learning rate: 0.00939 
2025-11-29 00:43:18.697215: train_loss -0.1703 
2025-11-29 00:43:18.697468: val_loss -0.1857 
2025-11-29 00:43:18.697752: Pseudo dice [0.6955, 0.0095, 0.7642, 0.0013, 0.0, 0.4908, 0.8799, 0.9086] 
2025-11-29 00:43:18.698014: Epoch time: 95.55 s 
2025-11-29 00:43:18.698179: Yayy! New best EMA pseudo Dice: 0.4543 
2025-11-29 00:43:21.702316:  
2025-11-29 00:43:21.702733: Epoch 68 
2025-11-29 00:43:21.702945: Current learning rate: 0.00939 
2025-11-29 00:44:57.694104: train_loss -0.1602 
2025-11-29 00:44:57.694423: val_loss -0.1807 
2025-11-29 00:44:57.694597: Pseudo dice [0.0005, 0.6299, 0.0, 0.6047, 0.0, 0.6655, 0.8837, 0.9014] 
2025-11-29 00:44:57.694703: Epoch time: 95.99 s 
2025-11-29 00:44:57.694840: Yayy! New best EMA pseudo Dice: 0.4549 
2025-11-29 00:45:00.649359:  
2025-11-29 00:45:00.649717: Epoch 69 
2025-11-29 00:45:00.649913: Current learning rate: 0.00938 
2025-11-29 00:46:36.680040: train_loss -0.1685 
2025-11-29 00:46:36.680491: val_loss -0.1673 
2025-11-29 00:46:36.680656: Pseudo dice [0.0004, 0.6719, 0.0, 0.5761, 0.5423, 0.0, 0.8836, 0.8901] 
2025-11-29 00:46:36.680759: Epoch time: 96.03 s 
2025-11-29 00:46:38.724634:  
2025-11-29 00:46:38.724996: Epoch 70 
2025-11-29 00:46:38.725188: Current learning rate: 0.00937 
2025-11-29 00:48:14.808883: train_loss -0.1525 
2025-11-29 00:48:14.809166: val_loss -0.1621 
2025-11-29 00:48:14.809403: Pseudo dice [0.0045, 0.5273, 0.6398, 0.0, 0.0, 0.2874, 0.8124, 0.8145] 
2025-11-29 00:48:14.809555: Epoch time: 96.09 s 
2025-11-29 00:48:16.883717:  
2025-11-29 00:48:16.884036: Epoch 71 
2025-11-29 00:48:16.884247: Current learning rate: 0.00936 
2025-11-29 00:49:52.801315: train_loss -0.1787 
2025-11-29 00:49:52.801622: val_loss -0.1657 
2025-11-29 00:49:52.801804: Pseudo dice [0.0, 0.641, 0.0088, 0.5977, 0.6423, 0.0, 0.8739, 0.8784] 
2025-11-29 00:49:52.801981: Epoch time: 95.92 s 
2025-11-29 00:49:54.910133:  
2025-11-29 00:49:54.910499: Epoch 72 
2025-11-29 00:49:54.910696: Current learning rate: 0.00935 
2025-11-29 00:51:30.102046: train_loss -0.1676 
2025-11-29 00:51:30.102411: val_loss -0.1743 
2025-11-29 00:51:30.102616: Pseudo dice [0.0, 0.6657, 0.6532, 0.0, 0.0, 0.6573, 0.8412, 0.8771] 
2025-11-29 00:51:30.102742: Epoch time: 95.19 s 
2025-11-29 00:51:32.250829:  
2025-11-29 00:51:32.251078: Epoch 73 
2025-11-29 00:51:32.251430: Current learning rate: 0.00934 
2025-11-29 00:53:07.557283: train_loss -0.1517 
2025-11-29 00:53:07.557712: val_loss -0.1834 
2025-11-29 00:53:07.557938: Pseudo dice [0.1025, 0.5664, 0.5287, 0.0116, 0.0, 0.4772, 0.8774, 0.9019] 
2025-11-29 00:53:07.558091: Epoch time: 95.31 s 
2025-11-29 00:53:09.584841:  
2025-11-29 00:53:09.585245: Epoch 74 
2025-11-29 00:53:09.585455: Current learning rate: 0.00933 
2025-11-29 00:54:45.310449: train_loss -0.1577 
2025-11-29 00:54:45.310785: val_loss -0.1746 
2025-11-29 00:54:45.311083: Pseudo dice [0.6713, 0.041, 0.5896, 0.0252, 0.5442, 0.0218, 0.862, 0.8802] 
2025-11-29 00:54:45.311444: Epoch time: 95.73 s 
2025-11-29 00:54:47.467190:  
2025-11-29 00:54:47.467530: Epoch 75 
2025-11-29 00:54:47.467707: Current learning rate: 0.00932 
2025-11-29 00:56:22.801406: train_loss -0.1702 
2025-11-29 00:56:22.801666: val_loss -0.1518 
2025-11-29 00:56:22.801918: Pseudo dice [0.6103, 0.0002, 0.1636, 0.5021, 0.0, 0.5221, 0.9072, 0.8457] 
2025-11-29 00:56:22.802073: Epoch time: 95.34 s 
2025-11-29 00:56:24.965765:  
2025-11-29 00:56:24.966174: Epoch 76 
2025-11-29 00:56:24.966359: Current learning rate: 0.00931 
2025-11-29 00:58:00.066971: train_loss -0.175 
2025-11-29 00:58:00.067346: val_loss -0.1586 
2025-11-29 00:58:00.067595: Pseudo dice [0.4812, 0.0, 0.5664, 0.0, 0.6215, 0.0, 0.8719, 0.8806] 
2025-11-29 00:58:00.067745: Epoch time: 95.1 s 
2025-11-29 00:58:02.203334:  
2025-11-29 00:58:02.203645: Epoch 77 
2025-11-29 00:58:02.203822: Current learning rate: 0.0093 
2025-11-29 00:59:37.621728: train_loss -0.1717 
2025-11-29 00:59:37.622068: val_loss -0.1782 
2025-11-29 00:59:37.622348: Pseudo dice [0.0, 0.6958, 0.5401, 0.0, 0.5476, 0.0931, 0.8645, 0.8914] 
2025-11-29 00:59:37.622498: Epoch time: 95.42 s 
2025-11-29 00:59:39.682905:  
2025-11-29 00:59:39.683262: Epoch 78 
2025-11-29 00:59:39.683504: Current learning rate: 0.0093 
2025-11-29 01:01:15.365767: train_loss -0.1714 
2025-11-29 01:01:15.366057: val_loss -0.1906 
2025-11-29 01:01:15.366320: Pseudo dice [0.0006, 0.6727, 0.0064, 0.7119, 0.6613, 0.002, 0.8837, 0.8902] 
2025-11-29 01:01:15.366459: Epoch time: 95.68 s 
2025-11-29 01:01:17.464805:  
2025-11-29 01:01:17.465106: Epoch 79 
2025-11-29 01:01:17.465309: Current learning rate: 0.00929 
2025-11-29 01:02:52.218936: train_loss -0.1677 
2025-11-29 01:02:52.219223: val_loss -0.2067 
2025-11-29 01:02:52.219565: Pseudo dice [0.764, 0.0, 0.0002, 0.6592, 0.7832, 0.0, 0.8405, 0.8817] 
2025-11-29 01:02:52.219715: Epoch time: 94.76 s 
2025-11-29 01:02:55.182424:  
2025-11-29 01:02:55.182741: Epoch 80 
2025-11-29 01:02:55.182911: Current learning rate: 0.00928 
2025-11-29 01:04:30.225138: train_loss -0.1643 
2025-11-29 01:04:30.225537: val_loss -0.1994 
2025-11-29 01:04:30.225823: Pseudo dice [0.6175, 0.0025, 0.6124, 0.3501, 0.0, 0.6972, 0.8868, 0.9081] 
2025-11-29 01:04:30.225986: Epoch time: 95.04 s 
2025-11-29 01:04:30.226104: Yayy! New best EMA pseudo Dice: 0.4596 
2025-11-29 01:04:33.105003:  
2025-11-29 01:04:33.105208: Epoch 81 
2025-11-29 01:04:33.105445: Current learning rate: 0.00927 
2025-11-29 01:06:08.156815: train_loss -0.1705 
2025-11-29 01:06:08.157122: val_loss -0.1802 
2025-11-29 01:06:08.157347: Pseudo dice [0.0, 0.531, 0.0, 0.3623, 0.5989, 0.0727, 0.9174, 0.8925] 
2025-11-29 01:06:08.157499: Epoch time: 95.05 s 
2025-11-29 01:06:10.128476:  
2025-11-29 01:06:10.128795: Epoch 82 
2025-11-29 01:06:10.128973: Current learning rate: 0.00926 
2025-11-29 01:07:45.463454: train_loss -0.1648 
2025-11-29 01:07:45.463777: val_loss -0.1651 
2025-11-29 01:07:45.464059: Pseudo dice [0.3311, 0.5292, 0.6027, 0.0008, 0.8107, 0.001, 0.8245, 0.8585] 
2025-11-29 01:07:45.464241: Epoch time: 95.34 s 
2025-11-29 01:07:45.464365: Yayy! New best EMA pseudo Dice: 0.4597 
2025-11-29 01:07:48.090216:  
2025-11-29 01:07:48.090531: Epoch 83 
2025-11-29 01:07:48.090696: Current learning rate: 0.00925 
2025-11-29 01:09:23.055416: train_loss -0.1682 
2025-11-29 01:09:23.055729: val_loss -0.1541 
2025-11-29 01:09:23.055944: Pseudo dice [0.574, 0.0212, 0.601, 0.0015, 0.581, 0.0, 0.8357, 0.8791] 
2025-11-29 01:09:23.056077: Epoch time: 94.97 s 
2025-11-29 01:09:24.938336:  
2025-11-29 01:09:24.938611: Epoch 84 
2025-11-29 01:09:24.938791: Current learning rate: 0.00924 
2025-11-29 01:10:59.730967: train_loss -0.1722 
2025-11-29 01:10:59.731360: val_loss -0.1958 
2025-11-29 01:10:59.731666: Pseudo dice [0.6117, 0.0, 0.6689, 0.0, 0.0001, 0.6235, 0.8685, 0.8911] 
2025-11-29 01:10:59.731838: Epoch time: 94.79 s 
2025-11-29 01:11:01.658797:  
2025-11-29 01:11:01.659030: Epoch 85 
2025-11-29 01:11:01.659269: Current learning rate: 0.00923 
2025-11-29 01:12:36.501743: train_loss -0.1685 
2025-11-29 01:12:36.502049: val_loss -0.1682 
2025-11-29 01:12:36.502294: Pseudo dice [0.0015, 0.5295, 0.1938, 0.5503, 0.5964, 0.007, 0.8496, 0.8694] 
2025-11-29 01:12:36.502482: Epoch time: 94.84 s 
2025-11-29 01:12:38.479327:  
2025-11-29 01:12:38.479657: Epoch 86 
2025-11-29 01:12:38.479879: Current learning rate: 0.00922 
2025-11-29 01:14:12.881346: train_loss -0.1791 
2025-11-29 01:14:12.881603: val_loss -0.1934 
2025-11-29 01:14:12.881748: Pseudo dice [0.0093, 0.5816, 0.0056, 0.7252, 0.0, 0.4098, 0.8964, 0.8891] 
2025-11-29 01:14:12.881860: Epoch time: 94.4 s 
2025-11-29 01:14:14.875266:  
2025-11-29 01:14:14.875554: Epoch 87 
2025-11-29 01:14:14.875721: Current learning rate: 0.00921 
2025-11-29 01:15:50.081804: train_loss -0.1847 
2025-11-29 01:15:50.082050: val_loss -0.1857 
2025-11-29 01:15:50.082284: Pseudo dice [0.0002, 0.612, 0.0439, 0.6254, 0.6948, 0.0053, 0.8419, 0.8973] 
2025-11-29 01:15:50.082430: Epoch time: 95.21 s 
2025-11-29 01:15:52.041254:  
2025-11-29 01:15:52.041665: Epoch 88 
2025-11-29 01:15:52.041860: Current learning rate: 0.0092 
2025-11-29 01:17:26.915352: train_loss -0.18 
2025-11-29 01:17:26.915619: val_loss -0.1848 
2025-11-29 01:17:26.915806: Pseudo dice [0.0, 0.6332, 0.0024, 0.5084, 0.0498, 0.3719, 0.858, 0.8845] 
2025-11-29 01:17:26.915930: Epoch time: 94.88 s 
2025-11-29 01:17:28.883617:  
2025-11-29 01:17:28.883840: Epoch 89 
2025-11-29 01:17:28.884021: Current learning rate: 0.0092 
2025-11-29 01:19:03.946767: train_loss -0.1779 
2025-11-29 01:19:03.947043: val_loss -0.1911 
2025-11-29 01:19:03.947302: Pseudo dice [0.0, 0.6393, 0.0, 0.6397, 0.7334, 0.0, 0.8915, 0.9078] 
2025-11-29 01:19:03.947447: Epoch time: 95.06 s 
2025-11-29 01:19:05.860778:  
2025-11-29 01:19:05.861119: Epoch 90 
2025-11-29 01:19:05.861357: Current learning rate: 0.00919 
2025-11-29 01:20:40.349679: train_loss -0.1684 
2025-11-29 01:20:40.350193: val_loss -0.189 
2025-11-29 01:20:40.350376: Pseudo dice [0.5983, 0.0001, 0.0, 0.6392, 0.0, 0.5721, 0.8476, 0.8681] 
2025-11-29 01:20:40.350481: Epoch time: 94.49 s 
2025-11-29 01:20:42.261726:  
2025-11-29 01:20:42.262088: Epoch 91 
2025-11-29 01:20:42.262320: Current learning rate: 0.00918 
2025-11-29 01:22:16.841772: train_loss -0.1756 
2025-11-29 01:22:16.842043: val_loss -0.2 
2025-11-29 01:22:16.842313: Pseudo dice [0.1808, 0.633, 0.0, 0.6873, 0.5926, 0.007, 0.8534, 0.9024] 
2025-11-29 01:22:16.842544: Epoch time: 94.58 s 
2025-11-29 01:22:18.665215:  
2025-11-29 01:22:18.665546: Epoch 92 
2025-11-29 01:22:18.665743: Current learning rate: 0.00917 
2025-11-29 01:23:52.666028: train_loss -0.1752 
2025-11-29 01:23:52.666444: val_loss -0.1852 
2025-11-29 01:23:52.666651: Pseudo dice [0.3153, 0.4866, 0.7313, 0.0, 0.5977, 0.0, 0.8629, 0.8793] 
2025-11-29 01:23:52.666782: Epoch time: 94.0 s 
2025-11-29 01:23:54.531797:  
2025-11-29 01:23:54.532078: Epoch 93 
2025-11-29 01:23:54.532263: Current learning rate: 0.00916 
2025-11-29 01:25:28.844783: train_loss -0.1721 
2025-11-29 01:25:28.845262: val_loss -0.1869 
2025-11-29 01:25:28.845494: Pseudo dice [0.4948, 0.3948, 0.0, 0.6633, 0.6278, 0.0, 0.8746, 0.8539] 
2025-11-29 01:25:28.845660: Epoch time: 94.31 s 
2025-11-29 01:25:28.845800: Yayy! New best EMA pseudo Dice: 0.4616 
2025-11-29 01:25:31.834737:  
2025-11-29 01:25:31.835075: Epoch 94 
2025-11-29 01:25:31.835249: Current learning rate: 0.00915 
2025-11-29 01:27:06.597603: train_loss -0.1554 
2025-11-29 01:27:06.597864: val_loss -0.188 
2025-11-29 01:27:06.598053: Pseudo dice [0.6815, 0.06, 0.0164, 0.6762, 0.6808, 0.0011, 0.867, 0.8808] 
2025-11-29 01:27:06.598268: Epoch time: 94.76 s 
2025-11-29 01:27:06.598483: Yayy! New best EMA pseudo Dice: 0.4638 
2025-11-29 01:27:09.249041:  
2025-11-29 01:27:09.249352: Epoch 95 
2025-11-29 01:27:09.249545: Current learning rate: 0.00914 
2025-11-29 01:28:44.088343: train_loss -0.1643 
2025-11-29 01:28:44.088650: val_loss -0.226 
2025-11-29 01:28:44.088915: Pseudo dice [0.6033, 0.0017, 0.7111, 0.0, 0.0, 0.6777, 0.9256, 0.9248] 
2025-11-29 01:28:44.089132: Epoch time: 94.84 s 
2025-11-29 01:28:44.089316: Yayy! New best EMA pseudo Dice: 0.4654 
2025-11-29 01:28:46.803418:  
2025-11-29 01:28:46.803775: Epoch 96 
2025-11-29 01:28:46.803958: Current learning rate: 0.00913 
2025-11-29 01:30:21.434986: train_loss -0.1745 
2025-11-29 01:30:21.435270: val_loss -0.1871 
2025-11-29 01:30:21.435535: Pseudo dice [0.679, 0.0019, 0.6313, 0.0, 0.6862, 0.0104, 0.8815, 0.8878] 
2025-11-29 01:30:21.435727: Epoch time: 94.63 s 
2025-11-29 01:30:21.435843: Yayy! New best EMA pseudo Dice: 0.4661 
2025-11-29 01:30:24.272625:  
2025-11-29 01:30:24.272922: Epoch 97 
2025-11-29 01:30:24.273094: Current learning rate: 0.00912 
2025-11-29 01:31:58.969492: train_loss -0.1886 
2025-11-29 01:31:58.969785: val_loss -0.1934 
2025-11-29 01:31:58.970030: Pseudo dice [0.6683, 0.3051, 0.003, 0.5084, 0.6828, 0.1054, 0.8928, 0.8853] 
2025-11-29 01:31:58.970332: Epoch time: 94.7 s 
2025-11-29 01:31:58.970623: Yayy! New best EMA pseudo Dice: 0.4701 
2025-11-29 01:32:01.740373:  
2025-11-29 01:32:01.740664: Epoch 98 
2025-11-29 01:32:01.740818: Current learning rate: 0.00911 
2025-11-29 01:33:36.605736: train_loss -0.1696 
2025-11-29 01:33:36.606076: val_loss -0.166 
2025-11-29 01:33:36.606357: Pseudo dice [0.0, 0.5645, 0.0, 0.6485, 0.7192, 0.0, 0.8582, 0.8913] 
2025-11-29 01:33:36.606535: Epoch time: 94.87 s 
2025-11-29 01:33:38.530401:  
2025-11-29 01:33:38.530720: Epoch 99 
2025-11-29 01:33:38.530897: Current learning rate: 0.0091 
2025-11-29 01:35:13.351709: train_loss -0.1866 
2025-11-29 01:35:13.352134: val_loss -0.1744 
2025-11-29 01:35:13.352493: Pseudo dice [0.6181, 0.0027, 0.5538, 0.0, 0.6052, 0.0993, 0.8933, 0.9026] 
2025-11-29 01:35:13.352678: Epoch time: 94.82 s 
2025-11-29 01:35:16.165851:  
2025-11-29 01:35:16.166198: Epoch 100 
2025-11-29 01:35:16.166440: Current learning rate: 0.0091 
2025-11-29 01:36:50.859236: train_loss -0.1746 
2025-11-29 01:36:50.859446: val_loss -0.1973 
2025-11-29 01:36:50.859585: Pseudo dice [0.5606, 0.0401, 0.0, 0.6493, 0.5552, 0.0217, 0.9067, 0.9168] 
2025-11-29 01:36:50.859678: Epoch time: 94.69 s 
2025-11-29 01:36:52.880583:  
2025-11-29 01:36:52.880981: Epoch 101 
2025-11-29 01:36:52.881186: Current learning rate: 0.00909 
2025-11-29 01:38:27.927094: train_loss -0.1674 
2025-11-29 01:38:27.927452: val_loss -0.1957 
2025-11-29 01:38:27.927671: Pseudo dice [0.0, 0.7158, 0.558, 0.0, 0.0, 0.7019, 0.8931, 0.9077] 
2025-11-29 01:38:27.927832: Epoch time: 95.05 s 
2025-11-29 01:38:30.760945:  
2025-11-29 01:38:30.761325: Epoch 102 
2025-11-29 01:38:30.761506: Current learning rate: 0.00908 
2025-11-29 01:40:06.720012: train_loss -0.1883 
2025-11-29 01:40:06.720345: val_loss -0.182 
2025-11-29 01:40:06.720562: Pseudo dice [0.0036, 0.5077, 0.0, 0.5894, 0.0, 0.2727, 0.8796, 0.8965] 
2025-11-29 01:40:06.720706: Epoch time: 95.96 s 
2025-11-29 01:40:08.856813:  
2025-11-29 01:40:08.857072: Epoch 103 
2025-11-29 01:40:08.857298: Current learning rate: 0.00907 
2025-11-29 01:41:43.764340: train_loss -0.1783 
2025-11-29 01:41:43.764683: val_loss -0.1914 
2025-11-29 01:41:43.764905: Pseudo dice [0.0, 0.6226, 0.0, 0.5439, 0.5887, 0.0386, 0.8518, 0.8776] 
2025-11-29 01:41:43.765096: Epoch time: 94.91 s 
2025-11-29 01:41:45.638122:  
2025-11-29 01:41:45.638510: Epoch 104 
2025-11-29 01:41:45.638749: Current learning rate: 0.00906 
2025-11-29 01:43:20.117038: train_loss -0.1907 
2025-11-29 01:43:20.117311: val_loss -0.1967 
2025-11-29 01:43:20.117531: Pseudo dice [0.6756, 0.006, 0.6294, 0.0, 0.5911, 0.0157, 0.8844, 0.8811] 
2025-11-29 01:43:20.117662: Epoch time: 94.48 s 
2025-11-29 01:43:22.105467:  
2025-11-29 01:43:22.105851: Epoch 105 
2025-11-29 01:43:22.106034: Current learning rate: 0.00905 
2025-11-29 01:44:56.346436: train_loss -0.1827 
2025-11-29 01:44:56.346752: val_loss -0.1928 
2025-11-29 01:44:56.347020: Pseudo dice [0.6165, 0.0218, 0.5813, 0.0, 0.0, 0.7183, 0.8846, 0.9008] 
2025-11-29 01:44:56.347243: Epoch time: 94.24 s 
2025-11-29 01:44:58.218215:  
2025-11-29 01:44:58.218504: Epoch 106 
2025-11-29 01:44:58.218673: Current learning rate: 0.00904 
2025-11-29 01:46:33.194041: train_loss -0.1775 
2025-11-29 01:46:33.194354: val_loss -0.2128 
2025-11-29 01:46:33.194796: Pseudo dice [0.6486, 0.0045, 0.0, 0.6163, 0.5794, 0.0002, 0.8748, 0.8871] 
2025-11-29 01:46:33.194946: Epoch time: 94.98 s 
2025-11-29 01:46:35.278125:  
2025-11-29 01:46:35.278490: Epoch 107 
2025-11-29 01:46:35.278677: Current learning rate: 0.00903 
2025-11-29 01:48:10.210407: train_loss -0.165 
2025-11-29 01:48:10.210776: val_loss -0.2084 
2025-11-29 01:48:10.211131: Pseudo dice [0.0, 0.6108, 0.0054, 0.6368, 0.0, 0.805, 0.8655, 0.9083] 
2025-11-29 01:48:10.211306: Epoch time: 94.93 s 
2025-11-29 01:48:12.188751:  
2025-11-29 01:48:12.189071: Epoch 108 
2025-11-29 01:48:12.189282: Current learning rate: 0.00902 
2025-11-29 01:49:47.086670: train_loss -0.1772 
2025-11-29 01:49:47.086931: val_loss -0.2076 
2025-11-29 01:49:47.087117: Pseudo dice [0.0007, 0.6246, 0.692, 0.0049, 0.6545, 0.0073, 0.8543, 0.8758] 
2025-11-29 01:49:47.087387: Epoch time: 94.9 s 
2025-11-29 01:49:49.049947:  
2025-11-29 01:49:49.050281: Epoch 109 
2025-11-29 01:49:49.050490: Current learning rate: 0.00901 
2025-11-29 01:51:24.141858: train_loss -0.1753 
2025-11-29 01:51:24.142360: val_loss -0.1865 
2025-11-29 01:51:24.142627: Pseudo dice [0.709, 0.0024, 0.6932, 0.0, 0.0, 0.8788, 0.8389, 0.8993] 
2025-11-29 01:51:24.142773: Epoch time: 95.09 s 
2025-11-29 01:51:26.178102:  
2025-11-29 01:51:26.178438: Epoch 110 
2025-11-29 01:51:26.178615: Current learning rate: 0.009 
2025-11-29 01:53:00.760701: train_loss -0.1754 
2025-11-29 01:53:00.761180: val_loss -0.2059 
2025-11-29 01:53:00.761419: Pseudo dice [0.7008, 0.0104, 0.0, 0.5676, 0.5247, 0.0402, 0.8414, 0.9223] 
2025-11-29 01:53:00.761571: Epoch time: 94.58 s 
2025-11-29 01:53:02.733765:  
2025-11-29 01:53:02.734091: Epoch 111 
2025-11-29 01:53:02.734275: Current learning rate: 0.009 
2025-11-29 01:54:37.104465: train_loss -0.1771 
2025-11-29 01:54:37.104737: val_loss -0.1877 
2025-11-29 01:54:37.104991: Pseudo dice [0.6975, 0.0061, 0.6124, 0.0, 0.0, 0.53, 0.8696, 0.8627] 
2025-11-29 01:54:37.105189: Epoch time: 94.37 s 
2025-11-29 01:54:39.016227:  
2025-11-29 01:54:39.016651: Epoch 112 
2025-11-29 01:54:39.016834: Current learning rate: 0.00899 
2025-11-29 01:56:13.125188: train_loss -0.1839 
2025-11-29 01:56:13.125503: val_loss -0.2003 
2025-11-29 01:56:13.125761: Pseudo dice [0.262, 0.6623, 0.4009, 0.0, 0.6464, 0.2209, 0.8891, 0.8988] 
2025-11-29 01:56:13.125926: Epoch time: 94.11 s 
2025-11-29 01:56:15.154695:  
2025-11-29 01:56:15.155037: Epoch 113 
2025-11-29 01:56:15.155237: Current learning rate: 0.00898 
2025-11-29 01:57:49.597511: train_loss -0.1787 
2025-11-29 01:57:49.597781: val_loss -0.1967 
2025-11-29 01:57:49.598030: Pseudo dice [0.0, 0.6878, 0.624, 0.0, 0.0, 0.6636, 0.8812, 0.9081] 
2025-11-29 01:57:49.598215: Epoch time: 94.44 s 
2025-11-29 01:57:51.526723:  
2025-11-29 01:57:51.527074: Epoch 114 
2025-11-29 01:57:51.527283: Current learning rate: 0.00897 
2025-11-29 01:59:25.534826: train_loss -0.1986 
2025-11-29 01:59:25.535044: val_loss -0.216 
2025-11-29 01:59:25.535259: Pseudo dice [0.0, 0.6224, 0.5873, 0.0, 0.6798, 0.1044, 0.8873, 0.9084] 
2025-11-29 01:59:25.535480: Epoch time: 94.01 s 
2025-11-29 01:59:27.305739:  
2025-11-29 01:59:27.306087: Epoch 115 
2025-11-29 01:59:27.306301: Current learning rate: 0.00896 
2025-11-29 02:01:02.526765: train_loss -0.1886 
2025-11-29 02:01:02.526978: val_loss -0.1825 
2025-11-29 02:01:02.527248: Pseudo dice [0.6557, 0.0693, 0.0042, 0.7144, 0.7528, 0.0013, 0.8427, 0.8592] 
2025-11-29 02:01:02.527555: Epoch time: 95.22 s 
2025-11-29 02:01:04.653287:  
2025-11-29 02:01:04.653587: Epoch 116 
2025-11-29 02:01:04.653990: Current learning rate: 0.00895 
2025-11-29 02:02:39.287348: train_loss -0.1911 
2025-11-29 02:02:39.287569: val_loss -0.1817 
2025-11-29 02:02:39.287699: Pseudo dice [0.0, 0.5097, 0.0015, 0.5318, 0.0, 0.5194, 0.9077, 0.9121] 
2025-11-29 02:02:39.287831: Epoch time: 94.64 s 
2025-11-29 02:02:41.374174:  
2025-11-29 02:02:41.374480: Epoch 117 
2025-11-29 02:02:41.374666: Current learning rate: 0.00894 
2025-11-29 02:04:16.137770: train_loss -0.1894 
2025-11-29 02:04:16.138018: val_loss -0.1948 
2025-11-29 02:04:16.138255: Pseudo dice [0.6772, 0.0558, 0.0311, 0.5492, 0.0, 0.6845, 0.8861, 0.918] 
2025-11-29 02:04:16.138484: Epoch time: 94.77 s 
2025-11-29 02:04:18.063674:  
2025-11-29 02:04:18.063957: Epoch 118 
2025-11-29 02:04:18.064254: Current learning rate: 0.00893 
2025-11-29 02:05:53.055189: train_loss -0.1765 
2025-11-29 02:05:53.055557: val_loss -0.2124 
2025-11-29 02:05:53.055731: Pseudo dice [0.0019, 0.7023, 0.0, 0.7271, 0.6877, 0.0444, 0.8684, 0.9053] 
2025-11-29 02:05:53.055836: Epoch time: 94.99 s 
2025-11-29 02:05:55.098057:  
2025-11-29 02:05:55.098429: Epoch 119 
2025-11-29 02:05:55.098673: Current learning rate: 0.00892 
2025-11-29 02:07:29.836819: train_loss -0.175 
2025-11-29 02:07:29.837060: val_loss -0.1935 
2025-11-29 02:07:29.837324: Pseudo dice [0.6382, 0.0019, 0.0, 0.3889, 0.4214, 0.0, 0.8725, 0.8857] 
2025-11-29 02:07:29.837543: Epoch time: 94.74 s 
2025-11-29 02:07:31.901548:  
2025-11-29 02:07:31.901875: Epoch 120 
2025-11-29 02:07:31.902042: Current learning rate: 0.00891 
2025-11-29 02:09:06.218338: train_loss -0.1921 
2025-11-29 02:09:06.218716: val_loss -0.2135 
2025-11-29 02:09:06.219078: Pseudo dice [0.6649, 0.2491, 0.0, 0.708, 0.6446, 0.228, 0.9024, 0.8997] 
2025-11-29 02:09:06.219349: Epoch time: 94.32 s 
2025-11-29 02:09:08.194258:  
2025-11-29 02:09:08.194586: Epoch 121 
2025-11-29 02:09:08.194776: Current learning rate: 0.0089 
2025-11-29 02:10:42.324960: train_loss -0.1893 
2025-11-29 02:10:42.325236: val_loss -0.2152 
2025-11-29 02:10:42.325474: Pseudo dice [0.0232, 0.6629, 0.0072, 0.7894, 0.0, 0.714, 0.8826, 0.904] 
2025-11-29 02:10:42.325819: Epoch time: 94.13 s 
2025-11-29 02:10:42.325907: Yayy! New best EMA pseudo Dice: 0.4718 
2025-11-29 02:10:45.020724:  
2025-11-29 02:10:45.021064: Epoch 122 
2025-11-29 02:10:45.021255: Current learning rate: 0.00889 
2025-11-29 02:12:18.789264: train_loss -0.1848 
2025-11-29 02:12:18.789654: val_loss -0.1835 
2025-11-29 02:12:18.789852: Pseudo dice [0.0, 0.6193, 0.0853, 0.5842, 0.0, 0.6544, 0.8451, 0.9014] 
2025-11-29 02:12:18.789974: Epoch time: 93.77 s 
2025-11-29 02:12:21.605248:  
2025-11-29 02:12:21.605651: Epoch 123 
2025-11-29 02:12:21.605848: Current learning rate: 0.00889 
2025-11-29 02:13:55.591734: train_loss -0.193 
2025-11-29 02:13:55.591970: val_loss -0.1791 
2025-11-29 02:13:55.592249: Pseudo dice [0.0, 0.586, 0.6641, 0.0, 0.0, 0.5872, 0.9005, 0.895] 
2025-11-29 02:13:55.592406: Epoch time: 93.99 s 
2025-11-29 02:13:57.592865:  
2025-11-29 02:13:57.593254: Epoch 124 
2025-11-29 02:13:57.593441: Current learning rate: 0.00888 
2025-11-29 02:15:31.914224: train_loss -0.1771 
2025-11-29 02:15:31.914496: val_loss -0.1816 
2025-11-29 02:15:31.914805: Pseudo dice [0.5724, 0.0, 0.5967, 0.0, 0.6704, 0.0, 0.9172, 0.9069] 
2025-11-29 02:15:31.915100: Epoch time: 94.32 s 
2025-11-29 02:15:33.988386:  
2025-11-29 02:15:33.988764: Epoch 125 
2025-11-29 02:15:33.988975: Current learning rate: 0.00887 
2025-11-29 02:17:08.123969: train_loss -0.1798 
2025-11-29 02:17:08.124258: val_loss -0.2122 
2025-11-29 02:17:08.124473: Pseudo dice [0.6667, 0.0, 0.1284, 0.6852, 0.7741, 0.0125, 0.8973, 0.925] 
2025-11-29 02:17:08.124612: Epoch time: 94.14 s 
2025-11-29 02:17:08.124741: Yayy! New best EMA pseudo Dice: 0.4723 
2025-11-29 02:17:10.940935:  
2025-11-29 02:17:10.941306: Epoch 126 
2025-11-29 02:17:10.941488: Current learning rate: 0.00886 
2025-11-29 02:18:45.454937: train_loss -0.1921 
2025-11-29 02:18:45.455135: val_loss -0.2027 
2025-11-29 02:18:45.455363: Pseudo dice [0.6187, 0.0, 0.0, 0.7471, 0.0, 0.618, 0.8925, 0.918] 
2025-11-29 02:18:45.455616: Epoch time: 94.52 s 
2025-11-29 02:18:45.455722: Yayy! New best EMA pseudo Dice: 0.4725 
2025-11-29 02:18:48.086785:  
2025-11-29 02:18:48.087191: Epoch 127 
2025-11-29 02:18:48.087384: Current learning rate: 0.00885 
2025-11-29 02:20:22.681698: train_loss -0.1853 
2025-11-29 02:20:22.681991: val_loss -0.1817 
2025-11-29 02:20:22.682227: Pseudo dice [0.5975, 0.0, 0.5687, 0.0, 0.0, 0.6086, 0.8939, 0.8813] 
2025-11-29 02:20:22.682402: Epoch time: 94.6 s 
2025-11-29 02:20:24.671225:  
2025-11-29 02:20:24.671533: Epoch 128 
2025-11-29 02:20:24.671703: Current learning rate: 0.00884 
2025-11-29 02:21:59.370117: train_loss -0.1872 
2025-11-29 02:21:59.370444: val_loss -0.2101 
2025-11-29 02:21:59.370605: Pseudo dice [0.0001, 0.6476, 0.0071, 0.6028, 0.0, 0.7512, 0.8909, 0.9028] 
2025-11-29 02:21:59.370705: Epoch time: 94.7 s 
2025-11-29 02:22:01.330848:  
2025-11-29 02:22:01.331159: Epoch 129 
2025-11-29 02:22:01.331461: Current learning rate: 0.00883 
2025-11-29 02:23:36.325099: train_loss -0.186 
2025-11-29 02:23:36.325460: val_loss -0.2247 
2025-11-29 02:23:36.325647: Pseudo dice [0.0, 0.6793, 0.6411, 0.0, 0.6006, 0.0022, 0.8866, 0.8759] 
2025-11-29 02:23:36.325758: Epoch time: 95.0 s 
2025-11-29 02:23:38.253808:  
2025-11-29 02:23:38.254161: Epoch 130 
2025-11-29 02:23:38.254347: Current learning rate: 0.00882 
2025-11-29 02:25:12.223321: train_loss -0.1848 
2025-11-29 02:25:12.223594: val_loss -0.2092 
2025-11-29 02:25:12.223828: Pseudo dice [0.6768, 0.028, 0.0181, 0.4908, 0.6796, 0.0002, 0.8566, 0.8905] 
2025-11-29 02:25:12.223981: Epoch time: 93.97 s 
2025-11-29 02:25:14.256336:  
2025-11-29 02:25:14.256587: Epoch 131 
2025-11-29 02:25:14.256843: Current learning rate: 0.00881 
2025-11-29 02:26:48.374027: train_loss -0.1883 
2025-11-29 02:26:48.374439: val_loss -0.1841 
2025-11-29 02:26:48.374682: Pseudo dice [0.6228, 0.0001, 0.3781, 0.5685, 0.0, 0.616, 0.9268, 0.9122] 
2025-11-29 02:26:48.374918: Epoch time: 94.12 s 
2025-11-29 02:26:50.324563:  
2025-11-29 02:26:50.324885: Epoch 132 
2025-11-29 02:26:50.325072: Current learning rate: 0.0088 
2025-11-29 02:28:24.731015: train_loss -0.1805 
2025-11-29 02:28:24.731306: val_loss -0.2034 
2025-11-29 02:28:24.731528: Pseudo dice [0.5143, 0.0007, 0.5986, 0.0047, 0.0, 0.7032, 0.8937, 0.878] 
2025-11-29 02:28:24.731658: Epoch time: 94.41 s 
2025-11-29 02:28:26.768870:  
2025-11-29 02:28:26.769171: Epoch 133 
2025-11-29 02:28:26.769380: Current learning rate: 0.00879 
2025-11-29 02:30:01.302750: train_loss -0.1848 
2025-11-29 02:30:01.303128: val_loss -0.1619 
2025-11-29 02:30:01.303393: Pseudo dice [0.668, 0.0, 0.5939, 0.0, 0.0, 0.755, 0.9018, 0.9124] 
2025-11-29 02:30:01.303709: Epoch time: 94.54 s 
2025-11-29 02:30:03.356672:  
2025-11-29 02:30:03.356966: Epoch 134 
2025-11-29 02:30:03.357188: Current learning rate: 0.00879 
2025-11-29 02:31:37.959484: train_loss -0.166 
2025-11-29 02:31:37.959761: val_loss -0.1912 
2025-11-29 02:31:37.959950: Pseudo dice [0.7573, 0.0241, 0.5873, 0.3441, 0.8123, 0.0806, 0.8063, 0.8302] 
2025-11-29 02:31:37.960070: Epoch time: 94.6 s 
2025-11-29 02:31:37.960216: Yayy! New best EMA pseudo Dice: 0.4761 
2025-11-29 02:31:40.697490:  
2025-11-29 02:31:40.697754: Epoch 135 
2025-11-29 02:31:40.697907: Current learning rate: 0.00878 
2025-11-29 02:33:15.054378: train_loss -0.1804 
2025-11-29 02:33:15.054608: val_loss -0.1823 
2025-11-29 02:33:15.054777: Pseudo dice [0.6822, 0.0003, 0.5835, 0.0, 0.0, 0.7317, 0.8449, 0.8758] 
2025-11-29 02:33:15.055012: Epoch time: 94.36 s 
2025-11-29 02:33:17.090890:  
2025-11-29 02:33:17.091201: Epoch 136 
2025-11-29 02:33:17.091424: Current learning rate: 0.00877 
2025-11-29 02:34:51.085394: train_loss -0.1722 
2025-11-29 02:34:51.085629: val_loss -0.2095 
2025-11-29 02:34:51.085780: Pseudo dice [0.6642, 0.0008, 0.6778, 0.0, 0.5156, 0.0322, 0.88, 0.9157] 
2025-11-29 02:34:51.085915: Epoch time: 94.0 s 
2025-11-29 02:34:53.063448:  
2025-11-29 02:34:53.063742: Epoch 137 
2025-11-29 02:34:53.063906: Current learning rate: 0.00876 
2025-11-29 02:36:27.922233: train_loss -0.1773 
2025-11-29 02:36:27.922567: val_loss -0.1991 
2025-11-29 02:36:27.922810: Pseudo dice [0.5738, 0.0, 0.6722, 0.0, 0.5383, 0.0074, 0.9068, 0.909] 
2025-11-29 02:36:27.922944: Epoch time: 94.86 s 
2025-11-29 02:36:29.802548:  
2025-11-29 02:36:29.802884: Epoch 138 
2025-11-29 02:36:29.803092: Current learning rate: 0.00875 
2025-11-29 02:38:03.717846: train_loss -0.1804 
2025-11-29 02:38:03.718056: val_loss -0.2046 
2025-11-29 02:38:03.718227: Pseudo dice [0.2351, 0.5467, 0.0087, 0.584, 0.0, 0.7533, 0.859, 0.893] 
2025-11-29 02:38:03.718459: Epoch time: 93.92 s 
2025-11-29 02:38:05.689813:  
2025-11-29 02:38:05.690099: Epoch 139 
2025-11-29 02:38:05.690325: Current learning rate: 0.00874 
2025-11-29 02:39:40.338337: train_loss -0.1751 
2025-11-29 02:39:40.338642: val_loss -0.1959 
2025-11-29 02:39:40.338796: Pseudo dice [0.0005, 0.5046, 0.0064, 0.6136, 0.0, 0.3988, 0.8487, 0.8854] 
2025-11-29 02:39:40.338900: Epoch time: 94.65 s 
2025-11-29 02:39:42.390809:  
2025-11-29 02:39:42.391197: Epoch 140 
2025-11-29 02:39:42.391379: Current learning rate: 0.00873 
2025-11-29 02:41:16.418510: train_loss -0.1775 
2025-11-29 02:41:16.418781: val_loss -0.2033 
2025-11-29 02:41:16.419011: Pseudo dice [0.0015, 0.7043, 0.0338, 0.7199, 0.2507, 0.0902, 0.9115, 0.9072] 
2025-11-29 02:41:16.419263: Epoch time: 94.03 s 
2025-11-29 02:41:18.340508:  
2025-11-29 02:41:18.340708: Epoch 141 
2025-11-29 02:41:18.340875: Current learning rate: 0.00872 
2025-11-29 02:42:52.711811: train_loss -0.1868 
2025-11-29 02:42:52.712077: val_loss -0.2037 
2025-11-29 02:42:52.712355: Pseudo dice [0.692, 0.0, 0.6184, 0.0, 0.7128, 0.0, 0.867, 0.8738] 
2025-11-29 02:42:52.712764: Epoch time: 94.37 s 
2025-11-29 02:42:54.741560:  
2025-11-29 02:42:54.741812: Epoch 142 
2025-11-29 02:42:54.742040: Current learning rate: 0.00871 
2025-11-29 02:44:28.902587: train_loss -0.1771 
2025-11-29 02:44:28.902884: val_loss -0.2237 
2025-11-29 02:44:28.903054: Pseudo dice [0.003, 0.6325, 0.5786, 0.0947, 0.0, 0.6471, 0.896, 0.894] 
2025-11-29 02:44:28.903186: Epoch time: 94.16 s 
2025-11-29 02:44:31.710711:  
2025-11-29 02:44:31.711049: Epoch 143 
2025-11-29 02:44:31.711227: Current learning rate: 0.0087 
2025-11-29 02:46:05.795164: train_loss -0.1795 
2025-11-29 02:46:05.795450: val_loss -0.2161 
2025-11-29 02:46:05.795666: Pseudo dice [0.0, 0.6546, 0.1269, 0.7655, 0.5918, 0.0, 0.8957, 0.9216] 
2025-11-29 02:46:05.795827: Epoch time: 94.09 s 
2025-11-29 02:46:07.741894:  
2025-11-29 02:46:07.742279: Epoch 144 
2025-11-29 02:46:07.742451: Current learning rate: 0.00869 
2025-11-29 02:47:42.394755: train_loss -0.1981 
2025-11-29 02:47:42.394994: val_loss -0.1778 
2025-11-29 02:47:42.395239: Pseudo dice [0.0, 0.5572, 0.1145, 0.6626, 0.0, 0.542, 0.8983, 0.9154] 
2025-11-29 02:47:42.395395: Epoch time: 94.65 s 
2025-11-29 02:47:44.452921:  
2025-11-29 02:47:44.453288: Epoch 145 
2025-11-29 02:47:44.453464: Current learning rate: 0.00868 
2025-11-29 02:49:18.404129: train_loss -0.194 
2025-11-29 02:49:18.404390: val_loss -0.2022 
2025-11-29 02:49:18.404572: Pseudo dice [0.6362, 0.0056, 0.4457, 0.0004, 0.5775, 0.0296, 0.9107, 0.881] 
2025-11-29 02:49:18.404722: Epoch time: 93.95 s 
2025-11-29 02:49:20.304779:  
2025-11-29 02:49:20.305171: Epoch 146 
2025-11-29 02:49:20.305340: Current learning rate: 0.00868 
2025-11-29 02:50:54.073124: train_loss -0.1861 
2025-11-29 02:50:54.073482: val_loss -0.1947 
2025-11-29 02:50:54.073899: Pseudo dice [0.7019, 0.0, 0.0127, 0.5449, 0.0, 0.5318, 0.7826, 0.8003] 
2025-11-29 02:50:54.074086: Epoch time: 93.77 s 
2025-11-29 02:50:56.062643:  
2025-11-29 02:50:56.062901: Epoch 147 
2025-11-29 02:50:56.063081: Current learning rate: 0.00867 
2025-11-29 02:52:30.161349: train_loss -0.1939 
2025-11-29 02:52:30.161570: val_loss -0.213 
2025-11-29 02:52:30.161707: Pseudo dice [0.0, 0.6244, 0.6347, 0.0, 0.0, 0.6473, 0.8714, 0.8912] 
2025-11-29 02:52:30.161803: Epoch time: 94.1 s 
2025-11-29 02:52:32.116695:  
2025-11-29 02:52:32.117030: Epoch 148 
2025-11-29 02:52:32.117301: Current learning rate: 0.00866 
2025-11-29 02:54:05.888809: train_loss -0.1673 
2025-11-29 02:54:05.889266: val_loss -0.1865 
2025-11-29 02:54:05.889522: Pseudo dice [0.5561, 0.0012, 0.456, 0.0, 0.0, 0.6199, 0.8837, 0.8455] 
2025-11-29 02:54:05.889667: Epoch time: 93.77 s 
2025-11-29 02:54:07.833225:  
2025-11-29 02:54:07.833529: Epoch 149 
2025-11-29 02:54:07.833685: Current learning rate: 0.00865 
2025-11-29 02:55:41.435929: train_loss -0.1789 
2025-11-29 02:55:41.436134: val_loss -0.1817 
2025-11-29 02:55:41.436331: Pseudo dice [0.0, 0.5923, 0.5081, 0.004, 0.7887, 0.0572, 0.7936, 0.8587] 
2025-11-29 02:55:41.436427: Epoch time: 93.6 s 
2025-11-29 02:55:44.300704:  
2025-11-29 02:55:44.301072: Epoch 150 
2025-11-29 02:55:44.301250: Current learning rate: 0.00864 
2025-11-29 02:57:18.484887: train_loss -0.1861 
2025-11-29 02:57:18.485189: val_loss -0.1967 
2025-11-29 02:57:18.485682: Pseudo dice [0.0, 0.5988, 0.0002, 0.6217, 0.6059, 0.0, 0.9028, 0.8916] 
2025-11-29 02:57:18.485820: Epoch time: 94.19 s 
2025-11-29 02:57:20.402689:  
2025-11-29 02:57:20.403010: Epoch 151 
2025-11-29 02:57:20.403190: Current learning rate: 0.00863 
2025-11-29 02:58:54.182804: train_loss -0.1941 
2025-11-29 02:58:54.183086: val_loss -0.2065 
2025-11-29 02:58:54.183334: Pseudo dice [0.0053, 0.7354, 0.6557, 0.0, 0.0, 0.77, 0.8751, 0.9016] 
2025-11-29 02:58:54.183503: Epoch time: 93.78 s 
2025-11-29 02:58:56.265865:  
2025-11-29 02:58:56.266202: Epoch 152 
2025-11-29 02:58:56.266371: Current learning rate: 0.00862 
2025-11-29 03:00:30.414745: train_loss -0.1714 
2025-11-29 03:00:30.415109: val_loss -0.2233 
2025-11-29 03:00:30.415404: Pseudo dice [0.0021, 0.4707, 0.6638, 0.0, 0.0001, 0.5573, 0.8949, 0.9002] 
2025-11-29 03:00:30.415574: Epoch time: 94.15 s 
2025-11-29 03:00:32.439231:  
2025-11-29 03:00:32.439515: Epoch 153 
2025-11-29 03:00:32.439729: Current learning rate: 0.00861 
2025-11-29 03:02:06.553480: train_loss -0.1913 
2025-11-29 03:02:06.553741: val_loss -0.2126 
2025-11-29 03:02:06.553935: Pseudo dice [0.7309, 0.0, 0.4445, 0.2547, 0.6053, 0.0862, 0.909, 0.9221] 
2025-11-29 03:02:06.554165: Epoch time: 94.12 s 
2025-11-29 03:02:08.543694:  
2025-11-29 03:02:08.544016: Epoch 154 
2025-11-29 03:02:08.544211: Current learning rate: 0.0086 
2025-11-29 03:03:42.440690: train_loss -0.1943 
2025-11-29 03:03:42.440913: val_loss -0.2076 
2025-11-29 03:03:42.441063: Pseudo dice [0.4819, 0.0001, 0.017, 0.7573, 0.609, 0.0226, 0.8668, 0.8867] 
2025-11-29 03:03:42.441226: Epoch time: 93.9 s 
2025-11-29 03:03:44.786876:  
2025-11-29 03:03:44.787603: Epoch 155 
2025-11-29 03:03:44.788400: Current learning rate: 0.00859 
2025-11-29 03:05:19.918635: train_loss -0.1935 
2025-11-29 03:05:19.918871: val_loss -0.2473 
2025-11-29 03:05:19.919266: Pseudo dice [0.6294, 0.0001, 0.0788, 0.5885, 0.5471, 0.0, 0.9138, 0.9205] 
2025-11-29 03:05:19.919547: Epoch time: 95.13 s 
2025-11-29 03:05:22.154669:  
2025-11-29 03:05:22.155004: Epoch 156 
2025-11-29 03:05:22.155208: Current learning rate: 0.00858 
2025-11-29 03:06:57.504367: train_loss -0.194 
2025-11-29 03:06:57.504784: val_loss -0.192 
2025-11-29 03:06:57.505019: Pseudo dice [0.6558, 0.0686, 0.5978, 0.0, 0.0, 0.5925, 0.8869, 0.8604] 
2025-11-29 03:06:57.505195: Epoch time: 95.35 s 
2025-11-29 03:06:59.758908:  
2025-11-29 03:06:59.759270: Epoch 157 
2025-11-29 03:06:59.759449: Current learning rate: 0.00858 
2025-11-29 03:08:35.315613: train_loss -0.1867 
2025-11-29 03:08:35.316161: val_loss -0.207 
2025-11-29 03:08:35.316350: Pseudo dice [0.0, 0.7309, 0.5704, 0.0, 0.0, 0.6282, 0.904, 0.9071] 
2025-11-29 03:08:35.316457: Epoch time: 95.56 s 
2025-11-29 03:08:37.345485:  
2025-11-29 03:08:37.345841: Epoch 158 
2025-11-29 03:08:37.346049: Current learning rate: 0.00857 
2025-11-29 03:10:12.043183: train_loss -0.1916 
2025-11-29 03:10:12.043384: val_loss -0.2189 
2025-11-29 03:10:12.043580: Pseudo dice [0.0, 0.7057, 0.0013, 0.5652, 0.0, 0.6202, 0.924, 0.9058] 
2025-11-29 03:10:12.043723: Epoch time: 94.7 s 
2025-11-29 03:10:14.066809:  
2025-11-29 03:10:14.067126: Epoch 159 
2025-11-29 03:10:14.067339: Current learning rate: 0.00856 
2025-11-29 03:11:48.577318: train_loss -0.1992 
2025-11-29 03:11:48.577572: val_loss -0.1987 
2025-11-29 03:11:48.577752: Pseudo dice [0.0, 0.4497, 0.8595, 0.0, 0.5853, 0.0856, 0.8706, 0.8855] 
2025-11-29 03:11:48.577892: Epoch time: 94.51 s 
2025-11-29 03:11:50.544477:  
2025-11-29 03:11:50.544821: Epoch 160 
2025-11-29 03:11:50.544991: Current learning rate: 0.00855 
2025-11-29 03:13:24.974041: train_loss -0.1995 
2025-11-29 03:13:24.974475: val_loss -0.2063 
2025-11-29 03:13:24.974642: Pseudo dice [0.6372, 0.002, 0.5264, 0.0, 0.0, 0.2371, 0.915, 0.9137] 
2025-11-29 03:13:24.974789: Epoch time: 94.43 s 
2025-11-29 03:13:27.062746:  
2025-11-29 03:13:27.063072: Epoch 161 
2025-11-29 03:13:27.063259: Current learning rate: 0.00854 
2025-11-29 03:15:01.377804: train_loss -0.1803 
2025-11-29 03:15:01.378098: val_loss -0.2055 
2025-11-29 03:15:01.378425: Pseudo dice [0.0, 0.6903, 0.0007, 0.7031, 0.0, 0.543, 0.916, 0.8912] 
2025-11-29 03:15:01.378587: Epoch time: 94.32 s 
2025-11-29 03:15:03.481858:  
2025-11-29 03:15:03.482209: Epoch 162 
2025-11-29 03:15:03.482395: Current learning rate: 0.00853 
2025-11-29 03:16:37.879278: train_loss -0.1907 
2025-11-29 03:16:37.879517: val_loss -0.2207 
2025-11-29 03:16:37.879864: Pseudo dice [0.0, 0.6686, 0.6543, 0.1937, 0.4644, 0.1543, 0.904, 0.9097] 
2025-11-29 03:16:37.880023: Epoch time: 94.4 s 
2025-11-29 03:16:39.907903:  
2025-11-29 03:16:39.908105: Epoch 163 
2025-11-29 03:16:39.908329: Current learning rate: 0.00852 
2025-11-29 03:18:14.472747: train_loss -0.196 
2025-11-29 03:18:14.472967: val_loss -0.207 
2025-11-29 03:18:14.473238: Pseudo dice [0.803, 0.0003, 0.6264, 0.0, 0.0, 0.3329, 0.9139, 0.904] 
2025-11-29 03:18:14.473376: Epoch time: 94.57 s 
2025-11-29 03:18:17.495062:  
2025-11-29 03:18:17.495366: Epoch 164 
2025-11-29 03:18:17.495546: Current learning rate: 0.00851 
2025-11-29 03:19:52.004256: train_loss -0.2007 
2025-11-29 03:19:52.004503: val_loss -0.2078 
2025-11-29 03:19:52.004700: Pseudo dice [0.5973, 0.0007, 0.6813, 0.0, 0.6127, 0.0, 0.8979, 0.9017] 
2025-11-29 03:19:52.004805: Epoch time: 94.51 s 
2025-11-29 03:19:53.918908:  
2025-11-29 03:19:53.919249: Epoch 165 
2025-11-29 03:19:53.919447: Current learning rate: 0.0085 
2025-11-29 03:21:28.382672: train_loss -0.1883 
2025-11-29 03:21:28.382902: val_loss -0.1929 
2025-11-29 03:21:28.383094: Pseudo dice [0.0, 0.6701, 0.1659, 0.5362, 0.0, 0.7317, 0.8176, 0.873] 
2025-11-29 03:21:28.383254: Epoch time: 94.47 s 
2025-11-29 03:21:30.326837:  
2025-11-29 03:21:30.327207: Epoch 166 
2025-11-29 03:21:30.327395: Current learning rate: 0.00849 
2025-11-29 03:23:04.780560: train_loss -0.175 
2025-11-29 03:23:04.780808: val_loss -0.1896 
2025-11-29 03:23:04.781038: Pseudo dice [0.5575, 0.2341, 0.0005, 0.553, 0.2691, 0.0, 0.897, 0.9081] 
2025-11-29 03:23:04.781227: Epoch time: 94.46 s 
2025-11-29 03:23:06.734198:  
2025-11-29 03:23:06.734567: Epoch 167 
2025-11-29 03:23:06.734740: Current learning rate: 0.00848 
2025-11-29 03:24:41.684881: train_loss -0.1839 
2025-11-29 03:24:41.685250: val_loss -0.1848 
2025-11-29 03:24:41.685791: Pseudo dice [0.6053, 0.0, 0.5757, 0.0, 0.0, 0.5076, 0.887, 0.9073] 
2025-11-29 03:24:41.685938: Epoch time: 94.95 s 
2025-11-29 03:24:43.855999:  
2025-11-29 03:24:43.856406: Epoch 168 
2025-11-29 03:24:43.856584: Current learning rate: 0.00847 
2025-11-29 03:26:18.889695: train_loss -0.1776 
2025-11-29 03:26:18.890011: val_loss -0.1881 
2025-11-29 03:26:18.890312: Pseudo dice [0.5718, 0.077, 0.6156, 0.1605, 0.7285, 0.0069, 0.9089, 0.8892] 
2025-11-29 03:26:18.890662: Epoch time: 95.04 s 
2025-11-29 03:26:21.046430:  
2025-11-29 03:26:21.046677: Epoch 169 
2025-11-29 03:26:21.046839: Current learning rate: 0.00847 
2025-11-29 03:27:55.851674: train_loss -0.1954 
2025-11-29 03:27:55.851911: val_loss -0.2058 
2025-11-29 03:27:55.852112: Pseudo dice [0.0, 0.6341, 0.0, 0.5893, 0.0, 0.7182, 0.8964, 0.8865] 
2025-11-29 03:27:55.852285: Epoch time: 94.81 s 
2025-11-29 03:27:57.856392:  
2025-11-29 03:27:57.856704: Epoch 170 
2025-11-29 03:27:57.856910: Current learning rate: 0.00846 
2025-11-29 03:29:32.875082: train_loss -0.2 
2025-11-29 03:29:32.875474: val_loss -0.1728 
2025-11-29 03:29:32.875706: Pseudo dice [0.0, 0.6085, 0.6094, 0.0, 0.0, 0.2971, 0.8917, 0.9173] 
2025-11-29 03:29:32.875865: Epoch time: 95.02 s 
2025-11-29 03:29:35.070472:  
2025-11-29 03:29:35.070806: Epoch 171 
2025-11-29 03:29:35.071060: Current learning rate: 0.00845 
2025-11-29 03:31:09.915546: train_loss -0.1877 
2025-11-29 03:31:09.915914: val_loss -0.1883 
2025-11-29 03:31:09.916087: Pseudo dice [0.6716, 0.2441, 0.0009, 0.701, 0.0, 0.6109, 0.9049, 0.892] 
2025-11-29 03:31:09.916268: Epoch time: 94.85 s 
2025-11-29 03:31:11.888787:  
2025-11-29 03:31:11.889063: Epoch 172 
2025-11-29 03:31:11.889247: Current learning rate: 0.00844 
2025-11-29 03:32:45.941725: train_loss -0.2037 
2025-11-29 03:32:45.941991: val_loss -0.2138 
2025-11-29 03:32:45.942261: Pseudo dice [0.5847, 0.0291, 0.0, 0.6431, 0.4803, 0.0002, 0.8958, 0.9075] 
2025-11-29 03:32:45.942523: Epoch time: 94.05 s 
2025-11-29 03:32:47.942372:  
2025-11-29 03:32:47.942611: Epoch 173 
2025-11-29 03:32:47.942789: Current learning rate: 0.00843 
2025-11-29 03:34:22.878422: train_loss -0.196 
2025-11-29 03:34:22.878850: val_loss -0.2135 
2025-11-29 03:34:22.879278: Pseudo dice [0.0813, 0.6442, 0.5794, 0.0, 0.7977, 0.0001, 0.9031, 0.9123] 
2025-11-29 03:34:22.879455: Epoch time: 94.94 s 
2025-11-29 03:34:24.977619:  
2025-11-29 03:34:24.977935: Epoch 174 
2025-11-29 03:34:24.978096: Current learning rate: 0.00842 
2025-11-29 03:36:00.012372: train_loss -0.1945 
2025-11-29 03:36:00.012684: val_loss -0.2265 
2025-11-29 03:36:00.012997: Pseudo dice [0.7021, 0.0089, 0.6814, 0.0, 0.6545, 0.1338, 0.9024, 0.8904] 
2025-11-29 03:36:00.013199: Epoch time: 95.04 s 
2025-11-29 03:36:02.162977:  
2025-11-29 03:36:02.163352: Epoch 175 
2025-11-29 03:36:02.163551: Current learning rate: 0.00841 
2025-11-29 03:37:37.017951: train_loss -0.188 
2025-11-29 03:37:37.018244: val_loss -0.191 
2025-11-29 03:37:37.018446: Pseudo dice [0.6815, 0.0142, 0.6979, 0.0, 0.0, 0.6356, 0.8694, 0.8808] 
2025-11-29 03:37:37.018549: Epoch time: 94.86 s 
2025-11-29 03:37:39.056850:  
2025-11-29 03:37:39.057160: Epoch 176 
2025-11-29 03:37:39.057338: Current learning rate: 0.0084 
2025-11-29 03:39:13.251365: train_loss -0.2023 
2025-11-29 03:39:13.251662: val_loss -0.1923 
2025-11-29 03:39:13.251883: Pseudo dice [0.6126, 0.0056, 0.0025, 0.7166, 0.5835, 0.0247, 0.9137, 0.9064] 
2025-11-29 03:39:13.252012: Epoch time: 94.2 s 
2025-11-29 03:39:15.231539:  
2025-11-29 03:39:15.231823: Epoch 177 
2025-11-29 03:39:15.231994: Current learning rate: 0.00839 
2025-11-29 03:40:49.269090: train_loss -0.1979 
2025-11-29 03:40:49.269463: val_loss -0.2218 
2025-11-29 03:40:49.269699: Pseudo dice [0.6511, 0.0066, 0.8063, 0.0, 0.471, 0.0066, 0.9234, 0.9195] 
2025-11-29 03:40:49.269889: Epoch time: 94.04 s 
2025-11-29 03:40:51.473282:  
2025-11-29 03:40:51.473507: Epoch 178 
2025-11-29 03:40:51.473672: Current learning rate: 0.00838 
2025-11-29 03:42:25.610929: train_loss -0.1959 
2025-11-29 03:42:25.611194: val_loss -0.2116 
2025-11-29 03:42:25.611420: Pseudo dice [0.721, 0.072, 0.5286, 0.0, 0.0, 0.4414, 0.8482, 0.8508] 
2025-11-29 03:42:25.611584: Epoch time: 94.14 s 
2025-11-29 03:42:27.522586:  
2025-11-29 03:42:27.522908: Epoch 179 
2025-11-29 03:42:27.523079: Current learning rate: 0.00837 
2025-11-29 03:44:02.433978: train_loss -0.1893 
2025-11-29 03:44:02.434405: val_loss -0.1978 
2025-11-29 03:44:02.434655: Pseudo dice [0.6412, 0.0004, 0.6358, 0.0, 0.0029, 0.3558, 0.9191, 0.8803] 
2025-11-29 03:44:02.434907: Epoch time: 94.91 s 
2025-11-29 03:44:04.439029:  
2025-11-29 03:44:04.439345: Epoch 180 
2025-11-29 03:44:04.439538: Current learning rate: 0.00836 
2025-11-29 03:45:39.111506: train_loss -0.1981 
2025-11-29 03:45:39.111763: val_loss -0.2164 
2025-11-29 03:45:39.111978: Pseudo dice [0.5587, 0.0864, 0.6704, 0.0081, 0.6075, 0.0003, 0.8699, 0.8682] 
2025-11-29 03:45:39.112126: Epoch time: 94.67 s 
2025-11-29 03:45:41.128762:  
2025-11-29 03:45:41.129011: Epoch 181 
2025-11-29 03:45:41.129197: Current learning rate: 0.00836 
2025-11-29 03:47:15.503989: train_loss -0.1875 
2025-11-29 03:47:15.504267: val_loss -0.192 
2025-11-29 03:47:15.504511: Pseudo dice [0.0024, 0.7176, 0.5439, 0.0, 0.6001, 0.016, 0.8425, 0.8636] 
2025-11-29 03:47:15.504646: Epoch time: 94.38 s 
2025-11-29 03:47:17.441881:  
2025-11-29 03:47:17.442204: Epoch 182 
2025-11-29 03:47:17.442368: Current learning rate: 0.00835 
2025-11-29 03:48:52.162393: train_loss -0.177 
2025-11-29 03:48:52.162686: val_loss -0.2141 
2025-11-29 03:48:52.162882: Pseudo dice [0.0007, 0.6918, 0.6716, 0.2499, 0.0, 0.6329, 0.8801, 0.889] 
2025-11-29 03:48:52.162998: Epoch time: 94.72 s 
2025-11-29 03:48:54.112772:  
2025-11-29 03:48:54.113035: Epoch 183 
2025-11-29 03:48:54.113256: Current learning rate: 0.00834 
2025-11-29 03:50:28.723496: train_loss -0.191 
2025-11-29 03:50:28.723804: val_loss -0.2027 
2025-11-29 03:50:28.724031: Pseudo dice [0.0647, 0.5919, 0.7502, 0.0, 0.6708, 0.0014, 0.8986, 0.9024] 
2025-11-29 03:50:28.724185: Epoch time: 94.61 s 
2025-11-29 03:50:30.645464:  
2025-11-29 03:50:30.645770: Epoch 184 
2025-11-29 03:50:30.645963: Current learning rate: 0.00833 
2025-11-29 03:52:05.819921: train_loss -0.1898 
2025-11-29 03:52:05.820362: val_loss -0.1917 
2025-11-29 03:52:05.820579: Pseudo dice [0.0004, 0.6273, 0.0252, 0.7158, 0.0, 0.6109, 0.8624, 0.8853] 
2025-11-29 03:52:05.820706: Epoch time: 95.18 s 
2025-11-29 03:52:08.626018:  
2025-11-29 03:52:08.626382: Epoch 185 
2025-11-29 03:52:08.626549: Current learning rate: 0.00832 
2025-11-29 03:53:43.100603: train_loss -0.1899 
2025-11-29 03:53:43.100854: val_loss -0.1699 
2025-11-29 03:53:43.101054: Pseudo dice [0.6738, 0.0001, 0.0, 0.6223, 0.7565, 0.0037, 0.841, 0.8478] 
2025-11-29 03:53:43.101218: Epoch time: 94.48 s 
2025-11-29 03:53:45.167128:  
2025-11-29 03:53:45.167507: Epoch 186 
2025-11-29 03:53:45.167700: Current learning rate: 0.00831 
2025-11-29 03:55:20.349649: train_loss -0.1863 
2025-11-29 03:55:20.349869: val_loss -0.1995 
2025-11-29 03:55:20.350127: Pseudo dice [0.6505, 0.0, 0.6083, 0.4296, 0.0, 0.7615, 0.8778, 0.8997] 
2025-11-29 03:55:20.350382: Epoch time: 95.18 s 
2025-11-29 03:55:22.383822:  
2025-11-29 03:55:22.384192: Epoch 187 
2025-11-29 03:55:22.384368: Current learning rate: 0.0083 
2025-11-29 03:56:57.735232: train_loss -0.1906 
2025-11-29 03:56:57.735527: val_loss -0.2127 
2025-11-29 03:56:57.735820: Pseudo dice [0.0, 0.5616, 0.0425, 0.5814, 0.1225, 0.2941, 0.8946, 0.9084] 
2025-11-29 03:56:57.735929: Epoch time: 95.35 s 
2025-11-29 03:56:59.670712:  
2025-11-29 03:56:59.671041: Epoch 188 
2025-11-29 03:56:59.671227: Current learning rate: 0.00829 
2025-11-29 03:58:34.679809: train_loss -0.1938 
2025-11-29 03:58:34.680040: val_loss -0.2077 
2025-11-29 03:58:34.680258: Pseudo dice [0.0003, 0.724, 0.0177, 0.6473, 0.4422, 0.0, 0.8996, 0.9116] 
2025-11-29 03:58:34.680411: Epoch time: 95.01 s 
2025-11-29 03:58:36.619617:  
2025-11-29 03:58:36.619950: Epoch 189 
2025-11-29 03:58:36.620112: Current learning rate: 0.00828 
2025-11-29 04:00:10.763689: train_loss -0.1807 
2025-11-29 04:00:10.763984: val_loss -0.2162 
2025-11-29 04:00:10.764241: Pseudo dice [0.5715, 0.0002, 0.1896, 0.6358, 0.4727, 0.1211, 0.8784, 0.8931] 
2025-11-29 04:00:10.764390: Epoch time: 94.15 s 
2025-11-29 04:00:12.823992:  
2025-11-29 04:00:12.824237: Epoch 190 
2025-11-29 04:00:12.824479: Current learning rate: 0.00827 
2025-11-29 04:01:46.818660: train_loss -0.1943 
2025-11-29 04:01:46.818925: val_loss -0.2091 
2025-11-29 04:01:46.819252: Pseudo dice [0.0276, 0.7018, 0.0, 0.7025, 0.4509, 0.3847, 0.9076, 0.9202] 
2025-11-29 04:01:46.819418: Epoch time: 94.0 s 
2025-11-29 04:01:48.804769:  
2025-11-29 04:01:48.805105: Epoch 191 
2025-11-29 04:01:48.805330: Current learning rate: 0.00826 
2025-11-29 04:03:23.773403: train_loss -0.1832 
2025-11-29 04:03:23.773775: val_loss -0.1881 
2025-11-29 04:03:23.773974: Pseudo dice [0.0013, 0.7396, 0.5366, 0.0, 0.3691, 0.0006, 0.8896, 0.882] 
2025-11-29 04:03:23.774111: Epoch time: 94.97 s 
2025-11-29 04:03:25.692760:  
2025-11-29 04:03:25.693051: Epoch 192 
2025-11-29 04:03:25.693227: Current learning rate: 0.00825 
2025-11-29 04:05:00.389329: train_loss -0.1864 
2025-11-29 04:05:00.389936: val_loss -0.1971 
2025-11-29 04:05:00.390163: Pseudo dice [0.0, 0.6874, 0.0, 0.7204, 0.0, 0.5351, 0.9091, 0.9084] 
2025-11-29 04:05:00.390296: Epoch time: 94.7 s 
2025-11-29 04:05:02.407887:  
2025-11-29 04:05:02.408106: Epoch 193 
2025-11-29 04:05:02.408340: Current learning rate: 0.00824 
2025-11-29 04:06:37.118826: train_loss -0.193 
2025-11-29 04:06:37.119266: val_loss -0.2133 
2025-11-29 04:06:37.119478: Pseudo dice [0.6181, 0.0003, 0.5745, 0.0001, 0.0, 0.5151, 0.8916, 0.9168] 
2025-11-29 04:06:37.119860: Epoch time: 94.71 s 
2025-11-29 04:06:39.164707:  
2025-11-29 04:06:39.165001: Epoch 194 
2025-11-29 04:06:39.165189: Current learning rate: 0.00824 
2025-11-29 04:08:13.199103: train_loss -0.2031 
2025-11-29 04:08:13.199456: val_loss -0.2032 
2025-11-29 04:08:13.199722: Pseudo dice [0.0017, 0.6341, 0.6076, 0.001, 0.0, 0.6184, 0.8855, 0.9141] 
2025-11-29 04:08:13.200012: Epoch time: 94.04 s 
2025-11-29 04:08:15.223313:  
2025-11-29 04:08:15.223688: Epoch 195 
2025-11-29 04:08:15.223890: Current learning rate: 0.00823 
2025-11-29 04:09:49.539704: train_loss -0.1949 
2025-11-29 04:09:49.540058: val_loss -0.2163 
2025-11-29 04:09:49.540335: Pseudo dice [0.7221, 0.002, 0.0, 0.682, 0.7535, 0.019, 0.9053, 0.9002] 
2025-11-29 04:09:49.540836: Epoch time: 94.32 s 
2025-11-29 04:09:51.703175:  
2025-11-29 04:09:51.703513: Epoch 196 
2025-11-29 04:09:51.703698: Current learning rate: 0.00822 
2025-11-29 04:11:26.462537: train_loss -0.2029 
2025-11-29 04:11:26.462908: val_loss -0.2114 
2025-11-29 04:11:26.463117: Pseudo dice [0.6056, 0.0, 0.4394, 0.0, 0.7993, 0.0959, 0.8668, 0.9091] 
2025-11-29 04:11:26.463269: Epoch time: 94.76 s 
2025-11-29 04:11:28.397307:  
2025-11-29 04:11:28.397534: Epoch 197 
2025-11-29 04:11:28.397735: Current learning rate: 0.00821 
2025-11-29 04:13:02.790025: train_loss -0.1971 
2025-11-29 04:13:02.790349: val_loss -0.2101 
2025-11-29 04:13:02.790807: Pseudo dice [0.8186, 0.0001, 0.0, 0.2647, 0.6327, 0.0, 0.9067, 0.8993] 
2025-11-29 04:13:02.791034: Epoch time: 94.39 s 
2025-11-29 04:13:04.919567:  
2025-11-29 04:13:04.919946: Epoch 198 
2025-11-29 04:13:04.920126: Current learning rate: 0.0082 
2025-11-29 04:14:40.250355: train_loss -0.1986 
2025-11-29 04:14:40.250731: val_loss -0.2198 
2025-11-29 04:14:40.250957: Pseudo dice [0.5997, 0.004, 0.715, 0.008, 0.738, 0.0001, 0.9292, 0.9289] 
2025-11-29 04:14:40.251091: Epoch time: 95.33 s 
2025-11-29 04:14:42.373305:  
2025-11-29 04:14:42.373621: Epoch 199 
2025-11-29 04:14:42.373785: Current learning rate: 0.00819 
2025-11-29 04:16:18.622670: train_loss -0.1991 
2025-11-29 04:16:18.623043: val_loss -0.2113 
2025-11-29 04:16:18.623354: Pseudo dice [0.5406, 0.0006, 0.4468, 0.444, 0.5788, 0.0, 0.9074, 0.8859] 
2025-11-29 04:16:18.623522: Epoch time: 96.25 s 
2025-11-29 04:16:21.824813:  
2025-11-29 04:16:21.825126: Epoch 200 
2025-11-29 04:16:21.825376: Current learning rate: 0.00818 
2025-11-29 04:17:57.918640: train_loss -0.1952 
2025-11-29 04:17:57.918932: val_loss -0.2011 
2025-11-29 04:17:57.919111: Pseudo dice [0.6056, 0.0, 0.6258, 0.0, 0.0, 0.724, 0.8874, 0.8911] 
2025-11-29 04:17:57.919267: Epoch time: 96.1 s 
2025-11-29 04:18:00.085467:  
2025-11-29 04:18:00.085760: Epoch 201 
2025-11-29 04:18:00.085958: Current learning rate: 0.00817 
2025-11-29 04:19:35.447631: train_loss -0.203 
2025-11-29 04:19:35.448002: val_loss -0.2109 
2025-11-29 04:19:35.448237: Pseudo dice [0.589, 0.0001, 0.6702, 0.0, 0.3088, 0.7353, 0.8732, 0.8923] 
2025-11-29 04:19:35.448502: Epoch time: 95.36 s 
2025-11-29 04:19:37.724641:  
2025-11-29 04:19:37.725049: Epoch 202 
2025-11-29 04:19:37.725255: Current learning rate: 0.00816 
2025-11-29 04:21:12.539853: train_loss -0.2086 
2025-11-29 04:21:12.540098: val_loss -0.2115 
2025-11-29 04:21:12.540326: Pseudo dice [0.6045, 0.0007, 0.609, 0.0, 0.3671, 0.0088, 0.9217, 0.9035] 
2025-11-29 04:21:12.540479: Epoch time: 94.82 s 
2025-11-29 04:21:14.641564:  
2025-11-29 04:21:14.641867: Epoch 203 
2025-11-29 04:21:14.642056: Current learning rate: 0.00815 
2025-11-29 04:22:49.624446: train_loss -0.1912 
2025-11-29 04:22:49.624788: val_loss -0.197 
2025-11-29 04:22:49.624931: Pseudo dice [0.5747, 0.0072, 0.4808, 0.0, 0.4459, 0.0487, 0.8825, 0.8973] 
2025-11-29 04:22:49.625023: Epoch time: 94.98 s 
2025-11-29 04:22:51.664862:  
2025-11-29 04:22:51.665083: Epoch 204 
2025-11-29 04:22:51.665316: Current learning rate: 0.00814 
2025-11-29 04:24:26.939219: train_loss -0.1968 
2025-11-29 04:24:26.939488: val_loss -0.2279 
2025-11-29 04:24:26.939703: Pseudo dice [0.667, 0.0002, 0.7019, 0.0035, 0.6176, 0.0185, 0.909, 0.9167] 
2025-11-29 04:24:26.939848: Epoch time: 95.28 s 
2025-11-29 04:24:29.831334:  
2025-11-29 04:24:29.831731: Epoch 205 
2025-11-29 04:24:29.831931: Current learning rate: 0.00813 
2025-11-29 04:26:03.993308: train_loss -0.2137 
2025-11-29 04:26:03.993608: val_loss -0.2025 
2025-11-29 04:26:03.993800: Pseudo dice [0.0, 0.6465, 0.0, 0.6495, 0.5389, 0.0079, 0.9108, 0.8946] 
2025-11-29 04:26:03.993925: Epoch time: 94.16 s 
2025-11-29 04:26:05.929541:  
2025-11-29 04:26:05.929911: Epoch 206 
2025-11-29 04:26:05.930082: Current learning rate: 0.00813 
2025-11-29 04:27:40.757933: train_loss -0.1971 
2025-11-29 04:27:40.758251: val_loss -0.2036 
2025-11-29 04:27:40.758529: Pseudo dice [0.6613, 0.0125, 0.6342, 0.0, 0.6307, 0.0103, 0.8974, 0.8899] 
2025-11-29 04:27:40.758806: Epoch time: 94.83 s 
2025-11-29 04:27:42.809157:  
2025-11-29 04:27:42.809566: Epoch 207 
2025-11-29 04:27:42.809747: Current learning rate: 0.00812 
2025-11-29 04:29:17.195421: train_loss -0.1931 
2025-11-29 04:29:17.195655: val_loss -0.2198 
2025-11-29 04:29:17.195839: Pseudo dice [0.6396, 0.0134, 0.655, 0.0, 0.0, 0.5521, 0.911, 0.91] 
2025-11-29 04:29:17.195958: Epoch time: 94.39 s 
2025-11-29 04:29:19.039717:  
2025-11-29 04:29:19.040111: Epoch 208 
2025-11-29 04:29:19.040307: Current learning rate: 0.00811 
2025-11-29 04:30:53.459781: train_loss -0.1923 
2025-11-29 04:30:53.460265: val_loss -0.2278 
2025-11-29 04:30:53.460505: Pseudo dice [0.6528, 0.004, 0.0, 0.6691, 0.7084, 0.0023, 0.9091, 0.9046] 
2025-11-29 04:30:53.460652: Epoch time: 94.42 s 
2025-11-29 04:30:55.496767:  
2025-11-29 04:30:55.497114: Epoch 209 
2025-11-29 04:30:55.497319: Current learning rate: 0.0081 
2025-11-29 04:32:30.092591: train_loss -0.2027 
2025-11-29 04:32:30.092870: val_loss -0.2043 
2025-11-29 04:32:30.093329: Pseudo dice [0.6818, 0.0051, 0.0, 0.493, 0.7273, 0.1024, 0.8997, 0.9106] 
2025-11-29 04:32:30.093628: Epoch time: 94.6 s 
2025-11-29 04:32:31.948604:  
2025-11-29 04:32:31.948930: Epoch 210 
2025-11-29 04:32:31.949121: Current learning rate: 0.00809 
2025-11-29 04:34:06.362411: train_loss -0.1955 
2025-11-29 04:34:06.362667: val_loss -0.1887 
2025-11-29 04:34:06.362949: Pseudo dice [0.6637, 0.0072, 0.5077, 0.0, 0.7472, 0.0, 0.8955, 0.8897] 
2025-11-29 04:34:06.363078: Epoch time: 94.42 s 
2025-11-29 04:34:08.276910:  
2025-11-29 04:34:08.277308: Epoch 211 
2025-11-29 04:34:08.277474: Current learning rate: 0.00808 
2025-11-29 04:35:42.700702: train_loss -0.2067 
2025-11-29 04:35:42.701038: val_loss -0.1984 
2025-11-29 04:35:42.701227: Pseudo dice [0.7049, 0.0058, 0.7232, 0.0, 0.0, 0.7534, 0.8618, 0.8702] 
2025-11-29 04:35:42.701344: Epoch time: 94.43 s 
2025-11-29 04:35:44.467844:  
2025-11-29 04:35:44.468180: Epoch 212 
2025-11-29 04:35:44.468350: Current learning rate: 0.00807 
2025-11-29 04:37:18.642988: train_loss -0.2046 
2025-11-29 04:37:18.643265: val_loss -0.2 
2025-11-29 04:37:18.643464: Pseudo dice [0.5895, 0.0821, 0.7302, 0.0, 0.6327, 0.0646, 0.8834, 0.8906] 
2025-11-29 04:37:18.643599: Epoch time: 94.18 s 
2025-11-29 04:37:20.572238:  
2025-11-29 04:37:20.572547: Epoch 213 
2025-11-29 04:37:20.572708: Current learning rate: 0.00806 
2025-11-29 04:38:54.878000: train_loss -0.1943 
2025-11-29 04:38:54.878464: val_loss -0.2322 
2025-11-29 04:38:54.878843: Pseudo dice [0.59, 0.131, 0.0049, 0.681, 0.0, 0.6211, 0.9236, 0.9217] 
2025-11-29 04:38:54.879097: Epoch time: 94.31 s 
2025-11-29 04:38:56.853213:  
2025-11-29 04:38:56.853511: Epoch 214 
2025-11-29 04:38:56.853676: Current learning rate: 0.00805 
2025-11-29 04:40:30.427234: train_loss -0.2052 
2025-11-29 04:40:30.427543: val_loss -0.1706 
2025-11-29 04:40:30.427842: Pseudo dice [0.0, 0.5914, 0.0, 0.5249, 0.0, 0.4875, 0.8932, 0.8974] 
2025-11-29 04:40:30.427946: Epoch time: 93.58 s 
2025-11-29 04:40:32.499472:  
2025-11-29 04:40:32.499825: Epoch 215 
2025-11-29 04:40:32.500030: Current learning rate: 0.00804 
2025-11-29 04:42:06.450422: train_loss -0.2144 
2025-11-29 04:42:06.450737: val_loss -0.2183 
2025-11-29 04:42:06.450935: Pseudo dice [0.0, 0.73, 0.0021, 0.6641, 0.6206, 0.0012, 0.915, 0.8813] 
2025-11-29 04:42:06.451087: Epoch time: 93.95 s 
2025-11-29 04:42:08.305899:  
2025-11-29 04:42:08.306248: Epoch 216 
2025-11-29 04:42:08.306417: Current learning rate: 0.00803 
2025-11-29 04:43:42.819016: train_loss -0.1951 
2025-11-29 04:43:42.819318: val_loss -0.185 
2025-11-29 04:43:42.819567: Pseudo dice [0.0025, 0.679, 0.5718, 0.0029, 0.4071, 0.0077, 0.8733, 0.8852] 
2025-11-29 04:43:42.819864: Epoch time: 94.51 s 
2025-11-29 04:43:44.705451:  
2025-11-29 04:43:44.705734: Epoch 217 
2025-11-29 04:43:44.705897: Current learning rate: 0.00802 
2025-11-29 04:45:20.416096: train_loss -0.1756 
2025-11-29 04:45:20.416392: val_loss -0.2251 
2025-11-29 04:45:20.416627: Pseudo dice [0.0, 0.7516, 0.5994, 0.0056, 0.0, 0.7684, 0.8914, 0.9105] 
2025-11-29 04:45:20.416765: Epoch time: 95.71 s 
2025-11-29 04:45:22.438370:  
2025-11-29 04:45:22.438728: Epoch 218 
2025-11-29 04:45:22.438930: Current learning rate: 0.00801 
2025-11-29 04:46:58.236789: train_loss -0.1885 
2025-11-29 04:46:58.237122: val_loss -0.2099 
2025-11-29 04:46:58.237383: Pseudo dice [0.6032, 0.3079, 0.5884, 0.0695, 0.4601, 0.0146, 0.8267, 0.8536] 
2025-11-29 04:46:58.237525: Epoch time: 95.8 s 
2025-11-29 04:47:00.172700:  
2025-11-29 04:47:00.173020: Epoch 219 
2025-11-29 04:47:00.173207: Current learning rate: 0.00801 
2025-11-29 04:48:34.412829: train_loss -0.1909 
2025-11-29 04:48:34.413053: val_loss -0.1995 
2025-11-29 04:48:34.413267: Pseudo dice [0.6993, 0.005, 0.3775, 0.6008, 0.7435, 0.0567, 0.8668, 0.9048] 
2025-11-29 04:48:34.413385: Epoch time: 94.24 s 
2025-11-29 04:48:36.329420:  
2025-11-29 04:48:36.329713: Epoch 220 
2025-11-29 04:48:36.329893: Current learning rate: 0.008 
2025-11-29 04:50:10.230767: train_loss -0.1859 
2025-11-29 04:50:10.231019: val_loss -0.2142 
2025-11-29 04:50:10.231277: Pseudo dice [0.0001, 0.6121, 0.0004, 0.6457, 0.0, 0.5687, 0.908, 0.886] 
2025-11-29 04:50:10.231452: Epoch time: 93.9 s 
2025-11-29 04:50:12.152451:  
2025-11-29 04:50:12.152776: Epoch 221 
2025-11-29 04:50:12.152940: Current learning rate: 0.00799 
2025-11-29 04:51:46.459316: train_loss -0.1972 
2025-11-29 04:51:46.459625: val_loss -0.2108 
2025-11-29 04:51:46.459949: Pseudo dice [0.5885, 0.0352, 0.4676, 0.0, 0.4626, 0.0756, 0.9167, 0.8933] 
2025-11-29 04:51:46.460110: Epoch time: 94.31 s 
2025-11-29 04:51:48.305171:  
2025-11-29 04:51:48.305469: Epoch 222 
2025-11-29 04:51:48.305629: Current learning rate: 0.00798 
2025-11-29 04:53:23.057681: train_loss -0.1952 
2025-11-29 04:53:23.058048: val_loss -0.1988 
2025-11-29 04:53:23.058261: Pseudo dice [0.58, 0.0, 0.6762, 0.0, 0.6245, 0.024, 0.8949, 0.9219] 
2025-11-29 04:53:23.058376: Epoch time: 94.75 s 
2025-11-29 04:53:25.107214:  
2025-11-29 04:53:25.107592: Epoch 223 
2025-11-29 04:53:25.107771: Current learning rate: 0.00797 
2025-11-29 04:54:59.501738: train_loss -0.2041 
2025-11-29 04:54:59.502159: val_loss -0.2071 
2025-11-29 04:54:59.502401: Pseudo dice [0.6097, 0.0003, 0.0, 0.6178, 0.6021, 0.2176, 0.8651, 0.9139] 
2025-11-29 04:54:59.502548: Epoch time: 94.4 s 
2025-11-29 04:55:01.411196:  
2025-11-29 04:55:01.411539: Epoch 224 
2025-11-29 04:55:01.411729: Current learning rate: 0.00796 
2025-11-29 04:56:35.503695: train_loss -0.2044 
2025-11-29 04:56:35.504122: val_loss -0.2039 
2025-11-29 04:56:35.504337: Pseudo dice [0.0366, 0.6552, 0.0, 0.7066, 0.639, 0.3545, 0.8569, 0.8769] 
2025-11-29 04:56:35.504493: Epoch time: 94.09 s 
2025-11-29 04:56:37.354504:  
2025-11-29 04:56:37.354800: Epoch 225 
2025-11-29 04:56:37.354975: Current learning rate: 0.00795 
2025-11-29 04:58:11.555239: train_loss -0.187 
2025-11-29 04:58:11.555746: val_loss -0.213 
2025-11-29 04:58:11.556015: Pseudo dice [0.6041, 0.0434, 0.1883, 0.5486, 0.0, 0.7764, 0.8984, 0.8992] 
2025-11-29 04:58:11.556216: Epoch time: 94.2 s 
2025-11-29 04:58:13.407259:  
2025-11-29 04:58:13.407411: Epoch 226 
2025-11-29 04:58:13.407676: Current learning rate: 0.00794 
2025-11-29 04:59:47.474998: train_loss -0.201 
2025-11-29 04:59:47.475273: val_loss -0.2328 
2025-11-29 04:59:47.475478: Pseudo dice [0.0243, 0.6967, 0.5746, 0.0722, 0.6064, 0.0001, 0.9174, 0.9077] 
2025-11-29 04:59:47.475611: Epoch time: 94.07 s 
2025-11-29 04:59:50.242389:  
2025-11-29 04:59:50.242826: Epoch 227 
2025-11-29 04:59:50.242995: Current learning rate: 0.00793 
2025-11-29 05:01:24.208422: train_loss -0.1924 
2025-11-29 05:01:24.208756: val_loss -0.1978 
2025-11-29 05:01:24.208910: Pseudo dice [0.6853, 0.0893, 0.0, 0.7056, 0.0, 0.4488, 0.8897, 0.8498] 
2025-11-29 05:01:24.209012: Epoch time: 93.97 s 
2025-11-29 05:01:26.077524:  
2025-11-29 05:01:26.077880: Epoch 228 
2025-11-29 05:01:26.078068: Current learning rate: 0.00792 
2025-11-29 05:03:00.618836: train_loss -0.1938 
2025-11-29 05:03:00.619100: val_loss -0.2092 
2025-11-29 05:03:00.619372: Pseudo dice [0.6035, 0.032, 0.6574, 0.0, 0.7086, 0.0718, 0.9084, 0.8941] 
2025-11-29 05:03:00.619506: Epoch time: 94.54 s 
2025-11-29 05:03:02.576202:  
2025-11-29 05:03:02.576581: Epoch 229 
2025-11-29 05:03:02.576778: Current learning rate: 0.00791 
2025-11-29 05:04:37.695945: train_loss -0.2032 
2025-11-29 05:04:37.696220: val_loss -0.2147 
2025-11-29 05:04:37.696446: Pseudo dice [0.2792, 0.6357, 0.7412, 0.0018, 0.6693, 0.0767, 0.9286, 0.8731] 
2025-11-29 05:04:37.696573: Epoch time: 95.12 s 
2025-11-29 05:04:37.696707: Yayy! New best EMA pseudo Dice: 0.4795 
2025-11-29 05:04:40.446844:  
2025-11-29 05:04:40.447208: Epoch 230 
2025-11-29 05:04:40.447389: Current learning rate: 0.0079 
2025-11-29 05:06:14.579848: train_loss -0.1969 
2025-11-29 05:06:14.580325: val_loss -0.2143 
2025-11-29 05:06:14.580547: Pseudo dice [0.593, 0.0791, 0.0, 0.8003, 0.222, 0.6125, 0.8795, 0.9083] 
2025-11-29 05:06:14.580705: Epoch time: 94.13 s 
2025-11-29 05:06:14.580828: Yayy! New best EMA pseudo Dice: 0.4827 
2025-11-29 05:06:17.214693:  
2025-11-29 05:06:17.215022: Epoch 231 
2025-11-29 05:06:17.215214: Current learning rate: 0.00789 
2025-11-29 05:07:51.535788: train_loss -0.2058 
2025-11-29 05:07:51.536084: val_loss -0.1882 
2025-11-29 05:07:51.536474: Pseudo dice [0.0, 0.6476, 0.0, 0.5965, 0.0, 0.6547, 0.9063, 0.8942] 
2025-11-29 05:07:51.536728: Epoch time: 94.32 s 
2025-11-29 05:07:53.410049:  
2025-11-29 05:07:53.410367: Epoch 232 
2025-11-29 05:07:53.410571: Current learning rate: 0.00789 
2025-11-29 05:09:27.430539: train_loss -0.1953 
2025-11-29 05:09:27.430842: val_loss -0.1714 
2025-11-29 05:09:27.430986: Pseudo dice [0.0, 0.6671, 0.0, 0.5631, 0.4603, 0.001, 0.878, 0.8594] 
2025-11-29 05:09:27.431086: Epoch time: 94.02 s 
2025-11-29 05:09:29.382038:  
2025-11-29 05:09:29.382414: Epoch 233 
2025-11-29 05:09:29.382602: Current learning rate: 0.00788 
2025-11-29 05:11:03.659837: train_loss -0.1917 
2025-11-29 05:11:03.660320: val_loss -0.1966 
2025-11-29 05:11:03.660542: Pseudo dice [0.686, 0.0, 0.0, 0.5418, 0.6474, 0.1491, 0.8992, 0.9037] 
2025-11-29 05:11:03.660654: Epoch time: 94.28 s 
2025-11-29 05:11:05.540555:  
2025-11-29 05:11:05.540906: Epoch 234 
2025-11-29 05:11:05.541075: Current learning rate: 0.00787 
2025-11-29 05:12:39.783009: train_loss -0.2028 
2025-11-29 05:12:39.783312: val_loss -0.1965 
2025-11-29 05:12:39.783447: Pseudo dice [0.6105, 0.0, 0.7131, 0.0, 0.5913, 0.001, 0.9336, 0.9092] 
2025-11-29 05:12:39.783537: Epoch time: 94.24 s 
2025-11-29 05:12:41.703570:  
2025-11-29 05:12:41.703903: Epoch 235 
2025-11-29 05:12:41.704070: Current learning rate: 0.00786 
2025-11-29 05:14:15.774066: train_loss -0.1932 
2025-11-29 05:14:15.774411: val_loss -0.2261 
2025-11-29 05:14:15.774637: Pseudo dice [0.0485, 0.5787, 0.6009, 0.0, 0.025, 0.5434, 0.9026, 0.902] 
2025-11-29 05:14:15.774917: Epoch time: 94.07 s 
2025-11-29 05:14:17.800002:  
2025-11-29 05:14:17.800382: Epoch 236 
2025-11-29 05:14:17.800567: Current learning rate: 0.00785 
2025-11-29 05:15:51.655895: train_loss -0.1975 
2025-11-29 05:15:51.656193: val_loss -0.2008 
2025-11-29 05:15:51.656477: Pseudo dice [0.5875, 0.0476, 0.5967, 0.0, 0.0, 0.7495, 0.8869, 0.9118] 
2025-11-29 05:15:51.656669: Epoch time: 93.86 s 
2025-11-29 05:15:53.494206:  
2025-11-29 05:15:53.494563: Epoch 237 
2025-11-29 05:15:53.494756: Current learning rate: 0.00784 
2025-11-29 05:17:27.571797: train_loss -0.1974 
2025-11-29 05:17:27.572082: val_loss -0.2106 
2025-11-29 05:17:27.572339: Pseudo dice [0.0119, 0.5491, 0.5689, 0.0, 0.6582, 0.0214, 0.8958, 0.9002] 
2025-11-29 05:17:27.572479: Epoch time: 94.08 s 
2025-11-29 05:17:29.375979:  
2025-11-29 05:17:29.376319: Epoch 238 
2025-11-29 05:17:29.376491: Current learning rate: 0.00783 
2025-11-29 05:19:03.291336: train_loss -0.1979 
2025-11-29 05:19:03.291722: val_loss -0.1821 
2025-11-29 05:19:03.291883: Pseudo dice [0.0, 0.6444, 0.0013, 0.6274, 0.0, 0.3533, 0.9242, 0.909] 
2025-11-29 05:19:03.292032: Epoch time: 93.92 s 
2025-11-29 05:19:05.177370:  
2025-11-29 05:19:05.177760: Epoch 239 
2025-11-29 05:19:05.178060: Current learning rate: 0.00782 
2025-11-29 05:20:39.368549: train_loss -0.202 
2025-11-29 05:20:39.368878: val_loss -0.1944 
2025-11-29 05:20:39.369308: Pseudo dice [0.1143, 0.6223, 0.7028, 0.0, 0.6247, 0.0, 0.8979, 0.9016] 
2025-11-29 05:20:39.369503: Epoch time: 94.19 s 
2025-11-29 05:20:41.327692:  
2025-11-29 05:20:41.328046: Epoch 240 
2025-11-29 05:20:41.328242: Current learning rate: 0.00781 
2025-11-29 05:22:14.896785: train_loss -0.1978 
2025-11-29 05:22:14.897018: val_loss -0.2212 
2025-11-29 05:22:14.897270: Pseudo dice [0.5421, 0.0003, 0.583, 0.0007, 0.0, 0.7823, 0.9006, 0.906] 
2025-11-29 05:22:14.897506: Epoch time: 93.57 s 
2025-11-29 05:22:16.826124:  
2025-11-29 05:22:16.826503: Epoch 241 
2025-11-29 05:22:16.826678: Current learning rate: 0.0078 
2025-11-29 05:23:51.066314: train_loss -0.2089 
2025-11-29 05:23:51.066594: val_loss -0.1902 
2025-11-29 05:23:51.066797: Pseudo dice [0.5318, 0.0, 0.5349, 0.0, 0.0, 0.5129, 0.9247, 0.9221] 
2025-11-29 05:23:51.066947: Epoch time: 94.24 s 
2025-11-29 05:23:53.012311:  
2025-11-29 05:23:53.012528: Epoch 242 
2025-11-29 05:23:53.012686: Current learning rate: 0.00779 
2025-11-29 05:25:27.386392: train_loss -0.2069 
2025-11-29 05:25:27.386833: val_loss -0.2186 
2025-11-29 05:25:27.386998: Pseudo dice [0.6193, 0.0008, 0.0, 0.7705, 0.6741, 0.0031, 0.8448, 0.8868] 
2025-11-29 05:25:27.387093: Epoch time: 94.38 s 
2025-11-29 05:25:29.405461:  
2025-11-29 05:25:29.405799: Epoch 243 
2025-11-29 05:25:29.406013: Current learning rate: 0.00778 
2025-11-29 05:27:03.404611: train_loss -0.1906 
2025-11-29 05:27:03.404967: val_loss -0.1965 
2025-11-29 05:27:03.405272: Pseudo dice [0.5411, 0.0005, 0.5516, 0.0, 0.0, 0.7896, 0.9083, 0.8957] 
2025-11-29 05:27:03.405439: Epoch time: 94.0 s 
2025-11-29 05:27:05.261846:  
2025-11-29 05:27:05.262183: Epoch 244 
2025-11-29 05:27:05.262420: Current learning rate: 0.00777 
2025-11-29 05:28:39.255670: train_loss -0.1979 
2025-11-29 05:28:39.255964: val_loss -0.2048 
2025-11-29 05:28:39.256101: Pseudo dice [0.0007, 0.6872, 0.0, 0.5552, 0.6388, 0.0002, 0.9057, 0.9252] 
2025-11-29 05:28:39.256238: Epoch time: 94.0 s 
2025-11-29 05:28:41.160061:  
2025-11-29 05:28:41.160392: Epoch 245 
2025-11-29 05:28:41.160589: Current learning rate: 0.00777 
2025-11-29 05:30:15.656453: train_loss -0.1958 
2025-11-29 05:30:15.656784: val_loss -0.1937 
2025-11-29 05:30:15.656937: Pseudo dice [0.0, 0.6261, 0.0103, 0.5896, 0.4454, 0.1774, 0.8655, 0.9135] 
2025-11-29 05:30:15.657037: Epoch time: 94.5 s 
2025-11-29 05:30:17.618444:  
2025-11-29 05:30:17.618847: Epoch 246 
2025-11-29 05:30:17.619030: Current learning rate: 0.00776 
2025-11-29 05:31:51.485270: train_loss -0.187 
2025-11-29 05:31:51.485471: val_loss -0.2234 
2025-11-29 05:31:51.485634: Pseudo dice [0.716, 0.0, 0.7226, 0.0, 0.0, 0.6151, 0.9204, 0.9136] 
2025-11-29 05:31:51.485727: Epoch time: 93.87 s 
2025-11-29 05:31:53.323940:  
2025-11-29 05:31:53.324258: Epoch 247 
2025-11-29 05:31:53.324442: Current learning rate: 0.00775 
2025-11-29 05:33:26.481318: train_loss -0.2006 
2025-11-29 05:33:26.481586: val_loss -0.2111 
2025-11-29 05:33:26.481795: Pseudo dice [0.2356, 0.5886, 0.6137, 0.0658, 0.661, 0.0286, 0.8987, 0.8768] 
2025-11-29 05:33:26.482062: Epoch time: 93.16 s 
2025-11-29 05:33:28.528860:  
2025-11-29 05:33:28.529132: Epoch 248 
2025-11-29 05:33:28.529318: Current learning rate: 0.00774 
2025-11-29 05:35:02.321708: train_loss -0.1997 
2025-11-29 05:35:02.322084: val_loss -0.2011 
2025-11-29 05:35:02.322286: Pseudo dice [0.0, 0.6095, 0.0003, 0.57, 0.4945, 0.2862, 0.9289, 0.9176] 
2025-11-29 05:35:02.322398: Epoch time: 93.79 s 
2025-11-29 05:35:05.060065:  
2025-11-29 05:35:05.060458: Epoch 249 
2025-11-29 05:35:05.060627: Current learning rate: 0.00773 
2025-11-29 05:36:38.789001: train_loss -0.2123 
2025-11-29 05:36:38.789393: val_loss -0.2161 
2025-11-29 05:36:38.789668: Pseudo dice [0.6618, 0.0, 0.6201, 0.0025, 0.7927, 0.116, 0.885, 0.8901] 
2025-11-29 05:36:38.789840: Epoch time: 93.73 s 
2025-11-29 05:36:41.893144:  
2025-11-29 05:36:41.893486: Epoch 250 
2025-11-29 05:36:41.893890: Current learning rate: 0.00772 
2025-11-29 05:38:16.213965: train_loss -0.2034 
2025-11-29 05:38:16.214269: val_loss -0.2097 
2025-11-29 05:38:16.214547: Pseudo dice [0.5822, 0.0002, 0.6457, 0.0027, 0.226, 0.0919, 0.9233, 0.9055] 
2025-11-29 05:38:16.214689: Epoch time: 94.32 s 
2025-11-29 05:38:18.066761:  
2025-11-29 05:38:18.067111: Epoch 251 
2025-11-29 05:38:18.067307: Current learning rate: 0.00771 
2025-11-29 05:39:52.452372: train_loss -0.2015 
2025-11-29 05:39:52.452934: val_loss -0.2103 
2025-11-29 05:39:52.453330: Pseudo dice [0.653, 0.0, 0.0304, 0.6341, 0.5917, 0.0038, 0.8933, 0.9282] 
2025-11-29 05:39:52.453500: Epoch time: 94.39 s 
2025-11-29 05:39:54.443993:  
2025-11-29 05:39:54.444358: Epoch 252 
2025-11-29 05:39:54.444539: Current learning rate: 0.0077 
2025-11-29 05:41:28.369569: train_loss -0.1958 
2025-11-29 05:41:28.369823: val_loss -0.1954 
2025-11-29 05:41:28.370028: Pseudo dice [0.6092, 0.3019, 0.0173, 0.5856, 0.0, 0.4447, 0.8135, 0.8939] 
2025-11-29 05:41:28.370183: Epoch time: 93.93 s 
2025-11-29 05:41:30.436799:  
2025-11-29 05:41:30.437233: Epoch 253 
2025-11-29 05:41:30.437406: Current learning rate: 0.00769 
2025-11-29 05:43:04.938539: train_loss -0.2037 
2025-11-29 05:43:04.938871: val_loss -0.208 
2025-11-29 05:43:04.939028: Pseudo dice [0.6038, 0.0002, 0.6005, 0.0, 0.0, 0.6568, 0.9043, 0.9207] 
2025-11-29 05:43:04.939130: Epoch time: 94.5 s 
2025-11-29 05:43:06.779398:  
2025-11-29 05:43:06.779751: Epoch 254 
2025-11-29 05:43:06.779932: Current learning rate: 0.00768 
2025-11-29 05:44:41.162267: train_loss -0.1898 
2025-11-29 05:44:41.162603: val_loss -0.1962 
2025-11-29 05:44:41.162925: Pseudo dice [0.0, 0.5376, 0.0004, 0.5433, 0.0, 0.3846, 0.8964, 0.8895] 
2025-11-29 05:44:41.163100: Epoch time: 94.38 s 
2025-11-29 05:44:43.114912:  
2025-11-29 05:44:43.115251: Epoch 255 
2025-11-29 05:44:43.115412: Current learning rate: 0.00767 
2025-11-29 05:46:16.936205: train_loss -0.2026 
2025-11-29 05:46:16.936646: val_loss -0.1915 
2025-11-29 05:46:16.936808: Pseudo dice [0.4664, 0.5324, 0.6579, 0.0028, 0.0596, 0.6566, 0.9184, 0.8959] 
2025-11-29 05:46:16.936903: Epoch time: 93.82 s 
2025-11-29 05:46:18.793951:  
2025-11-29 05:46:18.794306: Epoch 256 
2025-11-29 05:46:18.794485: Current learning rate: 0.00766 
2025-11-29 05:47:52.753585: train_loss -0.1934 
2025-11-29 05:47:52.753870: val_loss -0.21 
2025-11-29 05:47:52.754129: Pseudo dice [0.6384, 0.0039, 0.0, 0.6142, 0.6095, 0.0001, 0.8127, 0.8957] 
2025-11-29 05:47:52.754415: Epoch time: 93.96 s 
2025-11-29 05:47:54.641894:  
2025-11-29 05:47:54.642247: Epoch 257 
2025-11-29 05:47:54.642429: Current learning rate: 0.00765 
2025-11-29 05:49:28.319757: train_loss -0.2006 
2025-11-29 05:49:28.320087: val_loss -0.2136 
2025-11-29 05:49:28.320364: Pseudo dice [0.001, 0.6051, 0.0011, 0.4383, 0.5268, 0.0354, 0.9092, 0.8947] 
2025-11-29 05:49:28.320538: Epoch time: 93.68 s 
2025-11-29 05:49:30.240560:  
2025-11-29 05:49:30.240927: Epoch 258 
2025-11-29 05:49:30.241111: Current learning rate: 0.00764 
2025-11-29 05:51:04.453530: train_loss -0.2065 
2025-11-29 05:51:04.453776: val_loss -0.1844 
2025-11-29 05:51:04.454012: Pseudo dice [0.7119, 0.0, 0.5461, 0.0, 0.6845, 0.2126, 0.8982, 0.914] 
2025-11-29 05:51:04.454197: Epoch time: 94.21 s 
2025-11-29 05:51:06.350577:  
2025-11-29 05:51:06.350877: Epoch 259 
2025-11-29 05:51:06.351047: Current learning rate: 0.00764 
2025-11-29 05:52:40.000554: train_loss -0.2085 
2025-11-29 05:52:40.000782: val_loss -0.2225 
2025-11-29 05:52:40.001014: Pseudo dice [0.0, 0.6376, 0.0, 0.6096, 0.0, 0.5937, 0.9246, 0.9245] 
2025-11-29 05:52:40.001232: Epoch time: 93.65 s 
2025-11-29 05:52:41.892495:  
2025-11-29 05:52:41.892843: Epoch 260 
2025-11-29 05:52:41.893021: Current learning rate: 0.00763 
2025-11-29 05:54:15.844282: train_loss -0.2029 
2025-11-29 05:54:15.844579: val_loss -0.2099 
2025-11-29 05:54:15.844804: Pseudo dice [0.5583, 0.0262, 0.6281, 0.0, 0.0, 0.6674, 0.9069, 0.8983] 
2025-11-29 05:54:15.844951: Epoch time: 93.95 s 
2025-11-29 05:54:17.782791:  
2025-11-29 05:54:17.783168: Epoch 261 
2025-11-29 05:54:17.783342: Current learning rate: 0.00762 
2025-11-29 05:55:50.937742: train_loss -0.223 
2025-11-29 05:55:50.938165: val_loss -0.2003 
2025-11-29 05:55:50.938403: Pseudo dice [0.0, 0.6457, 0.5448, 0.0, 0.0, 0.5349, 0.9024, 0.8757] 
2025-11-29 05:55:50.938560: Epoch time: 93.16 s 
2025-11-29 05:55:52.859879:  
2025-11-29 05:55:52.860215: Epoch 262 
2025-11-29 05:55:52.860380: Current learning rate: 0.00761 
2025-11-29 05:57:26.072586: train_loss -0.2026 
2025-11-29 05:57:26.072978: val_loss -0.2307 
2025-11-29 05:57:26.073497: Pseudo dice [0.7214, 0.019, 0.5554, 0.3569, 0.7002, 0.0, 0.908, 0.9159] 
2025-11-29 05:57:26.073678: Epoch time: 93.21 s 
2025-11-29 05:57:28.036364:  
2025-11-29 05:57:28.036614: Epoch 263 
2025-11-29 05:57:28.036785: Current learning rate: 0.0076 
2025-11-29 05:59:02.079493: train_loss -0.2129 
2025-11-29 05:59:02.079805: val_loss -0.2281 
2025-11-29 05:59:02.080118: Pseudo dice [0.0, 0.7252, 0.0427, 0.7501, 0.0, 0.7196, 0.9157, 0.9225] 
2025-11-29 05:59:02.080290: Epoch time: 94.04 s 
2025-11-29 05:59:04.065767:  
2025-11-29 05:59:04.066095: Epoch 264 
2025-11-29 05:59:04.066311: Current learning rate: 0.00759 
2025-11-29 06:00:38.391903: train_loss -0.2 
2025-11-29 06:00:38.392204: val_loss -0.2095 
2025-11-29 06:00:38.392440: Pseudo dice [0.0, 0.6731, 0.0, 0.7464, 0.0, 0.8037, 0.9052, 0.8965] 
2025-11-29 06:00:38.392598: Epoch time: 94.33 s 
2025-11-29 06:00:40.262461:  
2025-11-29 06:00:40.262743: Epoch 265 
2025-11-29 06:00:40.262916: Current learning rate: 0.00758 
2025-11-29 06:02:13.898244: train_loss -0.199 
2025-11-29 06:02:13.898505: val_loss -0.2038 
2025-11-29 06:02:13.898740: Pseudo dice [0.0, 0.6793, 0.6056, 0.0, 0.5286, 0.002, 0.8769, 0.9047] 
2025-11-29 06:02:13.898972: Epoch time: 93.64 s 
2025-11-29 06:02:15.739919:  
2025-11-29 06:02:15.740276: Epoch 266 
2025-11-29 06:02:15.740453: Current learning rate: 0.00757 
2025-11-29 06:03:49.776088: train_loss -0.197 
2025-11-29 06:03:49.776536: val_loss -0.2087 
2025-11-29 06:03:49.776859: Pseudo dice [0.6549, 0.0047, 0.6116, 0.0, 0.0, 0.4832, 0.8707, 0.8897] 
2025-11-29 06:03:49.777020: Epoch time: 94.04 s 
2025-11-29 06:03:51.733882:  
2025-11-29 06:03:51.734190: Epoch 267 
2025-11-29 06:03:51.734363: Current learning rate: 0.00756 
2025-11-29 06:05:25.664697: train_loss -0.1975 
2025-11-29 06:05:25.665003: val_loss -0.2227 
2025-11-29 06:05:25.665215: Pseudo dice [0.6428, 0.0071, 0.0011, 0.6575, 0.7701, 0.011, 0.9265, 0.9244] 
2025-11-29 06:05:25.665388: Epoch time: 93.93 s 
2025-11-29 06:05:27.543255:  
2025-11-29 06:05:27.543592: Epoch 268 
2025-11-29 06:05:27.543770: Current learning rate: 0.00755 
2025-11-29 06:07:01.517159: train_loss -0.1935 
2025-11-29 06:07:01.517475: val_loss -0.2096 
2025-11-29 06:07:01.517690: Pseudo dice [0.6132, 0.0174, 0.6276, 0.0, 0.5882, 0.0425, 0.8417, 0.8822] 
2025-11-29 06:07:01.517832: Epoch time: 93.98 s 
2025-11-29 06:07:03.349786:  
2025-11-29 06:07:03.350097: Epoch 269 
2025-11-29 06:07:03.350288: Current learning rate: 0.00754 
2025-11-29 06:08:37.364136: train_loss -0.2122 
2025-11-29 06:08:37.364393: val_loss -0.2123 
2025-11-29 06:08:37.364599: Pseudo dice [0.0, 0.6244, 0.6327, 0.0, 0.0, 0.496, 0.9002, 0.8988] 
2025-11-29 06:08:37.364748: Epoch time: 94.02 s 
2025-11-29 06:08:39.276383:  
2025-11-29 06:08:39.276701: Epoch 270 
2025-11-29 06:08:39.276864: Current learning rate: 0.00753 
2025-11-29 06:10:13.721765: train_loss -0.1987 
2025-11-29 06:10:13.722044: val_loss -0.1588 
2025-11-29 06:10:13.722315: Pseudo dice [0.5388, 0.1509, 0.7041, 0.0, 0.4916, 0.3331, 0.9162, 0.7775] 
2025-11-29 06:10:13.722600: Epoch time: 94.45 s 
2025-11-29 06:10:16.623620:  
2025-11-29 06:10:16.623987: Epoch 271 
2025-11-29 06:10:16.624190: Current learning rate: 0.00752 
2025-11-29 06:11:51.083359: train_loss -0.2024 
2025-11-29 06:11:51.083783: val_loss -0.2215 
2025-11-29 06:11:51.084641: Pseudo dice [0.589, 0.0005, 0.5857, 0.0, 0.1119, 0.632, 0.8825, 0.9091] 
2025-11-29 06:11:51.085101: Epoch time: 94.46 s 
2025-11-29 06:11:53.011102:  
2025-11-29 06:11:53.011442: Epoch 272 
2025-11-29 06:11:53.011616: Current learning rate: 0.00751 
2025-11-29 06:13:27.909079: train_loss -0.202 
2025-11-29 06:13:27.909330: val_loss -0.2271 
2025-11-29 06:13:27.909482: Pseudo dice [0.6615, 0.0003, 0.7188, 0.0, 0.6527, 0.0594, 0.9154, 0.9169] 
2025-11-29 06:13:27.909574: Epoch time: 94.9 s 
2025-11-29 06:13:29.803679:  
2025-11-29 06:13:29.804024: Epoch 273 
2025-11-29 06:13:29.804204: Current learning rate: 0.00751 
2025-11-29 06:15:03.951958: train_loss -0.193 
2025-11-29 06:15:03.952263: val_loss -0.2367 
2025-11-29 06:15:03.952531: Pseudo dice [0.0277, 0.6143, 0.0059, 0.6111, 0.0, 0.5776, 0.9013, 0.9141] 
2025-11-29 06:15:03.952639: Epoch time: 94.15 s 
2025-11-29 06:15:05.896298:  
2025-11-29 06:15:05.896671: Epoch 274 
2025-11-29 06:15:05.896842: Current learning rate: 0.0075 
2025-11-29 06:16:39.943801: train_loss -0.2074 
2025-11-29 06:16:39.944048: val_loss -0.2272 
2025-11-29 06:16:39.944307: Pseudo dice [0.658, 0.0022, 0.6101, 0.0, 0.0, 0.7322, 0.8971, 0.9151] 
2025-11-29 06:16:39.944443: Epoch time: 94.05 s 
2025-11-29 06:16:41.857836:  
2025-11-29 06:16:41.858263: Epoch 275 
2025-11-29 06:16:41.858470: Current learning rate: 0.00749 
2025-11-29 06:18:16.438357: train_loss -0.1969 
2025-11-29 06:18:16.438671: val_loss -0.2145 
2025-11-29 06:18:16.438917: Pseudo dice [0.0006, 0.739, 0.6429, 0.0, 0.0, 0.8062, 0.9198, 0.9184] 
2025-11-29 06:18:16.439175: Epoch time: 94.58 s 
2025-11-29 06:18:18.272311:  
2025-11-29 06:18:18.272687: Epoch 276 
2025-11-29 06:18:18.272880: Current learning rate: 0.00748 
2025-11-29 06:19:52.386352: train_loss -0.1997 
2025-11-29 06:19:52.386711: val_loss -0.2249 
2025-11-29 06:19:52.387197: Pseudo dice [0.017, 0.7049, 0.0048, 0.6094, 0.6128, 0.1826, 0.9052, 0.902] 
2025-11-29 06:19:52.387529: Epoch time: 94.12 s 
2025-11-29 06:19:54.480080:  
2025-11-29 06:19:54.480430: Epoch 277 
2025-11-29 06:19:54.480599: Current learning rate: 0.00747 
2025-11-29 06:21:28.839482: train_loss -0.2114 
2025-11-29 06:21:28.839747: val_loss -0.2245 
2025-11-29 06:21:28.839988: Pseudo dice [0.631, 0.0003, 0.0108, 0.5831, 0.5191, 0.0275, 0.9142, 0.9124] 
2025-11-29 06:21:28.840187: Epoch time: 94.36 s 
2025-11-29 06:21:30.751746:  
2025-11-29 06:21:30.752069: Epoch 278 
2025-11-29 06:21:30.752255: Current learning rate: 0.00746 
2025-11-29 06:23:05.312078: train_loss -0.1998 
2025-11-29 06:23:05.312352: val_loss -0.2032 
2025-11-29 06:23:05.312602: Pseudo dice [0.5834, 0.0, 0.5499, 0.0, 0.7025, 0.0, 0.8983, 0.901] 
2025-11-29 06:23:05.312753: Epoch time: 94.56 s 
2025-11-29 06:23:07.202694:  
2025-11-29 06:23:07.203016: Epoch 279 
2025-11-29 06:23:07.203207: Current learning rate: 0.00745 
2025-11-29 06:24:41.114805: train_loss -0.2002 
2025-11-29 06:24:41.115098: val_loss -0.2219 
2025-11-29 06:24:41.115378: Pseudo dice [0.6979, 0.0007, 0.7289, 0.0, 0.6977, 0.0, 0.9013, 0.908] 
2025-11-29 06:24:41.115571: Epoch time: 93.91 s 
2025-11-29 06:24:43.148653:  
2025-11-29 06:24:43.148981: Epoch 280 
2025-11-29 06:24:43.149169: Current learning rate: 0.00744 
2025-11-29 06:26:16.813928: train_loss -0.1981 
2025-11-29 06:26:16.814204: val_loss -0.224 
2025-11-29 06:26:16.814436: Pseudo dice [0.7166, 0.0002, 0.0014, 0.6437, 0.8201, 0.0, 0.915, 0.9427] 
2025-11-29 06:26:16.814626: Epoch time: 93.67 s 
2025-11-29 06:26:18.589740:  
2025-11-29 06:26:18.590052: Epoch 281 
2025-11-29 06:26:18.590243: Current learning rate: 0.00743 
2025-11-29 06:27:52.110568: train_loss -0.2035 
2025-11-29 06:27:52.110800: val_loss -0.2204 
2025-11-29 06:27:52.110961: Pseudo dice [0.5956, 0.0007, 0.2822, 0.5483, 0.0, 0.658, 0.9015, 0.8848] 
2025-11-29 06:27:52.111072: Epoch time: 93.52 s 
2025-11-29 06:27:53.996027:  
2025-11-29 06:27:53.996266: Epoch 282 
2025-11-29 06:27:53.996439: Current learning rate: 0.00742 
2025-11-29 06:29:28.275442: train_loss -0.202 
2025-11-29 06:29:28.275691: val_loss -0.203 
2025-11-29 06:29:28.275885: Pseudo dice [0.6763, 0.0018, 0.6713, 0.0, 0.7124, 0.0, 0.922, 0.8917] 
2025-11-29 06:29:28.276107: Epoch time: 94.28 s 
2025-11-29 06:29:30.269245:  
2025-11-29 06:29:30.269601: Epoch 283 
2025-11-29 06:29:30.269782: Current learning rate: 0.00741 
2025-11-29 06:31:04.832991: train_loss -0.201 
2025-11-29 06:31:04.833402: val_loss -0.2042 
2025-11-29 06:31:04.833549: Pseudo dice [0.0, 0.5625, 0.6298, 0.0, 0.0, 0.5907, 0.8997, 0.8978] 
2025-11-29 06:31:04.833678: Epoch time: 94.57 s 
2025-11-29 06:31:06.776745:  
2025-11-29 06:31:06.777078: Epoch 284 
2025-11-29 06:31:06.777295: Current learning rate: 0.0074 
2025-11-29 06:32:41.237755: train_loss -0.1996 
2025-11-29 06:32:41.238075: val_loss -0.1992 
2025-11-29 06:32:41.238309: Pseudo dice [0.0, 0.5063, 0.0, 0.5205, 0.7516, 0.0077, 0.9058, 0.9131] 
2025-11-29 06:32:41.238756: Epoch time: 94.46 s 
2025-11-29 06:32:43.123664:  
2025-11-29 06:32:43.123913: Epoch 285 
2025-11-29 06:32:43.124130: Current learning rate: 0.00739 
2025-11-29 06:34:17.369847: train_loss -0.2132 
2025-11-29 06:34:17.370126: val_loss -0.2343 
2025-11-29 06:34:17.370352: Pseudo dice [0.1003, 0.6341, 0.7461, 0.0, 0.0, 0.4595, 0.9292, 0.9289] 
2025-11-29 06:34:17.370521: Epoch time: 94.25 s 
2025-11-29 06:34:19.223748:  
2025-11-29 06:34:19.224212: Epoch 286 
2025-11-29 06:34:19.224416: Current learning rate: 0.00738 
2025-11-29 06:35:52.996414: train_loss -0.2052 
2025-11-29 06:35:52.996694: val_loss -0.2121 
2025-11-29 06:35:52.996969: Pseudo dice [0.004, 0.5985, 0.0104, 0.7133, 0.6955, 0.0, 0.8959, 0.914] 
2025-11-29 06:35:52.997094: Epoch time: 93.77 s 
2025-11-29 06:35:54.863347:  
2025-11-29 06:35:54.863646: Epoch 287 
2025-11-29 06:35:54.863815: Current learning rate: 0.00738 
2025-11-29 06:37:29.005927: train_loss -0.203 
2025-11-29 06:37:29.006205: val_loss -0.211 
2025-11-29 06:37:29.006406: Pseudo dice [0.056, 0.601, 0.6188, 0.0, 0.7281, 0.204, 0.8919, 0.9056] 
2025-11-29 06:37:29.006531: Epoch time: 94.14 s 
2025-11-29 06:37:30.902246:  
2025-11-29 06:37:30.902443: Epoch 288 
2025-11-29 06:37:30.902683: Current learning rate: 0.00737 
2025-11-29 06:39:04.852679: train_loss -0.2068 
2025-11-29 06:39:04.852877: val_loss -0.2148 
2025-11-29 06:39:04.853011: Pseudo dice [0.0, 0.6281, 0.0, 0.5369, 0.0, 0.6447, 0.909, 0.9033] 
2025-11-29 06:39:04.853096: Epoch time: 93.95 s 
2025-11-29 06:39:06.690989:  
2025-11-29 06:39:06.691301: Epoch 289 
2025-11-29 06:39:06.691494: Current learning rate: 0.00736 
2025-11-29 06:40:40.737999: train_loss -0.2129 
2025-11-29 06:40:40.738385: val_loss -0.2106 
2025-11-29 06:40:40.738561: Pseudo dice [0.6698, 0.0004, 0.7277, 0.0, 0.5298, 0.0005, 0.8901, 0.902] 
2025-11-29 06:40:40.738656: Epoch time: 94.05 s 
2025-11-29 06:40:42.662824:  
2025-11-29 06:40:42.663107: Epoch 290 
2025-11-29 06:40:42.663285: Current learning rate: 0.00735 
2025-11-29 06:42:16.935122: train_loss -0.2007 
2025-11-29 06:42:16.935391: val_loss -0.209 
2025-11-29 06:42:16.935603: Pseudo dice [0.0, 0.6852, 0.0, 0.7122, 0.4129, 0.0461, 0.8877, 0.9087] 
2025-11-29 06:42:16.935735: Epoch time: 94.27 s 
2025-11-29 06:42:18.739543:  
2025-11-29 06:42:18.739831: Epoch 291 
2025-11-29 06:42:18.739989: Current learning rate: 0.00734 
2025-11-29 06:43:52.696087: train_loss -0.1988 
2025-11-29 06:43:52.696385: val_loss -0.2433 
2025-11-29 06:43:52.696582: Pseudo dice [0.0, 0.6995, 0.4041, 0.0149, 0.6074, 0.1309, 0.92, 0.9199] 
2025-11-29 06:43:52.696702: Epoch time: 93.96 s 
2025-11-29 06:43:55.414494:  
2025-11-29 06:43:55.414832: Epoch 292 
2025-11-29 06:43:55.415012: Current learning rate: 0.00733 
2025-11-29 06:45:29.877928: train_loss -0.2079 
2025-11-29 06:45:29.878256: val_loss -0.2172 
2025-11-29 06:45:29.878546: Pseudo dice [0.6774, 0.004, 0.7306, 0.0, 0.0895, 0.5216, 0.8078, 0.8748] 
2025-11-29 06:45:29.878676: Epoch time: 94.46 s 
2025-11-29 06:45:31.806797:  
2025-11-29 06:45:31.807168: Epoch 293 
2025-11-29 06:45:31.807346: Current learning rate: 0.00732 
2025-11-29 06:47:06.385827: train_loss -0.2059 
2025-11-29 06:47:06.386066: val_loss -0.2211 
2025-11-29 06:47:06.386344: Pseudo dice [0.0, 0.6327, 0.0, 0.5207, 0.7077, 0.0627, 0.9027, 0.8879] 
2025-11-29 06:47:06.386495: Epoch time: 94.58 s 
2025-11-29 06:47:08.340909:  
2025-11-29 06:47:08.341265: Epoch 294 
2025-11-29 06:47:08.341433: Current learning rate: 0.00731 
2025-11-29 06:48:42.124369: train_loss -0.2063 
2025-11-29 06:48:42.124806: val_loss -0.2127 
2025-11-29 06:48:42.125009: Pseudo dice [0.0002, 0.6582, 0.0015, 0.62, 0.587, 0.143, 0.9232, 0.9144] 
2025-11-29 06:48:42.125159: Epoch time: 93.78 s 
2025-11-29 06:48:44.010220:  
2025-11-29 06:48:44.010588: Epoch 295 
2025-11-29 06:48:44.010752: Current learning rate: 0.0073 
2025-11-29 06:50:18.145099: train_loss -0.1978 
2025-11-29 06:50:18.145460: val_loss -0.2044 
2025-11-29 06:50:18.145779: Pseudo dice [0.6362, 0.0004, 0.6331, 0.3229, 0.7238, 0.0092, 0.9344, 0.8991] 
2025-11-29 06:50:18.145918: Epoch time: 94.14 s 
2025-11-29 06:50:20.110999:  
2025-11-29 06:50:20.111371: Epoch 296 
2025-11-29 06:50:20.111572: Current learning rate: 0.00729 
2025-11-29 06:51:54.176330: train_loss -0.2057 
2025-11-29 06:51:54.176593: val_loss -0.2335 
2025-11-29 06:51:54.176770: Pseudo dice [0.0001, 0.6275, 0.0, 0.647, 0.0, 0.7939, 0.8751, 0.9068] 
2025-11-29 06:51:54.176883: Epoch time: 94.07 s 
2025-11-29 06:51:56.042412:  
2025-11-29 06:51:56.042628: Epoch 297 
2025-11-29 06:51:56.042780: Current learning rate: 0.00728 
2025-11-29 06:53:30.361480: train_loss -0.2055 
2025-11-29 06:53:30.361747: val_loss -0.1997 
2025-11-29 06:53:30.361956: Pseudo dice [0.0475, 0.7408, 0.5393, 0.0, 0.0, 0.6736, 0.8867, 0.9264] 
2025-11-29 06:53:30.362188: Epoch time: 94.32 s 
2025-11-29 06:53:32.316902:  
2025-11-29 06:53:32.317276: Epoch 298 
2025-11-29 06:53:32.317471: Current learning rate: 0.00727 
2025-11-29 06:55:06.951045: train_loss -0.1986 
2025-11-29 06:55:06.951349: val_loss -0.2133 
2025-11-29 06:55:06.951656: Pseudo dice [0.6743, 0.0003, 0.5688, 0.0, 0.5435, 0.0, 0.9132, 0.9133] 
2025-11-29 06:55:06.951912: Epoch time: 94.64 s 
2025-11-29 06:55:08.967023:  
2025-11-29 06:55:08.967409: Epoch 299 
2025-11-29 06:55:08.967577: Current learning rate: 0.00726 
2025-11-29 06:56:43.105832: train_loss -0.2178 
2025-11-29 06:56:43.106162: val_loss -0.2049 
2025-11-29 06:56:43.106407: Pseudo dice [0.0912, 0.5976, 0.0, 0.5622, 0.0, 0.4159, 0.925, 0.9204] 
2025-11-29 06:56:43.106552: Epoch time: 94.14 s 
2025-11-29 06:56:45.854985:  
2025-11-29 06:56:45.855223: Epoch 300 
2025-11-29 06:56:45.855424: Current learning rate: 0.00725 
2025-11-29 06:58:19.651887: train_loss -0.2171 
2025-11-29 06:58:19.652170: val_loss -0.2219 
2025-11-29 06:58:19.652695: Pseudo dice [0.0, 0.6305, 0.0004, 0.6109, 0.0, 0.712, 0.9248, 0.906] 
2025-11-29 06:58:19.652843: Epoch time: 93.8 s 
2025-11-29 06:58:21.581221:  
2025-11-29 06:58:21.581484: Epoch 301 
2025-11-29 06:58:21.581650: Current learning rate: 0.00724 
2025-11-29 06:59:55.310491: train_loss -0.212 
2025-11-29 06:59:55.310781: val_loss -0.2154 
2025-11-29 06:59:55.311012: Pseudo dice [0.0, 0.6087, 0.8059, 0.0008, 0.596, 0.07, 0.9182, 0.9127] 
2025-11-29 06:59:55.311205: Epoch time: 93.73 s 
2025-11-29 06:59:57.211494:  
2025-11-29 06:59:57.211758: Epoch 302 
2025-11-29 06:59:57.211920: Current learning rate: 0.00724 
2025-11-29 07:01:31.174883: train_loss -0.2077 
2025-11-29 07:01:31.175157: val_loss -0.2019 
2025-11-29 07:01:31.175421: Pseudo dice [0.5629, 0.0004, 0.0001, 0.6571, 0.505, 0.0, 0.8776, 0.8885] 
2025-11-29 07:01:31.175549: Epoch time: 93.96 s 
2025-11-29 07:01:33.100789:  
2025-11-29 07:01:33.101102: Epoch 303 
2025-11-29 07:01:33.101276: Current learning rate: 0.00723 
2025-11-29 07:03:06.773432: train_loss -0.2023 
2025-11-29 07:03:06.773688: val_loss -0.2302 
2025-11-29 07:03:06.773887: Pseudo dice [0.0001, 0.6918, 0.6549, 0.0, 0.4479, 0.0, 0.9068, 0.9321] 
2025-11-29 07:03:06.774105: Epoch time: 93.67 s 
2025-11-29 07:03:08.664867:  
2025-11-29 07:03:08.665273: Epoch 304 
2025-11-29 07:03:08.665480: Current learning rate: 0.00722 
2025-11-29 07:04:42.843782: train_loss -0.2007 
2025-11-29 07:04:42.844103: val_loss -0.2137 
2025-11-29 07:04:42.844342: Pseudo dice [0.0, 0.5976, 0.0987, 0.6482, 0.0, 0.7802, 0.9075, 0.9107] 
2025-11-29 07:04:42.844548: Epoch time: 94.18 s 
2025-11-29 07:04:44.683063:  
2025-11-29 07:04:44.683356: Epoch 305 
2025-11-29 07:04:44.683511: Current learning rate: 0.00721 
2025-11-29 07:06:19.697068: train_loss -0.2014 
2025-11-29 07:06:19.697282: val_loss -0.2314 
2025-11-29 07:06:19.697433: Pseudo dice [0.0082, 0.6249, 0.0003, 0.7403, 0.0, 0.5298, 0.9225, 0.9246] 
2025-11-29 07:06:19.697529: Epoch time: 95.02 s 
2025-11-29 07:06:21.727290:  
2025-11-29 07:06:21.727590: Epoch 306 
2025-11-29 07:06:21.727787: Current learning rate: 0.0072 
2025-11-29 07:07:56.521712: train_loss -0.2048 
2025-11-29 07:07:56.522014: val_loss -0.2242 
2025-11-29 07:07:56.522369: Pseudo dice [0.0006, 0.6999, 0.0, 0.7234, 0.5105, 0.007, 0.9175, 0.9079] 
2025-11-29 07:07:56.522564: Epoch time: 94.8 s 
2025-11-29 07:07:58.541621:  
2025-11-29 07:07:58.541925: Epoch 307 
2025-11-29 07:07:58.542099: Current learning rate: 0.00719 
2025-11-29 07:09:33.944910: train_loss -0.2043 
2025-11-29 07:09:33.945194: val_loss -0.2193 
2025-11-29 07:09:33.945421: Pseudo dice [0.0, 0.6293, 0.6755, 0.0003, 0.0, 0.4364, 0.9226, 0.917] 
2025-11-29 07:09:33.945584: Epoch time: 95.4 s 
2025-11-29 07:09:36.048202:  
2025-11-29 07:09:36.048437: Epoch 308 
2025-11-29 07:09:36.048605: Current learning rate: 0.00718 
2025-11-29 07:11:10.441547: train_loss -0.2016 
2025-11-29 07:11:10.441803: val_loss -0.2278 
2025-11-29 07:11:10.441997: Pseudo dice [0.696, 0.1033, 0.001, 0.6027, 0.7199, 0.0, 0.905, 0.878] 
2025-11-29 07:11:10.442116: Epoch time: 94.39 s 
2025-11-29 07:11:12.362929:  
2025-11-29 07:11:12.363286: Epoch 309 
2025-11-29 07:11:12.363482: Current learning rate: 0.00717 
2025-11-29 07:12:47.277256: train_loss -0.2035 
2025-11-29 07:12:47.277567: val_loss -0.2253 
2025-11-29 07:12:47.277799: Pseudo dice [0.6313, 0.0015, 0.6327, 0.0019, 0.6592, 0.0003, 0.9258, 0.9359] 
2025-11-29 07:12:47.277938: Epoch time: 94.92 s 
2025-11-29 07:12:49.309298:  
2025-11-29 07:12:49.309686: Epoch 310 
2025-11-29 07:12:49.309860: Current learning rate: 0.00716 
2025-11-29 07:14:24.358732: train_loss -0.1962 
2025-11-29 07:14:24.358981: val_loss -0.2075 
2025-11-29 07:14:24.359210: Pseudo dice [0.6256, 0.0, 0.5404, 0.0, 0.0, 0.6635, 0.8859, 0.8837] 
2025-11-29 07:14:24.359370: Epoch time: 95.05 s 
2025-11-29 07:14:26.288029:  
2025-11-29 07:14:26.288350: Epoch 311 
2025-11-29 07:14:26.288567: Current learning rate: 0.00715 
2025-11-29 07:16:00.740188: train_loss -0.1973 
2025-11-29 07:16:00.740432: val_loss -0.2238 
2025-11-29 07:16:00.740609: Pseudo dice [0.6773, 0.0001, 0.1024, 0.5495, 0.5764, 0.0002, 0.8987, 0.9152] 
2025-11-29 07:16:00.740793: Epoch time: 94.45 s 
2025-11-29 07:16:02.696653:  
2025-11-29 07:16:02.696983: Epoch 312 
2025-11-29 07:16:02.697186: Current learning rate: 0.00714 
2025-11-29 07:17:37.105923: train_loss -0.2037 
2025-11-29 07:17:37.106353: val_loss -0.2191 
2025-11-29 07:17:37.106544: Pseudo dice [0.0, 0.6773, 0.0, 0.6404, 0.5071, 0.0001, 0.9042, 0.9099] 
2025-11-29 07:17:37.106646: Epoch time: 94.41 s 
2025-11-29 07:17:39.130435:  
2025-11-29 07:17:39.130777: Epoch 313 
2025-11-29 07:17:39.130980: Current learning rate: 0.00713 
2025-11-29 07:19:14.868660: train_loss -0.1988 
2025-11-29 07:19:14.868929: val_loss -0.2494 
2025-11-29 07:19:14.869167: Pseudo dice [0.5903, 0.1152, 0.0088, 0.7428, 0.0, 0.7259, 0.9276, 0.9323] 
2025-11-29 07:19:14.869447: Epoch time: 95.74 s 
2025-11-29 07:19:16.887229:  
2025-11-29 07:19:16.887531: Epoch 314 
2025-11-29 07:19:16.887687: Current learning rate: 0.00712 
2025-11-29 07:20:51.820673: train_loss -0.1968 
2025-11-29 07:20:51.821117: val_loss -0.1841 
2025-11-29 07:20:51.821390: Pseudo dice [0.6287, 0.0017, 0.5055, 0.0, 0.5422, 0.0, 0.8655, 0.9045] 
2025-11-29 07:20:51.821547: Epoch time: 94.93 s 
2025-11-29 07:20:53.777099:  
2025-11-29 07:20:53.777495: Epoch 315 
2025-11-29 07:20:53.777678: Current learning rate: 0.00711 
2025-11-29 07:22:28.254694: train_loss -0.2029 
2025-11-29 07:22:28.254945: val_loss -0.2065 
2025-11-29 07:22:28.255270: Pseudo dice [0.6755, 0.0, 0.3498, 0.6407, 0.0, 0.7155, 0.9192, 0.9252] 
2025-11-29 07:22:28.255432: Epoch time: 94.48 s 
2025-11-29 07:22:30.268205:  
2025-11-29 07:22:30.268570: Epoch 316 
2025-11-29 07:22:30.268737: Current learning rate: 0.0071 
2025-11-29 07:24:04.179765: train_loss -0.2125 
2025-11-29 07:24:04.180047: val_loss -0.2213 
2025-11-29 07:24:04.180323: Pseudo dice [0.0, 0.7679, 0.4597, 0.3378, 0.0, 0.6742, 0.9289, 0.9179] 
2025-11-29 07:24:04.180551: Epoch time: 93.91 s 
2025-11-29 07:24:06.146607:  
2025-11-29 07:24:06.146937: Epoch 317 
2025-11-29 07:24:06.147103: Current learning rate: 0.0071 
2025-11-29 07:25:40.851434: train_loss -0.2107 
2025-11-29 07:25:40.851730: val_loss -0.2237 
2025-11-29 07:25:40.851918: Pseudo dice [0.5669, 0.2713, 0.0109, 0.5767, 0.5161, 0.3479, 0.8837, 0.9008] 
2025-11-29 07:25:40.852014: Epoch time: 94.71 s 
2025-11-29 07:25:42.881100:  
2025-11-29 07:25:42.881475: Epoch 318 
2025-11-29 07:25:42.881634: Current learning rate: 0.00709 
2025-11-29 07:27:17.044599: train_loss -0.2102 
2025-11-29 07:27:17.044881: val_loss -0.2207 
2025-11-29 07:27:17.045111: Pseudo dice [0.6029, 0.3753, 0.1556, 0.6632, 0.0, 0.421, 0.8995, 0.918] 
2025-11-29 07:27:17.045304: Epoch time: 94.16 s 
2025-11-29 07:27:18.936782:  
2025-11-29 07:27:18.937129: Epoch 319 
2025-11-29 07:27:18.937337: Current learning rate: 0.00708 
2025-11-29 07:28:53.117739: train_loss -0.2105 
2025-11-29 07:28:53.117991: val_loss -0.224 
2025-11-29 07:28:53.118330: Pseudo dice [0.0, 0.6009, 0.566, 0.0, 0.5808, 0.0003, 0.871, 0.8915] 
2025-11-29 07:28:53.118472: Epoch time: 94.18 s 
2025-11-29 07:28:55.057494:  
2025-11-29 07:28:55.057853: Epoch 320 
2025-11-29 07:28:55.058032: Current learning rate: 0.00707 
2025-11-29 07:30:29.225391: train_loss -0.2066 
2025-11-29 07:30:29.225632: val_loss -0.2162 
2025-11-29 07:30:29.225873: Pseudo dice [0.6302, 0.2947, 0.0097, 0.6642, 0.7237, 0.0, 0.8914, 0.8429] 
2025-11-29 07:30:29.226299: Epoch time: 94.17 s 
2025-11-29 07:30:31.207112:  
2025-11-29 07:30:31.207642: Epoch 321 
2025-11-29 07:30:31.207839: Current learning rate: 0.00706 
2025-11-29 07:32:04.973974: train_loss -0.2072 
2025-11-29 07:32:04.974230: val_loss -0.2134 
2025-11-29 07:32:04.974508: Pseudo dice [0.6141, 0.0301, 0.0013, 0.7056, 0.1648, 0.6794, 0.9129, 0.8956] 
2025-11-29 07:32:04.974659: Epoch time: 93.77 s 
2025-11-29 07:32:04.974766: Yayy! New best EMA pseudo Dice: 0.4827 
2025-11-29 07:32:08.096702:  
2025-11-29 07:32:08.096922: Epoch 322 
2025-11-29 07:32:08.097130: Current learning rate: 0.00705 
2025-11-29 07:33:43.206750: train_loss -0.2065 
2025-11-29 07:33:43.206974: val_loss -0.2147 
2025-11-29 07:33:43.207187: Pseudo dice [0.0009, 0.5658, 0.0049, 0.5675, 0.7152, 0.0, 0.9033, 0.9154] 
2025-11-29 07:33:43.207379: Epoch time: 95.11 s 
2025-11-29 07:33:45.272278:  
2025-11-29 07:33:45.272660: Epoch 323 
2025-11-29 07:33:45.272848: Current learning rate: 0.00704 
2025-11-29 07:35:20.499632: train_loss -0.1931 
2025-11-29 07:35:20.500218: val_loss -0.2174 
2025-11-29 07:35:20.500402: Pseudo dice [0.6625, 0.0152, 0.6248, 0.0, 0.8088, 0.0036, 0.906, 0.8816] 
2025-11-29 07:35:20.500506: Epoch time: 95.23 s 
2025-11-29 07:35:22.753077:  
2025-11-29 07:35:22.753519: Epoch 324 
2025-11-29 07:35:22.753719: Current learning rate: 0.00703 
2025-11-29 07:36:57.335549: train_loss -0.1968 
2025-11-29 07:36:57.335849: val_loss -0.2072 
2025-11-29 07:36:57.336060: Pseudo dice [0.0922, 0.6797, 0.0036, 0.5544, 0.0, 0.7339, 0.9031, 0.9108] 
2025-11-29 07:36:57.336322: Epoch time: 94.58 s 
2025-11-29 07:36:59.259609:  
2025-11-29 07:36:59.259927: Epoch 325 
2025-11-29 07:36:59.260094: Current learning rate: 0.00702 
2025-11-29 07:38:33.476723: train_loss -0.1742 
2025-11-29 07:38:33.476939: val_loss -0.205 
2025-11-29 07:38:33.477087: Pseudo dice [0.7246, 0.001, 0.604, 0.0, 0.3532, 0.4178, 0.874, 0.9115] 
2025-11-29 07:38:33.477271: Epoch time: 94.22 s 
2025-11-29 07:38:35.463532:  
2025-11-29 07:38:35.463843: Epoch 326 
2025-11-29 07:38:35.464015: Current learning rate: 0.00701 
2025-11-29 07:40:10.333242: train_loss -0.1932 
2025-11-29 07:40:10.333625: val_loss -0.2212 
2025-11-29 07:40:10.333828: Pseudo dice [0.0, 0.6892, 0.0, 0.6004, 0.0, 0.6309, 0.8876, 0.8923] 
2025-11-29 07:40:10.333952: Epoch time: 94.87 s 
2025-11-29 07:40:12.239165:  
2025-11-29 07:40:12.239447: Epoch 327 
2025-11-29 07:40:12.239620: Current learning rate: 0.007 
2025-11-29 07:41:45.846597: train_loss -0.2027 
2025-11-29 07:41:45.846848: val_loss -0.1953 
2025-11-29 07:41:45.847026: Pseudo dice [0.633, 0.3343, 0.0, 0.6167, 0.0, 0.5338, 0.9095, 0.8983] 
2025-11-29 07:41:45.847174: Epoch time: 93.61 s 
2025-11-29 07:41:47.797389:  
2025-11-29 07:41:47.797734: Epoch 328 
2025-11-29 07:41:47.797913: Current learning rate: 0.00699 
2025-11-29 07:43:22.183829: train_loss -0.2133 
2025-11-29 07:43:22.184185: val_loss -0.2523 
2025-11-29 07:43:22.184452: Pseudo dice [0.6521, 0.0078, 0.7025, 0.0, 0.6013, 0.2107, 0.9298, 0.9471] 
2025-11-29 07:43:22.184583: Epoch time: 94.39 s 
2025-11-29 07:43:22.184655: Yayy! New best EMA pseudo Dice: 0.4836 
2025-11-29 07:43:25.171203:  
2025-11-29 07:43:25.171497: Epoch 329 
2025-11-29 07:43:25.171655: Current learning rate: 0.00698 
2025-11-29 07:44:59.296067: train_loss -0.2181 
2025-11-29 07:44:59.296384: val_loss -0.2247 
2025-11-29 07:44:59.296660: Pseudo dice [0.0027, 0.674, 0.0, 0.5312, 0.5805, 0.4754, 0.8856, 0.9034] 
2025-11-29 07:44:59.296845: Epoch time: 94.13 s 
2025-11-29 07:44:59.296982: Yayy! New best EMA pseudo Dice: 0.4859 
2025-11-29 07:45:02.135051:  
2025-11-29 07:45:02.135275: Epoch 330 
2025-11-29 07:45:02.135483: Current learning rate: 0.00697 
2025-11-29 07:46:37.092088: train_loss -0.2155 
2025-11-29 07:46:37.092408: val_loss -0.243 
2025-11-29 07:46:37.092687: Pseudo dice [0.0, 0.7206, 0.0059, 0.6263, 0.0, 0.4891, 0.9182, 0.9201] 
2025-11-29 07:46:37.092858: Epoch time: 94.96 s 
2025-11-29 07:46:39.099504:  
2025-11-29 07:46:39.099819: Epoch 331 
2025-11-29 07:46:39.099998: Current learning rate: 0.00696 
2025-11-29 07:48:13.325343: train_loss -0.2047 
2025-11-29 07:48:13.325737: val_loss -0.1967 
2025-11-29 07:48:13.325937: Pseudo dice [0.0003, 0.5167, 0.5828, 0.0, 0.0008, 0.1769, 0.9202, 0.9157] 
2025-11-29 07:48:13.326061: Epoch time: 94.23 s 
2025-11-29 07:48:15.393139:  
2025-11-29 07:48:15.393503: Epoch 332 
2025-11-29 07:48:15.393673: Current learning rate: 0.00696 
2025-11-29 07:49:50.665688: train_loss -0.1989 
2025-11-29 07:49:50.665957: val_loss -0.2316 
2025-11-29 07:49:50.666388: Pseudo dice [0.035, 0.6234, 0.0009, 0.6251, 0.6642, 0.0206, 0.9133, 0.92] 
2025-11-29 07:49:50.666552: Epoch time: 95.27 s 
2025-11-29 07:49:52.684660:  
2025-11-29 07:49:52.684992: Epoch 333 
2025-11-29 07:49:52.685190: Current learning rate: 0.00695 
2025-11-29 07:51:27.041560: train_loss -0.2097 
2025-11-29 07:51:27.041917: val_loss -0.2075 
2025-11-29 07:51:27.042104: Pseudo dice [0.6299, 0.0003, 0.0, 0.706, 0.7099, 0.0018, 0.934, 0.9183] 
2025-11-29 07:51:27.042272: Epoch time: 94.36 s 
2025-11-29 07:51:29.811467:  
2025-11-29 07:51:29.811807: Epoch 334 
2025-11-29 07:51:29.812007: Current learning rate: 0.00694 
2025-11-29 07:53:03.779994: train_loss -0.2085 
2025-11-29 07:53:03.780304: val_loss -0.2105 
2025-11-29 07:53:03.780790: Pseudo dice [0.5859, 0.0039, 0.0002, 0.6148, 0.7249, 0.2322, 0.8949, 0.9138] 
2025-11-29 07:53:03.780943: Epoch time: 93.97 s 
2025-11-29 07:53:05.848996:  
2025-11-29 07:53:05.849409: Epoch 335 
2025-11-29 07:53:05.849607: Current learning rate: 0.00693 
2025-11-29 07:54:39.475080: train_loss -0.1969 
2025-11-29 07:54:39.475531: val_loss -0.2339 
2025-11-29 07:54:39.475761: Pseudo dice [0.0, 0.7439, 0.0, 0.6616, 0.0, 0.8378, 0.898, 0.9109] 
2025-11-29 07:54:39.475921: Epoch time: 93.63 s 
2025-11-29 07:54:41.450090:  
2025-11-29 07:54:41.450430: Epoch 336 
2025-11-29 07:54:41.450609: Current learning rate: 0.00692 
2025-11-29 07:56:15.621772: train_loss -0.2095 
2025-11-29 07:56:15.622234: val_loss -0.2015 
2025-11-29 07:56:15.622405: Pseudo dice [0.65, 0.0015, 0.6872, 0.0, 0.7039, 0.0, 0.9142, 0.8873] 
2025-11-29 07:56:15.622549: Epoch time: 94.17 s 
2025-11-29 07:56:17.684363:  
2025-11-29 07:56:17.684650: Epoch 337 
2025-11-29 07:56:17.684896: Current learning rate: 0.00691 
2025-11-29 07:57:52.208434: train_loss -0.1961 
2025-11-29 07:57:52.208950: val_loss -0.1988 
2025-11-29 07:57:52.209211: Pseudo dice [0.5731, 0.0094, 0.5735, 0.0, 0.0, 0.5688, 0.8706, 0.9267] 
2025-11-29 07:57:52.209365: Epoch time: 94.53 s 
2025-11-29 07:57:54.223730:  
2025-11-29 07:57:54.224098: Epoch 338 
2025-11-29 07:57:54.224299: Current learning rate: 0.0069 
2025-11-29 07:59:28.101873: train_loss -0.2112 
2025-11-29 07:59:28.102110: val_loss -0.2169 
2025-11-29 07:59:28.102317: Pseudo dice [0.6166, 0.0013, 0.0302, 0.5649, 0.0, 0.4768, 0.9168, 0.9223] 
2025-11-29 07:59:28.102443: Epoch time: 93.88 s 
2025-11-29 07:59:30.093274:  
2025-11-29 07:59:30.093657: Epoch 339 
2025-11-29 07:59:30.093840: Current learning rate: 0.00689 
2025-11-29 08:01:04.246405: train_loss -0.2199 
2025-11-29 08:01:04.246663: val_loss -0.2179 
2025-11-29 08:01:04.246894: Pseudo dice [0.0, 0.6017, 0.0036, 0.6812, 0.0, 0.4722, 0.9105, 0.9184] 
2025-11-29 08:01:04.247040: Epoch time: 94.15 s 
2025-11-29 08:01:06.219867:  
2025-11-29 08:01:06.220079: Epoch 340 
2025-11-29 08:01:06.220282: Current learning rate: 0.00688 
2025-11-29 08:02:39.815727: train_loss -0.2134 
2025-11-29 08:02:39.816041: val_loss -0.2468 
2025-11-29 08:02:39.816291: Pseudo dice [0.709, 0.0079, 0.6694, 0.0, 0.0, 0.4753, 0.913, 0.9127] 
2025-11-29 08:02:39.816453: Epoch time: 93.6 s 
2025-11-29 08:02:41.771133:  
2025-11-29 08:02:41.771472: Epoch 341 
2025-11-29 08:02:41.771639: Current learning rate: 0.00687 
2025-11-29 08:04:16.387441: train_loss -0.2042 
2025-11-29 08:04:16.387781: val_loss -0.2365 
2025-11-29 08:04:16.388159: Pseudo dice [0.7094, 0.0019, 0.6067, 0.0, 0.6802, 0.0044, 0.8641, 0.9148] 
2025-11-29 08:04:16.388332: Epoch time: 94.62 s 
2025-11-29 08:04:18.341016:  
2025-11-29 08:04:18.341345: Epoch 342 
2025-11-29 08:04:18.341530: Current learning rate: 0.00686 
2025-11-29 08:05:51.993448: train_loss -0.2135 
2025-11-29 08:05:51.993689: val_loss -0.2329 
2025-11-29 08:05:51.993888: Pseudo dice [0.5023, 0.0002, 0.5625, 0.0, 0.0201, 0.863, 0.9282, 0.9039] 
2025-11-29 08:05:51.994034: Epoch time: 93.65 s 
2025-11-29 08:05:54.037301:  
2025-11-29 08:05:54.037635: Epoch 343 
2025-11-29 08:05:54.037812: Current learning rate: 0.00685 
2025-11-29 08:07:28.139302: train_loss -0.2092 
2025-11-29 08:07:28.139585: val_loss -0.2199 
2025-11-29 08:07:28.140077: Pseudo dice [0.7106, 0.0158, 0.6231, 0.0, 0.0, 0.7343, 0.9019, 0.8994] 
2025-11-29 08:07:28.140289: Epoch time: 94.1 s 
2025-11-29 08:07:30.140005:  
2025-11-29 08:07:30.140410: Epoch 344 
2025-11-29 08:07:30.140612: Current learning rate: 0.00684 
2025-11-29 08:09:04.974869: train_loss -0.2022 
2025-11-29 08:09:04.975118: val_loss -0.2147 
2025-11-29 08:09:04.975345: Pseudo dice [0.6056, 0.0059, 0.6582, 0.0, 0.0, 0.7591, 0.8974, 0.8983] 
2025-11-29 08:09:04.975499: Epoch time: 94.84 s 
2025-11-29 08:09:07.110080:  
2025-11-29 08:09:07.110360: Epoch 345 
2025-11-29 08:09:07.110541: Current learning rate: 0.00683 
2025-11-29 08:10:41.633178: train_loss -0.208 
2025-11-29 08:10:41.633410: val_loss -0.2526 
2025-11-29 08:10:41.633650: Pseudo dice [0.6302, 0.0901, 0.6896, 0.0, 0.5963, 0.0043, 0.9266, 0.9071] 
2025-11-29 08:10:41.633779: Epoch time: 94.52 s 
2025-11-29 08:10:43.593213:  
2025-11-29 08:10:43.593514: Epoch 346 
2025-11-29 08:10:43.593704: Current learning rate: 0.00682 
2025-11-29 08:12:18.136630: train_loss -0.2103 
2025-11-29 08:12:18.136898: val_loss -0.2505 
2025-11-29 08:12:18.137098: Pseudo dice [0.8081, 0.0005, 0.6813, 0.0, 0.764, 0.0003, 0.9044, 0.898] 
2025-11-29 08:12:18.137281: Epoch time: 94.54 s 
2025-11-29 08:12:20.183854:  
2025-11-29 08:12:20.184285: Epoch 347 
2025-11-29 08:12:20.184460: Current learning rate: 0.00681 
2025-11-29 08:13:54.167395: train_loss -0.2072 
2025-11-29 08:13:54.167601: val_loss -0.2272 
2025-11-29 08:13:54.167747: Pseudo dice [0.0002, 0.6342, 0.0155, 0.6822, 0.651, 0.2079, 0.9298, 0.9104] 
2025-11-29 08:13:54.167877: Epoch time: 93.99 s 
2025-11-29 08:13:56.214887:  
2025-11-29 08:13:56.215214: Epoch 348 
2025-11-29 08:13:56.215388: Current learning rate: 0.0068 
2025-11-29 08:15:29.647869: train_loss -0.214 
2025-11-29 08:15:29.648233: val_loss -0.2106 
2025-11-29 08:15:29.648652: Pseudo dice [0.0, 0.7274, 0.0001, 0.6044, 0.0, 0.8414, 0.9056, 0.8815] 
2025-11-29 08:15:29.648944: Epoch time: 93.43 s 
2025-11-29 08:15:31.890453:  
2025-11-29 08:15:31.890792: Epoch 349 
2025-11-29 08:15:31.890952: Current learning rate: 0.0068 
2025-11-29 08:17:05.983315: train_loss -0.2133 
2025-11-29 08:17:05.983542: val_loss -0.22 
2025-11-29 08:17:05.983785: Pseudo dice [0.0038, 0.6399, 0.6692, 0.0, 0.5866, 0.0552, 0.9039, 0.9303] 
2025-11-29 08:17:05.984103: Epoch time: 94.09 s 
2025-11-29 08:17:08.690066:  
2025-11-29 08:17:08.690362: Epoch 350 
2025-11-29 08:17:08.690542: Current learning rate: 0.00679 
2025-11-29 08:18:42.971046: train_loss -0.2053 
2025-11-29 08:18:42.971415: val_loss -0.2153 
2025-11-29 08:18:42.971558: Pseudo dice [0.5587, 0.266, 0.5706, 0.0, 0.7021, 0.0441, 0.9187, 0.8903] 
2025-11-29 08:18:42.971649: Epoch time: 94.28 s 
2025-11-29 08:18:44.934803:  
2025-11-29 08:18:44.935157: Epoch 351 
2025-11-29 08:18:44.935342: Current learning rate: 0.00678 
2025-11-29 08:20:19.102094: train_loss -0.2074 
2025-11-29 08:20:19.102462: val_loss -0.2184 
2025-11-29 08:20:19.102725: Pseudo dice [0.0363, 0.6854, 0.0, 0.7552, 0.8334, 0.1187, 0.9239, 0.9035] 
2025-11-29 08:20:19.102868: Epoch time: 94.17 s 
2025-11-29 08:20:19.102991: Yayy! New best EMA pseudo Dice: 0.4865 
2025-11-29 08:20:22.123617:  
2025-11-29 08:20:22.123914: Epoch 352 
2025-11-29 08:20:22.124074: Current learning rate: 0.00677 
2025-11-29 08:21:55.819355: train_loss -0.2052 
2025-11-29 08:21:55.819661: val_loss -0.1879 
2025-11-29 08:21:55.819911: Pseudo dice [0.6366, 0.0346, 0.0, 0.613, 0.0, 0.5825, 0.8806, 0.8732] 
2025-11-29 08:21:55.820028: Epoch time: 93.7 s 
2025-11-29 08:21:57.819021:  
2025-11-29 08:21:57.819429: Epoch 353 
2025-11-29 08:21:57.819613: Current learning rate: 0.00676 
2025-11-29 08:23:31.059645: train_loss -0.1974 
2025-11-29 08:23:31.060074: val_loss -0.2234 
2025-11-29 08:23:31.060360: Pseudo dice [0.0001, 0.6481, 0.0018, 0.6419, 0.6204, 0.0084, 0.9301, 0.9143] 
2025-11-29 08:23:31.060520: Epoch time: 93.24 s 
2025-11-29 08:23:33.061877:  
2025-11-29 08:23:33.062155: Epoch 354 
2025-11-29 08:23:33.062333: Current learning rate: 0.00675 
2025-11-29 08:25:06.384699: train_loss -0.1975 
2025-11-29 08:25:06.385083: val_loss -0.2253 
2025-11-29 08:25:06.385350: Pseudo dice [0.4882, 0.4141, 0.0, 0.6511, 0.0, 0.4585, 0.8926, 0.8915] 
2025-11-29 08:25:06.385511: Epoch time: 93.32 s 
2025-11-29 08:25:09.200668:  
2025-11-29 08:25:09.201091: Epoch 355 
2025-11-29 08:25:09.201285: Current learning rate: 0.00674 
2025-11-29 08:26:42.684960: train_loss -0.2128 
2025-11-29 08:26:42.685389: val_loss -0.2148 
2025-11-29 08:26:42.685663: Pseudo dice [0.0, 0.6295, 0.6406, 0.0, 0.0, 0.6769, 0.9203, 0.9198] 
2025-11-29 08:26:42.685828: Epoch time: 93.49 s 
2025-11-29 08:26:44.704304:  
2025-11-29 08:26:44.704557: Epoch 356 
2025-11-29 08:26:44.704737: Current learning rate: 0.00673 
2025-11-29 08:28:18.210971: train_loss -0.201 
2025-11-29 08:28:18.211251: val_loss -0.2189 
2025-11-29 08:28:18.211447: Pseudo dice [0.586, 0.0132, 0.6836, 0.0, 0.5799, 0.1385, 0.9249, 0.9058] 
2025-11-29 08:28:18.211617: Epoch time: 93.51 s 
2025-11-29 08:28:20.155103:  
2025-11-29 08:28:20.155374: Epoch 357 
2025-11-29 08:28:20.155544: Current learning rate: 0.00672 
2025-11-29 08:29:53.851616: train_loss -0.2085 
2025-11-29 08:29:53.851870: val_loss -0.2204 
2025-11-29 08:29:53.852078: Pseudo dice [0.0, 0.6501, 0.0001, 0.6484, 0.7073, 0.0, 0.9118, 0.9094] 
2025-11-29 08:29:53.852252: Epoch time: 93.7 s 
2025-11-29 08:29:55.832032:  
2025-11-29 08:29:55.832233: Epoch 358 
2025-11-29 08:29:55.832631: Current learning rate: 0.00671 
2025-11-29 08:31:29.766782: train_loss -0.218 
2025-11-29 08:31:29.767194: val_loss -0.2423 
2025-11-29 08:31:29.767456: Pseudo dice [0.5321, 0.0004, 0.5844, 0.0, 0.314, 0.0172, 0.9048, 0.9015] 
2025-11-29 08:31:29.767632: Epoch time: 93.94 s 
2025-11-29 08:31:31.730166:  
2025-11-29 08:31:31.730497: Epoch 359 
2025-11-29 08:31:31.730661: Current learning rate: 0.0067 
2025-11-29 08:33:05.417411: train_loss -0.2021 
2025-11-29 08:33:05.417726: val_loss -0.2028 
2025-11-29 08:33:05.417954: Pseudo dice [0.6736, 0.0018, 0.5942, 0.0, 0.615, 0.0389, 0.8927, 0.9048] 
2025-11-29 08:33:05.418165: Epoch time: 93.69 s 
2025-11-29 08:33:07.347687:  
2025-11-29 08:33:07.348027: Epoch 360 
2025-11-29 08:33:07.348213: Current learning rate: 0.00669 
2025-11-29 08:34:40.447295: train_loss -0.2095 
2025-11-29 08:34:40.447627: val_loss -0.2305 
2025-11-29 08:34:40.447875: Pseudo dice [0.6398, 0.0085, 0.0, 0.6286, 0.5833, 0.0115, 0.9233, 0.9152] 
2025-11-29 08:34:40.448050: Epoch time: 93.1 s 
2025-11-29 08:34:42.371108:  
2025-11-29 08:34:42.371380: Epoch 361 
2025-11-29 08:34:42.371592: Current learning rate: 0.00668 
2025-11-29 08:36:16.428362: train_loss -0.2075 
2025-11-29 08:36:16.428642: val_loss -0.2088 
2025-11-29 08:36:16.428854: Pseudo dice [0.0, 0.68, 0.0003, 0.5136, 0.0, 0.7233, 0.8996, 0.8992] 
2025-11-29 08:36:16.429028: Epoch time: 94.06 s 
2025-11-29 08:36:18.382899:  
2025-11-29 08:36:18.383101: Epoch 362 
2025-11-29 08:36:18.383285: Current learning rate: 0.00667 
2025-11-29 08:37:52.368266: train_loss -0.1953 
2025-11-29 08:37:52.368670: val_loss -0.2195 
2025-11-29 08:37:52.368879: Pseudo dice [0.0006, 0.6673, 0.5327, 0.0, 0.0, 0.6775, 0.9034, 0.9063] 
2025-11-29 08:37:52.368982: Epoch time: 93.99 s 
2025-11-29 08:37:54.293603:  
2025-11-29 08:37:54.293923: Epoch 363 
2025-11-29 08:37:54.294068: Current learning rate: 0.00666 
2025-11-29 08:39:29.359953: train_loss -0.198 
2025-11-29 08:39:29.360353: val_loss -0.2283 
2025-11-29 08:39:29.360669: Pseudo dice [0.6055, 0.1505, 0.7333, 0.0, 0.5625, 0.051, 0.9028, 0.9258] 
2025-11-29 08:39:29.360970: Epoch time: 95.07 s 
2025-11-29 08:39:31.481409:  
2025-11-29 08:39:31.481745: Epoch 364 
2025-11-29 08:39:31.481941: Current learning rate: 0.00665 
2025-11-29 08:41:06.046232: train_loss -0.2088 
2025-11-29 08:41:06.046524: val_loss -0.229 
2025-11-29 08:41:06.046862: Pseudo dice [0.5333, 0.2432, 0.6432, 0.0, 0.31, 0.6345, 0.9145, 0.8844] 
2025-11-29 08:41:06.047200: Epoch time: 94.57 s 
2025-11-29 08:41:08.084933:  
2025-11-29 08:41:08.085277: Epoch 365 
2025-11-29 08:41:08.085443: Current learning rate: 0.00665 
2025-11-29 08:42:42.464303: train_loss -0.2057 
2025-11-29 08:42:42.464584: val_loss -0.2265 
2025-11-29 08:42:42.464817: Pseudo dice [0.0497, 0.5453, 0.0, 0.7294, 0.73, 0.0172, 0.9146, 0.9107] 
2025-11-29 08:42:42.464962: Epoch time: 94.38 s 
2025-11-29 08:42:44.459891:  
2025-11-29 08:42:44.460228: Epoch 366 
2025-11-29 08:42:44.460401: Current learning rate: 0.00664 
2025-11-29 08:44:18.926399: train_loss -0.2112 
2025-11-29 08:44:18.926612: val_loss -0.2221 
2025-11-29 08:44:18.926749: Pseudo dice [0.7321, 0.0378, 0.0, 0.5201, 0.0, 0.5275, 0.8942, 0.9072] 
2025-11-29 08:44:18.926845: Epoch time: 94.47 s 
2025-11-29 08:44:20.886267:  
2025-11-29 08:44:20.886614: Epoch 367 
2025-11-29 08:44:20.886785: Current learning rate: 0.00663 
2025-11-29 08:45:54.806699: train_loss -0.2045 
2025-11-29 08:45:54.807052: val_loss -0.2312 
2025-11-29 08:45:54.807314: Pseudo dice [0.606, 0.0087, 0.0017, 0.5728, 0.7013, 0.0725, 0.9168, 0.9015] 
2025-11-29 08:45:54.807480: Epoch time: 93.92 s 
2025-11-29 08:45:56.795005:  
2025-11-29 08:45:56.795341: Epoch 368 
2025-11-29 08:45:56.795537: Current learning rate: 0.00662 
2025-11-29 08:47:31.013899: train_loss -0.2036 
2025-11-29 08:47:31.014197: val_loss -0.1898 
2025-11-29 08:47:31.014457: Pseudo dice [0.0, 0.6285, 0.0001, 0.6775, 0.6834, 0.0066, 0.87, 0.8493] 
2025-11-29 08:47:31.014611: Epoch time: 94.22 s 
2025-11-29 08:47:33.024215:  
2025-11-29 08:47:33.024451: Epoch 369 
2025-11-29 08:47:33.024612: Current learning rate: 0.00661 
2025-11-29 08:49:07.251662: train_loss -0.2057 
2025-11-29 08:49:07.251941: val_loss -0.2237 
2025-11-29 08:49:07.252201: Pseudo dice [0.0, 0.7657, 0.0002, 0.6701, 0.6968, 0.0058, 0.9104, 0.9168] 
2025-11-29 08:49:07.252374: Epoch time: 94.23 s 
2025-11-29 08:49:09.193717:  
2025-11-29 08:49:09.194011: Epoch 370 
2025-11-29 08:49:09.194200: Current learning rate: 0.0066 
2025-11-29 08:50:43.357493: train_loss -0.2005 
2025-11-29 08:50:43.357780: val_loss -0.1971 
2025-11-29 08:50:43.357994: Pseudo dice [0.0396, 0.6087, 0.0101, 0.6013, 0.0, 0.6802, 0.8809, 0.8719] 
2025-11-29 08:50:43.358161: Epoch time: 94.17 s 
2025-11-29 08:50:45.379286:  
2025-11-29 08:50:45.379539: Epoch 371 
2025-11-29 08:50:45.379704: Current learning rate: 0.00659 
2025-11-29 08:52:19.636677: train_loss -0.2141 
2025-11-29 08:52:19.636930: val_loss -0.2115 
2025-11-29 08:52:19.637091: Pseudo dice [0.5186, 0.0016, 0.0058, 0.6732, 0.4994, 0.0, 0.9156, 0.927] 
2025-11-29 08:52:19.637262: Epoch time: 94.26 s 
2025-11-29 08:52:21.660164:  
2025-11-29 08:52:21.660582: Epoch 372 
2025-11-29 08:52:21.660791: Current learning rate: 0.00658 
2025-11-29 08:53:55.824691: train_loss -0.2131 
2025-11-29 08:53:55.824934: val_loss -0.2371 
2025-11-29 08:53:55.825211: Pseudo dice [0.6863, 0.0012, 0.0025, 0.6488, 0.731, 0.0515, 0.8829, 0.9] 
2025-11-29 08:53:55.825370: Epoch time: 94.17 s 
2025-11-29 08:53:57.890693:  
2025-11-29 08:53:57.891043: Epoch 373 
2025-11-29 08:53:57.891235: Current learning rate: 0.00657 
2025-11-29 08:55:33.373487: train_loss -0.1982 
2025-11-29 08:55:33.373892: val_loss -0.2157 
2025-11-29 08:55:33.374119: Pseudo dice [0.6878, 0.0002, 0.5568, 0.0, 0.0, 0.5637, 0.9058, 0.9181] 
2025-11-29 08:55:33.374326: Epoch time: 95.48 s 
2025-11-29 08:55:35.557312:  
2025-11-29 08:55:35.557648: Epoch 374 
2025-11-29 08:55:35.557836: Current learning rate: 0.00656 
2025-11-29 08:57:11.172873: train_loss -0.1991 
2025-11-29 08:57:11.173175: val_loss -0.2161 
2025-11-29 08:57:11.173602: Pseudo dice [0.0, 0.51, 0.7362, 0.0001, 0.0, 0.4361, 0.9211, 0.9166] 
2025-11-29 08:57:11.173786: Epoch time: 95.62 s 
2025-11-29 08:57:14.265117:  
2025-11-29 08:57:14.265532: Epoch 375 
2025-11-29 08:57:14.265679: Current learning rate: 0.00655 
2025-11-29 08:58:50.837853: train_loss -0.2086 
2025-11-29 08:58:50.838197: val_loss -0.2227 
2025-11-29 08:58:50.838418: Pseudo dice [0.0, 0.6435, 0.0012, 0.6468, 0.7868, 0.0, 0.9205, 0.9297] 
2025-11-29 08:58:50.838590: Epoch time: 96.57 s 
2025-11-29 08:58:53.030316:  
2025-11-29 08:58:53.030707: Epoch 376 
2025-11-29 08:58:53.030905: Current learning rate: 0.00654 
2025-11-29 09:00:27.973506: train_loss -0.2101 
2025-11-29 09:00:27.973744: val_loss -0.2207 
2025-11-29 09:00:27.973885: Pseudo dice [0.6508, 0.001, 0.7107, 0.0, 0.0, 0.5987, 0.922, 0.9233] 
2025-11-29 09:00:27.973980: Epoch time: 94.94 s 
2025-11-29 09:00:30.162605:  
2025-11-29 09:00:30.162980: Epoch 377 
2025-11-29 09:00:30.163174: Current learning rate: 0.00653 
2025-11-29 09:02:04.828003: train_loss -0.2197 
2025-11-29 09:02:04.828256: val_loss -0.2162 
2025-11-29 09:02:04.828452: Pseudo dice [0.8063, 0.0052, 0.688, 0.0, 0.0, 0.4039, 0.9307, 0.9144] 
2025-11-29 09:02:04.828582: Epoch time: 94.67 s 
2025-11-29 09:02:06.840044:  
2025-11-29 09:02:06.840288: Epoch 378 
2025-11-29 09:02:06.840471: Current learning rate: 0.00652 
2025-11-29 09:03:41.768264: train_loss -0.213 
2025-11-29 09:03:41.768548: val_loss -0.2209 
2025-11-29 09:03:41.768812: Pseudo dice [0.0, 0.5317, 0.5464, 0.4114, 0.0, 0.4267, 0.8969, 0.9001] 
2025-11-29 09:03:41.768957: Epoch time: 94.93 s 
2025-11-29 09:03:44.071237:  
2025-11-29 09:03:44.071581: Epoch 379 
2025-11-29 09:03:44.071746: Current learning rate: 0.00651 
2025-11-29 09:05:18.654947: train_loss -0.2175 
2025-11-29 09:05:18.655203: val_loss -0.2175 
2025-11-29 09:05:18.655406: Pseudo dice [0.6332, 0.0017, 0.574, 0.0, 0.0, 0.7167, 0.8994, 0.9228] 
2025-11-29 09:05:18.655546: Epoch time: 94.59 s 
2025-11-29 09:05:20.657940:  
2025-11-29 09:05:20.658261: Epoch 380 
2025-11-29 09:05:20.658434: Current learning rate: 0.0065 
2025-11-29 09:06:54.939176: train_loss -0.2102 
2025-11-29 09:06:54.939444: val_loss -0.2147 
2025-11-29 09:06:54.939701: Pseudo dice [0.6037, 0.1472, 0.5997, 0.011, 0.5568, 0.025, 0.9353, 0.8943] 
2025-11-29 09:06:54.939855: Epoch time: 94.28 s 
2025-11-29 09:06:56.883836:  
2025-11-29 09:06:56.884233: Epoch 381 
2025-11-29 09:06:56.884420: Current learning rate: 0.00649 
2025-11-29 09:08:31.789261: train_loss -0.2137 
2025-11-29 09:08:31.789583: val_loss -0.2068 
2025-11-29 09:08:31.789890: Pseudo dice [0.6044, 0.1243, 0.5425, 0.0, 0.0, 0.7411, 0.8912, 0.8997] 
2025-11-29 09:08:31.790053: Epoch time: 94.91 s 
2025-11-29 09:08:34.001176:  
2025-11-29 09:08:34.001535: Epoch 382 
2025-11-29 09:08:34.001761: Current learning rate: 0.00648 
2025-11-29 09:10:08.776584: train_loss -0.2146 
2025-11-29 09:10:08.777004: val_loss -0.218 
2025-11-29 09:10:08.777246: Pseudo dice [0.6593, 0.1784, 0.5743, 0.0, 0.6102, 0.2049, 0.8836, 0.8809] 
2025-11-29 09:10:08.777405: Epoch time: 94.78 s 
2025-11-29 09:10:10.847539:  
2025-11-29 09:10:10.847806: Epoch 383 
2025-11-29 09:10:10.847964: Current learning rate: 0.00648 
2025-11-29 09:11:45.975042: train_loss -0.218 
2025-11-29 09:11:45.975290: val_loss -0.2307 
2025-11-29 09:11:45.975475: Pseudo dice [0.6206, 0.001, 0.6918, 0.0, 0.0, 0.816, 0.9177, 0.9222] 
2025-11-29 09:11:45.975588: Epoch time: 95.13 s 
2025-11-29 09:11:48.081878:  
2025-11-29 09:11:48.082281: Epoch 384 
2025-11-29 09:11:48.082502: Current learning rate: 0.00647 
2025-11-29 09:13:22.481000: train_loss -0.2096 
2025-11-29 09:13:22.481344: val_loss -0.2177 
2025-11-29 09:13:22.481647: Pseudo dice [0.0006, 0.6292, 0.6942, 0.0001, 0.0, 0.7329, 0.9091, 0.8981] 
2025-11-29 09:13:22.481803: Epoch time: 94.4 s 
2025-11-29 09:13:24.531796:  
2025-11-29 09:13:24.532042: Epoch 385 
2025-11-29 09:13:24.532278: Current learning rate: 0.00646 
2025-11-29 09:14:59.458613: train_loss -0.2043 
2025-11-29 09:14:59.458813: val_loss -0.2203 
2025-11-29 09:14:59.458995: Pseudo dice [0.5515, 0.4635, 0.5236, 0.0, 0.6509, 0.0031, 0.8941, 0.8849] 
2025-11-29 09:14:59.459109: Epoch time: 94.93 s 
2025-11-29 09:15:01.649752:  
2025-11-29 09:15:01.650091: Epoch 386 
2025-11-29 09:15:01.650309: Current learning rate: 0.00645 
2025-11-29 09:16:36.592517: train_loss -0.2036 
2025-11-29 09:16:36.592887: val_loss -0.2009 
2025-11-29 09:16:36.593096: Pseudo dice [0.6842, 0.0134, 0.0, 0.584, 0.3764, 0.3734, 0.826, 0.8807] 
2025-11-29 09:16:36.593355: Epoch time: 94.94 s 
2025-11-29 09:16:38.605071:  
2025-11-29 09:16:38.605403: Epoch 387 
2025-11-29 09:16:38.605577: Current learning rate: 0.00644 
2025-11-29 09:18:13.031833: train_loss -0.1972 
2025-11-29 09:18:13.032045: val_loss -0.216 
2025-11-29 09:18:13.032276: Pseudo dice [0.0, 0.5031, 0.0183, 0.4865, 0.0, 0.493, 0.8935, 0.9106] 
2025-11-29 09:18:13.032405: Epoch time: 94.43 s 
2025-11-29 09:18:15.061949:  
2025-11-29 09:18:15.062271: Epoch 388 
2025-11-29 09:18:15.062436: Current learning rate: 0.00643 
2025-11-29 09:19:49.726846: train_loss -0.2037 
2025-11-29 09:19:49.727098: val_loss -0.1915 
2025-11-29 09:19:49.727367: Pseudo dice [0.5404, 0.3962, 0.0, 0.5492, 0.0215, 0.6257, 0.862, 0.8958] 
2025-11-29 09:19:49.727533: Epoch time: 94.67 s 
2025-11-29 09:19:51.962930:  
2025-11-29 09:19:51.963217: Epoch 389 
2025-11-29 09:19:51.963382: Current learning rate: 0.00642 
2025-11-29 09:21:26.744771: train_loss -0.1924 
2025-11-29 09:21:26.745048: val_loss -0.2039 
2025-11-29 09:21:26.745299: Pseudo dice [0.577, 0.0063, 0.6249, 0.0018, 0.7122, 0.0002, 0.9027, 0.8998] 
2025-11-29 09:21:26.745485: Epoch time: 94.78 s 
2025-11-29 09:21:28.812449:  
2025-11-29 09:21:28.812798: Epoch 390 
2025-11-29 09:21:28.812962: Current learning rate: 0.00641 
2025-11-29 09:23:02.498665: train_loss -0.2066 
2025-11-29 09:23:02.498919: val_loss -0.2252 
2025-11-29 09:23:02.499098: Pseudo dice [0.0, 0.6603, 0.0, 0.6894, 0.0, 0.8411, 0.9118, 0.9103] 
2025-11-29 09:23:02.499261: Epoch time: 93.69 s 
2025-11-29 09:23:04.543711:  
2025-11-29 09:23:04.544012: Epoch 391 
2025-11-29 09:23:04.544196: Current learning rate: 0.0064 
2025-11-29 09:24:38.733519: train_loss -0.2183 
2025-11-29 09:24:38.733835: val_loss -0.2483 
2025-11-29 09:24:38.734083: Pseudo dice [0.6379, 0.0005, 0.6852, 0.0, 0.7976, 0.0011, 0.9239, 0.927] 
2025-11-29 09:24:38.734280: Epoch time: 94.19 s 
2025-11-29 09:24:40.877132:  
2025-11-29 09:24:40.877472: Epoch 392 
2025-11-29 09:24:40.877651: Current learning rate: 0.00639 
2025-11-29 09:26:15.531079: train_loss -0.2125 
2025-11-29 09:26:15.531415: val_loss -0.227 
2025-11-29 09:26:15.531687: Pseudo dice [0.6504, 0.0225, 0.5709, 0.0, 0.0, 0.6462, 0.9112, 0.9124] 
2025-11-29 09:26:15.531854: Epoch time: 94.66 s 
2025-11-29 09:26:17.809005:  
2025-11-29 09:26:17.809373: Epoch 393 
2025-11-29 09:26:17.809561: Current learning rate: 0.00638 
2025-11-29 09:27:52.531382: train_loss -0.2084 
2025-11-29 09:27:52.531590: val_loss -0.227 
2025-11-29 09:27:52.531726: Pseudo dice [0.6004, 0.0009, 0.0, 0.7819, 0.0, 0.4556, 0.9268, 0.9279] 
2025-11-29 09:27:52.531815: Epoch time: 94.72 s 
2025-11-29 09:27:54.526793:  
2025-11-29 09:27:54.527156: Epoch 394 
2025-11-29 09:27:54.527339: Current learning rate: 0.00637 
2025-11-29 09:29:28.698841: train_loss -0.2152 
2025-11-29 09:29:28.699119: val_loss -0.2432 
2025-11-29 09:29:28.699383: Pseudo dice [0.5896, 0.1106, 0.0055, 0.6571, 0.0, 0.5131, 0.9302, 0.9107] 
2025-11-29 09:29:28.699583: Epoch time: 94.17 s 
2025-11-29 09:29:30.697571:  
2025-11-29 09:29:30.697855: Epoch 395 
2025-11-29 09:29:30.698030: Current learning rate: 0.00636 
2025-11-29 09:31:05.342277: train_loss -0.2115 
2025-11-29 09:31:05.342541: val_loss -0.2276 
2025-11-29 09:31:05.342852: Pseudo dice [0.0203, 0.4271, 0.0261, 0.5684, 0.9014, 0.0, 0.8845, 0.9102] 
2025-11-29 09:31:05.343011: Epoch time: 94.65 s 
2025-11-29 09:31:08.232972:  
2025-11-29 09:31:08.233372: Epoch 396 
2025-11-29 09:31:08.233579: Current learning rate: 0.00635 
2025-11-29 09:32:43.691474: train_loss -0.1936 
2025-11-29 09:32:43.691776: val_loss -0.223 
2025-11-29 09:32:43.691984: Pseudo dice [0.0041, 0.6822, 0.6521, 0.0, 0.0, 0.7387, 0.8961, 0.9375] 
2025-11-29 09:32:43.692118: Epoch time: 95.46 s 
2025-11-29 09:32:45.701854:  
2025-11-29 09:32:45.702298: Epoch 397 
2025-11-29 09:32:45.702501: Current learning rate: 0.00634 
2025-11-29 09:34:21.004354: train_loss -0.2058 
2025-11-29 09:34:21.004623: val_loss -0.2292 
2025-11-29 09:34:21.004880: Pseudo dice [0.6868, 0.0008, 0.3012, 0.5249, 0.0, 0.6233, 0.9219, 0.8856] 
2025-11-29 09:34:21.005094: Epoch time: 95.3 s 
2025-11-29 09:34:23.154842:  
2025-11-29 09:34:23.155288: Epoch 398 
2025-11-29 09:34:23.155470: Current learning rate: 0.00633 
2025-11-29 09:36:00.308833: train_loss -0.2084 
2025-11-29 09:36:00.309076: val_loss -0.235 
2025-11-29 09:36:00.309271: Pseudo dice [0.0819, 0.6321, 0.0, 0.6027, 0.0, 0.6301, 0.9216, 0.9222] 
2025-11-29 09:36:00.309415: Epoch time: 97.16 s 
2025-11-29 09:36:02.656589:  
2025-11-29 09:36:02.657015: Epoch 399 
2025-11-29 09:36:02.657207: Current learning rate: 0.00632 
2025-11-29 09:37:38.194269: train_loss -0.2126 
2025-11-29 09:37:38.194606: val_loss -0.1869 
2025-11-29 09:37:38.194841: Pseudo dice [0.0, 0.5967, 0.0, 0.5966, 0.0, 0.3977, 0.8999, 0.8811] 
2025-11-29 09:37:38.194984: Epoch time: 95.54 s 
2025-11-29 09:37:41.177672:  
2025-11-29 09:37:41.178036: Epoch 400 
2025-11-29 09:37:41.178226: Current learning rate: 0.00631 
2025-11-29 09:39:17.022145: train_loss -0.2263 
2025-11-29 09:39:17.022510: val_loss -0.2273 
2025-11-29 09:39:17.022785: Pseudo dice [0.5781, 0.0011, 0.0018, 0.6285, 0.3422, 0.611, 0.9084, 0.8888] 
2025-11-29 09:39:17.023041: Epoch time: 95.85 s 
2025-11-29 09:39:19.124045:  
2025-11-29 09:39:19.124402: Epoch 401 
2025-11-29 09:39:19.124613: Current learning rate: 0.0063 
2025-11-29 09:40:54.776279: train_loss -0.2117 
2025-11-29 09:40:54.776532: val_loss -0.2249 
2025-11-29 09:40:54.776819: Pseudo dice [0.6006, 0.0227, 0.5386, 0.0, 0.6154, 0.0, 0.908, 0.9151] 
2025-11-29 09:40:54.777015: Epoch time: 95.65 s 
2025-11-29 09:40:56.875795:  
2025-11-29 09:40:56.876183: Epoch 402 
2025-11-29 09:40:56.876332: Current learning rate: 0.0063 
2025-11-29 09:42:32.415801: train_loss -0.2087 
2025-11-29 09:42:32.416113: val_loss -0.2091 
2025-11-29 09:42:32.416376: Pseudo dice [0.0001, 0.6719, 0.5745, 0.0, 0.0, 0.5826, 0.9049, 0.9165] 
2025-11-29 09:42:32.416542: Epoch time: 95.54 s 
2025-11-29 09:42:34.722754:  
2025-11-29 09:42:34.723106: Epoch 403 
2025-11-29 09:42:34.723317: Current learning rate: 0.00629 
2025-11-29 09:44:10.322932: train_loss -0.2213 
2025-11-29 09:44:10.323305: val_loss -0.2399 
2025-11-29 09:44:10.323553: Pseudo dice [0.0656, 0.6694, 0.044, 0.6425, 0.0, 0.6651, 0.9243, 0.9367] 
2025-11-29 09:44:10.323744: Epoch time: 95.6 s 
2025-11-29 09:44:12.598361:  
2025-11-29 09:44:12.598685: Epoch 404 
2025-11-29 09:44:12.598833: Current learning rate: 0.00628 
2025-11-29 09:45:47.304178: train_loss -0.2051 
2025-11-29 09:45:47.304465: val_loss -0.2097 
2025-11-29 09:45:47.304731: Pseudo dice [0.4537, 0.3288, 0.4459, 0.5708, 0.4762, 0.0, 0.9236, 0.9214] 
2025-11-29 09:45:47.304909: Epoch time: 94.71 s 
2025-11-29 09:45:49.420274:  
2025-11-29 09:45:49.420587: Epoch 405 
2025-11-29 09:45:49.420759: Current learning rate: 0.00627 
2025-11-29 09:47:25.864580: train_loss -0.2065 
2025-11-29 09:47:25.864824: val_loss -0.2034 
2025-11-29 09:47:25.864957: Pseudo dice [0.0, 0.6307, 0.0494, 0.6328, 0.0, 0.4385, 0.9092, 0.9176] 
2025-11-29 09:47:25.865044: Epoch time: 96.45 s 
2025-11-29 09:47:27.961812:  
2025-11-29 09:47:27.962130: Epoch 406 
2025-11-29 09:47:27.962332: Current learning rate: 0.00626 
2025-11-29 09:49:03.006196: train_loss -0.2048 
2025-11-29 09:49:03.006523: val_loss -0.2116 
2025-11-29 09:49:03.006831: Pseudo dice [0.0, 0.6157, 0.0, 0.4823, 0.7142, 0.0159, 0.936, 0.9161] 
2025-11-29 09:49:03.006958: Epoch time: 95.05 s 
2025-11-29 09:49:05.272337:  
2025-11-29 09:49:05.272683: Epoch 407 
2025-11-29 09:49:05.272872: Current learning rate: 0.00625 
2025-11-29 09:50:40.329369: train_loss -0.216 
2025-11-29 09:50:40.329726: val_loss -0.2383 
2025-11-29 09:50:40.330052: Pseudo dice [0.733, 0.0, 0.754, 0.0, 0.6129, 0.0009, 0.9098, 0.9335] 
2025-11-29 09:50:40.330283: Epoch time: 95.06 s 
2025-11-29 09:50:42.398631:  
2025-11-29 09:50:42.398920: Epoch 408 
2025-11-29 09:50:42.399082: Current learning rate: 0.00624 
2025-11-29 09:52:17.025836: train_loss -0.211 
2025-11-29 09:52:17.026044: val_loss -0.2344 
2025-11-29 09:52:17.026265: Pseudo dice [0.6147, 0.015, 0.5865, 0.0, 0.3987, 0.0051, 0.9311, 0.9328] 
2025-11-29 09:52:17.026428: Epoch time: 94.63 s 
2025-11-29 09:52:19.110767:  
2025-11-29 09:52:19.111110: Epoch 409 
2025-11-29 09:52:19.111312: Current learning rate: 0.00623 
2025-11-29 09:53:53.439131: train_loss -0.2046 
2025-11-29 09:53:53.439414: val_loss -0.2129 
2025-11-29 09:53:53.439555: Pseudo dice [0.0002, 0.6556, 0.0001, 0.5379, 0.4718, 0.0782, 0.9041, 0.9035] 
2025-11-29 09:53:53.439734: Epoch time: 94.33 s 
2025-11-29 09:53:55.528982:  
2025-11-29 09:53:55.529234: Epoch 410 
2025-11-29 09:53:55.529432: Current learning rate: 0.00622 
2025-11-29 09:55:30.110634: train_loss -0.2191 
2025-11-29 09:55:30.110875: val_loss -0.23 
2025-11-29 09:55:30.111207: Pseudo dice [0.7756, 0.0195, 0.3527, 0.2132, 0.0, 0.5853, 0.8975, 0.9046] 
2025-11-29 09:55:30.111384: Epoch time: 94.58 s 
2025-11-29 09:55:32.060823:  
2025-11-29 09:55:32.061176: Epoch 411 
2025-11-29 09:55:32.061371: Current learning rate: 0.00621 
2025-11-29 09:57:07.078107: train_loss -0.2126 
2025-11-29 09:57:07.078361: val_loss -0.2363 
2025-11-29 09:57:07.078621: Pseudo dice [0.698, 0.021, 0.005, 0.6633, 0.6623, 0.0541, 0.9109, 0.9165] 
2025-11-29 09:57:07.078778: Epoch time: 95.02 s 
2025-11-29 09:57:09.038104:  
2025-11-29 09:57:09.038363: Epoch 412 
2025-11-29 09:57:09.038610: Current learning rate: 0.0062 
2025-11-29 09:58:43.414338: train_loss -0.2044 
2025-11-29 09:58:43.414608: val_loss -0.2095 
2025-11-29 09:58:43.414837: Pseudo dice [0.1493, 0.4863, 0.0071, 0.5451, 0.0, 0.5863, 0.8833, 0.895] 
2025-11-29 09:58:43.414997: Epoch time: 94.38 s 
2025-11-29 09:58:45.267150:  
2025-11-29 09:58:45.267466: Epoch 413 
2025-11-29 09:58:45.267627: Current learning rate: 0.00619 
2025-11-29 10:00:19.886459: train_loss -0.2049 
2025-11-29 10:00:19.886748: val_loss -0.2237 
2025-11-29 10:00:19.887106: Pseudo dice [0.0016, 0.6042, 0.0033, 0.4952, 0.7825, 0.2712, 0.919, 0.9037] 
2025-11-29 10:00:19.887291: Epoch time: 94.62 s 
2025-11-29 10:00:22.009604:  
2025-11-29 10:00:22.010028: Epoch 414 
2025-11-29 10:00:22.010223: Current learning rate: 0.00618 
2025-11-29 10:01:55.449609: train_loss -0.2109 
2025-11-29 10:01:55.449858: val_loss -0.2174 
2025-11-29 10:01:55.450046: Pseudo dice [0.0018, 0.6582, 0.5704, 0.0, 0.0, 0.7201, 0.9156, 0.9055] 
2025-11-29 10:01:55.450315: Epoch time: 93.44 s 
2025-11-29 10:01:57.379492:  
2025-11-29 10:01:57.379790: Epoch 415 
2025-11-29 10:01:57.379968: Current learning rate: 0.00617 
2025-11-29 10:03:31.003074: train_loss -0.2139 
2025-11-29 10:03:31.003330: val_loss -0.216 
2025-11-29 10:03:31.003531: Pseudo dice [0.0, 0.6292, 0.6777, 0.0, 0.0, 0.6069, 0.9029, 0.8843] 
2025-11-29 10:03:31.003713: Epoch time: 93.62 s 
2025-11-29 10:03:33.793978:  
2025-11-29 10:03:33.794269: Epoch 416 
2025-11-29 10:03:33.794431: Current learning rate: 0.00616 
2025-11-29 10:05:08.815726: train_loss -0.2094 
2025-11-29 10:05:08.815975: val_loss -0.2176 
2025-11-29 10:05:08.816219: Pseudo dice [0.6083, 0.0006, 0.5886, 0.0711, 0.7691, 0.0007, 0.9131, 0.9235] 
2025-11-29 10:05:08.816375: Epoch time: 95.02 s 
2025-11-29 10:05:10.726338:  
2025-11-29 10:05:10.726596: Epoch 417 
2025-11-29 10:05:10.726761: Current learning rate: 0.00615 
2025-11-29 10:06:45.292627: train_loss -0.2034 
2025-11-29 10:06:45.292986: val_loss -0.2468 
2025-11-29 10:06:45.293238: Pseudo dice [0.2142, 0.619, 0.0226, 0.6083, 0.0, 0.3872, 0.9224, 0.9148] 
2025-11-29 10:06:45.293393: Epoch time: 94.57 s 
2025-11-29 10:06:47.240721:  
2025-11-29 10:06:47.240952: Epoch 418 
2025-11-29 10:06:47.241111: Current learning rate: 0.00614 
2025-11-29 10:08:21.250842: train_loss -0.2183 
2025-11-29 10:08:21.251104: val_loss -0.2316 
2025-11-29 10:08:21.251390: Pseudo dice [0.0002, 0.6597, 0.7168, 0.0, 0.037, 0.5936, 0.9373, 0.9198] 
2025-11-29 10:08:21.251561: Epoch time: 94.01 s 
2025-11-29 10:08:23.280071:  
2025-11-29 10:08:23.280405: Epoch 419 
2025-11-29 10:08:23.280599: Current learning rate: 0.00613 
2025-11-29 10:09:57.277006: train_loss -0.2132 
2025-11-29 10:09:57.277349: val_loss -0.2334 
2025-11-29 10:09:57.277588: Pseudo dice [0.0003, 0.6268, 0.0142, 0.6534, 0.0, 0.769, 0.9165, 0.9089] 
2025-11-29 10:09:57.277731: Epoch time: 94.0 s 
2025-11-29 10:09:59.110028:  
2025-11-29 10:09:59.110280: Epoch 420 
2025-11-29 10:09:59.110481: Current learning rate: 0.00612 
2025-11-29 10:11:32.656779: train_loss -0.2043 
2025-11-29 10:11:32.657202: val_loss -0.2485 
2025-11-29 10:11:32.657434: Pseudo dice [0.0, 0.7221, 0.0151, 0.807, 0.4937, 0.0202, 0.9265, 0.9232] 
2025-11-29 10:11:32.657598: Epoch time: 93.55 s 
2025-11-29 10:11:34.545130:  
2025-11-29 10:11:34.545481: Epoch 421 
2025-11-29 10:11:34.545649: Current learning rate: 0.00612 
2025-11-29 10:13:08.285719: train_loss -0.2191 
2025-11-29 10:13:08.285958: val_loss -0.2216 
2025-11-29 10:13:08.286249: Pseudo dice [0.0004, 0.6906, 0.6526, 0.0, 0.0, 0.6059, 0.9109, 0.9177] 
2025-11-29 10:13:08.286516: Epoch time: 93.74 s 
2025-11-29 10:13:10.157780:  
2025-11-29 10:13:10.158114: Epoch 422 
2025-11-29 10:13:10.158317: Current learning rate: 0.00611 
2025-11-29 10:14:44.097786: train_loss -0.2165 
2025-11-29 10:14:44.098040: val_loss -0.2308 
2025-11-29 10:14:44.098306: Pseudo dice [0.0, 0.631, 0.0327, 0.5689, 0.5347, 0.161, 0.9258, 0.9331] 
2025-11-29 10:14:44.098450: Epoch time: 93.94 s 
2025-11-29 10:14:45.912785:  
2025-11-29 10:14:45.913061: Epoch 423 
2025-11-29 10:14:45.913253: Current learning rate: 0.0061 
2025-11-29 10:16:19.577917: train_loss -0.2062 
2025-11-29 10:16:19.578133: val_loss -0.2255 
2025-11-29 10:16:19.578394: Pseudo dice [0.5429, 0.1152, 0.5358, 0.0, 0.6396, 0.3206, 0.8897, 0.9175] 
2025-11-29 10:16:19.578661: Epoch time: 93.67 s 
2025-11-29 10:16:21.426363:  
2025-11-29 10:16:21.426705: Epoch 424 
2025-11-29 10:16:21.426873: Current learning rate: 0.00609 
2025-11-29 10:17:55.231886: train_loss -0.2207 
2025-11-29 10:17:55.232109: val_loss -0.2322 
2025-11-29 10:17:55.232372: Pseudo dice [0.6424, 0.0026, 0.589, 0.0, 0.4545, 0.0365, 0.9127, 0.9158] 
2025-11-29 10:17:55.232570: Epoch time: 93.81 s 
2025-11-29 10:17:57.035360:  
2025-11-29 10:17:57.035758: Epoch 425 
2025-11-29 10:17:57.035944: Current learning rate: 0.00608 
2025-11-29 10:19:31.149912: train_loss -0.2077 
2025-11-29 10:19:31.150252: val_loss -0.2236 
2025-11-29 10:19:31.150537: Pseudo dice [0.7043, 0.0016, 0.5539, 0.0, 0.0414, 0.5566, 0.9287, 0.9313] 
2025-11-29 10:19:31.150662: Epoch time: 94.12 s 
2025-11-29 10:19:33.121469:  
2025-11-29 10:19:33.121689: Epoch 426 
2025-11-29 10:19:33.121858: Current learning rate: 0.00607 
2025-11-29 10:21:07.522841: train_loss -0.1981 
2025-11-29 10:21:07.523094: val_loss -0.2205 
2025-11-29 10:21:07.523332: Pseudo dice [0.6645, 0.0, 0.6528, 0.0, 0.5389, 0.0303, 0.9223, 0.888] 
2025-11-29 10:21:07.523463: Epoch time: 94.4 s 
2025-11-29 10:21:09.352913:  
2025-11-29 10:21:09.353119: Epoch 427 
2025-11-29 10:21:09.353308: Current learning rate: 0.00606 
2025-11-29 10:22:43.488864: train_loss -0.2096 
2025-11-29 10:22:43.489174: val_loss -0.2413 
2025-11-29 10:22:43.489419: Pseudo dice [0.0002, 0.5147, 0.7761, 0.0, 0.0, 0.658, 0.9285, 0.9095] 
2025-11-29 10:22:43.489837: Epoch time: 94.14 s 
2025-11-29 10:22:45.362259:  
2025-11-29 10:22:45.362589: Epoch 428 
2025-11-29 10:22:45.362727: Current learning rate: 0.00605 
2025-11-29 10:24:19.531719: train_loss -0.2113 
2025-11-29 10:24:19.531963: val_loss -0.2145 
2025-11-29 10:24:19.532325: Pseudo dice [0.1389, 0.684, 0.7094, 0.0, 0.4936, 0.5803, 0.9187, 0.9155] 
2025-11-29 10:24:19.532514: Epoch time: 94.17 s 
2025-11-29 10:24:21.394708:  
2025-11-29 10:24:21.395054: Epoch 429 
2025-11-29 10:24:21.395236: Current learning rate: 0.00604 
2025-11-29 10:25:55.254795: train_loss -0.2179 
2025-11-29 10:25:55.255198: val_loss -0.2137 
2025-11-29 10:25:55.255420: Pseudo dice [0.655, 0.0043, 0.0009, 0.5533, 0.0, 0.6286, 0.8812, 0.8823] 
2025-11-29 10:25:55.255545: Epoch time: 93.86 s 
2025-11-29 10:25:57.214978:  
2025-11-29 10:25:57.215391: Epoch 430 
2025-11-29 10:25:57.215571: Current learning rate: 0.00603 
2025-11-29 10:27:31.305709: train_loss -0.2104 
2025-11-29 10:27:31.306022: val_loss -0.2337 
2025-11-29 10:27:31.306495: Pseudo dice [0.0003, 0.6593, 0.0997, 0.7044, 0.0, 0.7418, 0.9089, 0.9047] 
2025-11-29 10:27:31.306768: Epoch time: 94.09 s 
2025-11-29 10:27:33.219383:  
2025-11-29 10:27:33.219704: Epoch 431 
2025-11-29 10:27:33.219884: Current learning rate: 0.00602 
2025-11-29 10:29:06.939525: train_loss -0.2156 
2025-11-29 10:29:06.939775: val_loss -0.2335 
2025-11-29 10:29:06.939980: Pseudo dice [0.7306, 0.0003, 0.0002, 0.7646, 0.6971, 0.0225, 0.9107, 0.9206] 
2025-11-29 10:29:06.940120: Epoch time: 93.72 s 
2025-11-29 10:29:08.724773:  
2025-11-29 10:29:08.725081: Epoch 432 
2025-11-29 10:29:08.725295: Current learning rate: 0.00601 
2025-11-29 10:30:42.573577: train_loss -0.2135 
2025-11-29 10:30:42.573841: val_loss -0.201 
2025-11-29 10:30:42.574016: Pseudo dice [0.0008, 0.6275, 0.6746, 0.0, 0.5874, 0.0772, 0.904, 0.8836] 
2025-11-29 10:30:42.574128: Epoch time: 93.85 s 
2025-11-29 10:30:44.382741:  
2025-11-29 10:30:44.383038: Epoch 433 
2025-11-29 10:30:44.383236: Current learning rate: 0.006 
2025-11-29 10:32:18.605534: train_loss -0.212 
2025-11-29 10:32:18.605757: val_loss -0.1986 
2025-11-29 10:32:18.606006: Pseudo dice [0.6363, 0.0482, 0.0028, 0.6657, 0.3463, 0.1535, 0.9106, 0.9221] 
2025-11-29 10:32:18.606160: Epoch time: 94.22 s 
2025-11-29 10:32:20.564803:  
2025-11-29 10:32:20.565130: Epoch 434 
2025-11-29 10:32:20.565336: Current learning rate: 0.00599 
2025-11-29 10:33:54.555105: train_loss -0.2019 
2025-11-29 10:33:54.555370: val_loss -0.2254 
2025-11-29 10:33:54.555629: Pseudo dice [0.0, 0.6042, 0.0028, 0.5667, 0.5977, 0.0083, 0.9104, 0.9173] 
2025-11-29 10:33:54.555884: Epoch time: 93.99 s 
2025-11-29 10:33:56.394173:  
2025-11-29 10:33:56.394475: Epoch 435 
2025-11-29 10:33:56.394668: Current learning rate: 0.00598 
2025-11-29 10:35:30.380901: train_loss -0.2096 
2025-11-29 10:35:30.381281: val_loss -0.2288 
2025-11-29 10:35:30.381807: Pseudo dice [0.6345, 0.0005, 0.5883, 0.0, 0.6107, 0.0002, 0.914, 0.8809] 
2025-11-29 10:35:30.382231: Epoch time: 93.99 s 
2025-11-29 10:35:32.253598:  
2025-11-29 10:35:32.253990: Epoch 436 
2025-11-29 10:35:32.254198: Current learning rate: 0.00597 
