<div align="center">

# ğŸ¦´ 3D Segmentation and Modeling of Lower Limb Bones

[![Python 3.10+](https://img.shields.io/badge/Python-3.10+-3776AB?style=for-the-badge&logo=python&logoColor=white)](https://python.org)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.5+-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=white)](https://pytorch.org)
[![nnU-Net v2](https://img.shields.io/badge/nnU--Net-v2.6-00ADD8?style=for-the-badge)](https://github.com/MIC-DKFZ/nnUNet)
[![CUDA 12.1](https://img.shields.io/badge/CUDA-12.1+-76B900?style=for-the-badge&logo=nvidia&logoColor=white)](https://developer.nvidia.com/cuda-toolkit)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.115+-009688?style=for-the-badge&logo=fastapi&logoColor=white)](https://fastapi.tiangolo.com)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow?style=for-the-badge)](LICENSE)

**An end-to-end medical imaging solution for automatic bone segmentation & interactive 3D visualization**

[ğŸš€ Quick Start](#-quick-start-guide) â€¢ [ğŸ“– Documentation](#-project-overview) â€¢ [ğŸ–¥ï¸ Bone Viewer App](#-3d-bone-viewer-application) â€¢ [ğŸ“Š Results](#-expected-performance)

</div>

---

## ğŸ“‹ Project Overview

A comprehensive medical image analysis platform combining **state-of-the-art deep learning segmentation** with an **interactive 3D visualization application**. This project delivers a complete clinical workflow from raw CT scan preprocessing to surgical planning visualization.

<div align="center">

| ğŸ§  **AI Segmentation** | ğŸ¨ **3D Visualization** | âš¡ **Production Ready** |
|:---:|:---:|:---:|
| nnU-Net v2 powered | Three.js rendering | PWA + Clean Architecture |
| 8 anatomical classes | Real-time interaction | Offline-capable |
| 5-fold validation | Medical color schemes | RESTful API |

</div>

### âœ¨ Key Features

- ğŸ”¬ **Automated Bone Segmentation** â€” Segment 8 anatomical structures (Femur, Hip, Patella, Sacrum) bilaterally with clinical-grade accuracy
- ğŸ“Š **3D Volumetric Analysis** â€” Process full 3D CT volumes for comprehensive spatial analysis
- ğŸ–¥ï¸ **Interactive Visualization** â€” Web-based 3D bone viewer with implant planning capabilities
- ğŸ—ï¸ **Clean Architecture** â€” Production-ready backend with scalable domain-centric design
- ğŸ“± **Progressive Web App** â€” Installable, offline-capable frontend
- ğŸ” **Reproducible Pipeline** â€” Complete workflow for data preparation, training, and inference

---

## ğŸ¯ Project Scope

### Anatomical Targets (8 Classes)
The pipeline segments the following structures from lower limb CT scans:

<div align="center">

| Structure | Count | Side | Clinical Relevance |
|:----------|:-----:|:----:|:-------------------|
| ğŸ¦´ Femur (Thighbone) | 2 | Left & Right | Hip/Knee replacement |
| ğŸ¦´ Hip (Pelvis/Acetabulum) | 2 | Left & Right | Hip arthroplasty |
| ğŸ¦´ Patella (Kneecap) | 2 | Left & Right | Knee surgery |
| ğŸ¦´ Sacrum (Base of Spine) | 1 | Single | Spinal procedures |
| ğŸ¦´ Bone Threshold Region | 1 | Single | General analysis |
| **Total Classes** | **8** | â€” | â€” |

</div>

### Data Characteristics
- **Dataset Size**: 23+ manually segmented CT cases
- **Image Modality**: Computed Tomography (CT)
- **Image Format**: Medical imaging standards (NRRD â†’ NIfTI)
- **Spatial Resolution**: Variable, with median spacing standardization
- **Cross-validation**: 5-fold split for robust model evaluation

---

## ğŸ—ï¸ System Architecture

This project consists of two major components:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    3D SEGMENTATION & MODELING PLATFORM                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                    ğŸ§  AI SEGMENTATION PIPELINE                       â”‚    â”‚
â”‚  â”‚                                                                      â”‚    â”‚
â”‚  â”‚   CT Scans  â”€â”€â–º  nnU-Net v2  â”€â”€â–º  8-Class Segmentation  â”€â”€â–º  NIfTI â”‚    â”‚
â”‚  â”‚   (NRRD)         (3D U-Net)       (Bone Labels)              (.nii.gz)  â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                    â”‚                                         â”‚
â”‚                                    â–¼                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                    ğŸ–¥ï¸ 3D BONE VIEWER APPLICATION                    â”‚    â”‚
â”‚  â”‚                                                                      â”‚    â”‚
â”‚  â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚    â”‚
â”‚  â”‚   â”‚   Frontend   â”‚  REST    â”‚   Backend    â”‚  Process â”‚  NIfTI   â”‚ â”‚    â”‚
â”‚  â”‚   â”‚  (PWA/JS)    â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚  (FastAPI)   â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚  Files   â”‚ â”‚    â”‚
â”‚  â”‚   â”‚  Three.js    â”‚   API    â”‚   Python     â”‚          â”‚          â”‚ â”‚    â”‚
â”‚  â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”„ Complete Pipeline Workflow

```
Step 1: DATA EXTRACTION & CONVERSION
â”œâ”€ Extract individual bone segments from segmentation files
â”œâ”€ Convert NRRD â†’ NIfTI format (.nii.gz)
â”œâ”€ Global label mapping for consistency
â””â”€ Spatial alignment and resampling

              â†“

Step 2: DATASET PREPARATION (nnU-Net Format)
â”œâ”€ Organize into nnU-Net-compliant directory structure
â”œâ”€ Split into training/validation folds
â”œâ”€ Generate dataset.json metadata
â””â”€ Create preprocessing plans

              â†“

Step 3: PREPROCESSING & PLANNING
â”œâ”€ Analyze dataset properties (spacing, shape, intensity)
â”œâ”€ Create nnU-Net preprocessing plans
â”œâ”€ Generate 5-fold cross-validation splits
â””â”€ Normalize and standardize image data

              â†“

Step 4: MODEL TRAINING (nnU-Net v2)
â”œâ”€ Train 3D UNet models (3d_fullres configuration)
â”œâ”€ 5-fold cross-validation training
â”œâ”€ Automatic learning rate scheduling
â”œâ”€ Early stopping & checkpoint management
â””â”€ GPU-accelerated training (PyTorch + CUDA)

              â†“

Step 5: INFERENCE & VALIDATION
â”œâ”€ Run predictions on test cases
â”œâ”€ Generate probability maps and segmentations
â”œâ”€ Compute validation metrics (Dice, IoU)
â””â”€ Export results in standard formats

              â†“

Step 6: 3D VISUALIZATION & PLANNING
â”œâ”€ Load segmentation results in Bone Viewer
â”œâ”€ Interactive 3D bone visualization
â”œâ”€ Implant placement simulation
â””â”€ Surgical planning support
```

---

## ğŸ“ Project Structure

```
3D-Segmentation-and-Modeling-of-Lower-Limb-Bones/
â”‚
â”œâ”€â”€ ğŸ“‚ Data Preparation/                    # Core AI pipeline scripts
â”‚   â”œâ”€â”€ prepare_for_nnunet.py              # Full dataset preparation
â”‚   â”œâ”€â”€ prepare_for_nnunet_new.py          # Filtered dataset - 8 labels
â”‚   â”œâ”€â”€ preprocess_only.py                 # Preprocessing without training
â”‚   â”œâ”€â”€ train_nnunet.py                    # Complete training pipeline
â”‚   â”œâ”€â”€ train_single_fold.py               # Individual fold training
â”‚   â”œâ”€â”€ check_training_progress.py         # Monitor training status
â”‚   â”œâ”€â”€ setup_env_vars.ps1                 # Environment configuration
â”‚   â”œâ”€â”€ test.ipynb                         # Testing & validation notebook
â”‚   â”œâ”€â”€ nnUNet_raw_data/                   # Raw training data
â”‚   â”œâ”€â”€ nnUNet_preprocessed/               # Preprocessed data (auto-generated)
â”‚   â””â”€â”€ nnUNet_results/                    # Training results (auto-generated)
â”‚
â”œâ”€â”€ ğŸ“‚ bone_viewer_app/                     # ğŸ–¥ï¸ 3D Visualization Application
â”‚   â”œâ”€â”€ Medical_Image_Segmentation.ipynb   # Inference notebook
â”‚   â”œâ”€â”€ backend/                           # FastAPI backend (Clean Architecture)
â”‚   â”‚   â”œâ”€â”€ main.py                        # Entry point
â”‚   â”‚   â”œâ”€â”€ requirements.txt               # Backend dependencies
â”‚   â”‚   â”œâ”€â”€ src/                           # Clean Architecture source
â”‚   â”‚   â”‚   â”œâ”€â”€ domain/                    # Entities & Interfaces
â”‚   â”‚   â”‚   â”œâ”€â”€ application/               # Business logic (Services)
â”‚   â”‚   â”‚   â”œâ”€â”€ infrastructure/            # External adapters
â”‚   â”‚   â”‚   â””â”€â”€ presentation/              # API Layer (FastAPI routes)
â”‚   â”‚   â””â”€â”€ uploads/                       # Data storage
â”‚   â””â”€â”€ frontend/                          # PWA Frontend
â”‚       â”œâ”€â”€ index.html                     # PWA entry point
â”‚       â”œâ”€â”€ manifest.json                  # PWA manifest
â”‚       â”œâ”€â”€ sw.js                          # Service Worker (offline support)
â”‚       â”œâ”€â”€ css/                           # Stylesheets
â”‚       â”œâ”€â”€ js/                            # JavaScript modules (Three.js)
â”‚       â””â”€â”€ images/                        # Assets & icons
â”‚
â”œâ”€â”€ ğŸ“‚ CV Dataset/                          # Raw medical imaging data
â”‚   â””â”€â”€ 002/, 006/, ..., z066/             # 30+ subjects with NRRD files
â”‚
â”œâ”€â”€ ğŸ“‚ nnUNet_preds/                        # Inference predictions
â”‚   â”œâ”€â”€ PELVISTHIGHS_001.nii.gz            # Prediction results
â”‚   â”œâ”€â”€ dataset.json                       # Configuration
â”‚   â”œâ”€â”€ plans.json                         # Inference plans
â”‚   â””â”€â”€ predict_from_raw_data_args.json
â”‚
â”œâ”€â”€ ğŸ“‚ nnUNet_results/                      # Trained model checkpoints
â”‚   â””â”€â”€ Dataset001_PelvisThighs/           # Model outputs
â”‚
â”œâ”€â”€ ğŸ“‚ 3D-Segmentation/                     # Python virtual environment
â”‚   â””â”€â”€ (Pre-configured with all dependencies)
â”‚
â”œâ”€â”€ README.md                               # This documentation
â””â”€â”€ test.py                                 # Quick testing script
```

---

## ğŸ”§ Installation & Setup

### Prerequisites

<div align="center">

| Requirement | Minimum | Recommended |
|:------------|:--------|:------------|
| **Python** | 3.10+ | 3.12 |
| **GPU** | NVIDIA (CUDA 11.8+) | CUDA 12.1+ |
| **VRAM** | 8 GB | 24 GB+ |
| **RAM** | 16 GB | 32 GB+ |
| **Storage** | 50 GB | 100 GB+ |

</div>

### 1. Navigate to Project
```powershell
cd "d:\3D-Segmentation-and-Modeling-of-Lower-Limb-Bones"
```

### 2. Activate Virtual Environment
The project includes a pre-configured virtual environment in `3D-Segmentation/`:
```powershell
.\3D-Segmentation\Scripts\Activate.ps1
```

### 3. Set Environment Variables
```powershell
# Option A: Run PowerShell setup script
.\Data` Preparation\setup_env_vars.ps1

# Option B: Manual setup
$env:nnUNet_raw = "d:\3D-Segmentation-and-Modeling-of-Lower-Limb-Bones\Data Preparation\nnUNet_raw_data"
$env:nnUNet_preprocessed = "d:\3D-Segmentation-and-Modeling-of-Lower-Limb-Bones\Data Preparation\nnUNet_preprocessed"
$env:nnUNet_results = "d:\3D-Segmentation-and-Modeling-of-Lower-Limb-Bones\Data Preparation\nnUNet_results"
```

### 4. Key Dependencies

<details>
<summary>ğŸ“¦ Click to expand full dependency list</summary>

Pre-installed in the virtual environment:
- **nnunetv2** (2.6.2) - Medical image segmentation framework
- **PyTorch** (2.5.1 with CUDA 12.1) - Deep learning
- **nibabel** (5.3.2) - NIfTI file handling
- **scikit-image** (0.25.2) - Image processing
- **scipy** (1.16.3) - Scientific computing
- **numpy** (2.3.4) - Numerical operations
- **SimpleITK** (2.5.2) - Medical image processing
- **FastAPI** (0.115+) - REST API framework
- **Three.js** - WebGL 3D rendering

</details>

---

## ğŸš€ Quick Start Guide

<div align="center">

### Choose Your Workflow

</div>

<table>
<tr>
<td width="50%" valign="top">

### ğŸ§  AI Segmentation Pipeline

#### Option 1: Complete Pipeline (Recommended)
```powershell
cd "Data Preparation"

# Prepare filtered dataset (8-label)
python prepare_for_nnunet_new.py

# Train the model (5-fold CV)
python train_nnunet.py

# Monitor progress
python check_training_progress.py
```

#### Option 2: Full Dataset
```powershell
cd "Data Preparation"
python prepare_for_nnunet.py
python train_nnunet.py
```

#### Option 3: Preprocessing Only
```powershell
cd "Data Preparation"
python preprocess_only.py
```

#### Option 4: Train Specific Fold
```powershell
cd "Data Preparation"
python train_single_fold.py --fold 0
python train_single_fold.py --fold 1 --continue
```

</td>
<td width="50%" valign="top">

### ğŸ–¥ï¸ Bone Viewer Application

#### Step 1: Start Backend
```powershell
cd bone_viewer_app/backend

# Install dependencies (first time)
pip install -r requirements.txt

# Run server
python main.py
```
> API: `http://localhost:8001`

#### Step 2: Start Frontend
```powershell
cd bone_viewer_app/frontend

# Serve PWA
python -m http.server 8080
```
> Web App: `http://localhost:8080`

#### Step 3: Use the App
1. Open browser to `localhost:8080`
2. Drag & drop `.nii.gz` file
3. Explore 3D visualization
4. Add implants for planning

</td>
</tr>
</table>

---

## ğŸ–¥ï¸ 3D Bone Viewer Application

<div align="center">

![Bone Viewer Demo](bone_viewer_app/images/example.png)

*Interactive 3D visualization of segmented bones with surgical planning capabilities*

</div>

### Overview

The **3D Bone Viewer** is a full-stack medical visualization application designed for surgeons, radiologists, and medical professionals. It provides real-time 3D rendering of segmented bone structures with support for surgical implant planning.

### âœ¨ Application Features

<div align="center">

| Feature | Description |
|:--------|:------------|
| ğŸ—ï¸ **Clean Architecture** | Scalable, domain-centric backend design |
| ğŸ“± **Progressive Web App** | Installable, offline-capable, and responsive |
| ğŸ¦´ **NIfTI Processing** | Automatic bone extraction from segmentation files |
| ğŸ¨ **Medical Visualization** | High-fidelity 3D rendering with medical color schemes |
| âœ‹ **Interactive Controls** | Move, rotate, and scale bones in real-time |
| ğŸ”§ **Implant System** | Support for STL, PLY, and OBJ implant files |
| ğŸ”’ **Secure Data Handling** | Organized file storage and processing |

</div>

### ğŸ› ï¸ Technology Stack

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         FRONTEND                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  HTML5 â”‚ CSS3 (Light Theme) â”‚ JavaScript (ES Modules)â”‚    â”‚
â”‚  â”‚           Three.js (WebGL 3D Rendering)              â”‚    â”‚
â”‚  â”‚           PWA: Manifest + Service Worker              â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                         REST API
                              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    BACKEND (Clean Architecture)               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Domain    â”‚ â”‚Application â”‚ â”‚Infrastructureâ”‚ â”‚Presentationâ”‚ â”‚
â”‚  â”‚  Entities  â”‚ â”‚  Services  â”‚ â”‚  Adapters   â”‚ â”‚  FastAPI   â”‚ â”‚
â”‚  â”‚ Interfaces â”‚ â”‚   Logic    â”‚ â”‚ File System â”‚ â”‚   Routes   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                     Nibabel â”‚ NumPy â”‚ SciPy                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸš€ Running the Bone Viewer

#### 1. Start the Backend Server

```powershell
cd bone_viewer_app/backend
pip install -r requirements.txt
python main.py
```
> ğŸŒ API available at `http://localhost:8001`

#### 2. Launch the Frontend (PWA)

```powershell
cd bone_viewer_app/frontend
python -m http.server 8080
```
> ğŸŒ Open `http://localhost:8080` in Chrome/Edge

### ğŸ“– Usage Guide

<div align="center">

| Step | Action | Description |
|:----:|:-------|:------------|
| 1ï¸âƒ£ | **Install App** | Click the install icon in your browser to add as desktop/mobile app |
| 2ï¸âƒ£ | **Upload** | Drag & drop a `.nii.gz` segmentation file |
| 3ï¸âƒ£ | **Visualize** | Bones are automatically extracted and displayed in 3D |
| 4ï¸âƒ£ | **Interact** | Rotate, zoom, and pan to explore the anatomy |
| 5ï¸âƒ£ | **Plan** | Upload `.stl` or `.ply` implants for surgical planning |
| 6ï¸âƒ£ | **Offline** | App works offline after initial cache (backend needed for new processing) |

</div>

### ğŸ›ï¸ Clean Architecture Principles

The backend follows the **Dependency Rule** ensuring maintainability and testability:

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚    Presentation     â”‚  â† FastAPI routes, DTOs
                    â”‚   (Web Interface)   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚    Application      â”‚  â† Use cases, orchestration
                    â”‚    (Services)       â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚      Domain         â”‚  â† Entities, business rules
                    â”‚  (Core Business)    â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â–²
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   Infrastructure    â”‚  â† File I/O, external libs
                    â”‚    (Adapters)       â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Key: Domain knows nothing about outer layers
```

---

## ğŸ“Š Dataset Details

### Source Data
- **Raw Format**: NRRD files with embedded segmentation metadata
- **Segmentation Format**: Individual .nii.gz files per anatomical structure
- **Total Subjects**: 30+ manually segmented CT scans

### Processing Pipeline

#### Step 1: Extract & Convert
Extracts from `CV Dataset/` subjects:
- Identifies transformed segmentation folders
- Extracts individual bone label files
- Converts NRRD â†’ NIfTI format
- Output: Raw training data in NIfTI format

#### Step 2: Global Label Mapping
```
Femur_L    â†’ Label 1
Femur_R    â†’ Label 2
Hip_L      â†’ Label 3
Hip_R      â†’ Label 4
Patella_L  â†’ Label 5
Patella_R  â†’ Label 6
Sacrum     â†’ Label 7
Threshold-200-MAX â†’ Label 8
```

#### Step 3: Merge & Align
- Merges individual segmentations into single label map
- Resamples to reference geometry for consistency
- Ensures spatial alignment across dataset

#### Step 4: Create nnU-Net Dataset
Creates `dataset.json` with:
- Channel names (CT modality)
- Label mappings
- Training case count (23+)
- File format (.nii.gz)

---

## ğŸ§  Model Architecture

### nnU-Net v2 Configuration: 3d_fullres

**Why nnU-Net?**
- Fully automatic architecture design
- Self-configuring preprocessing
- State-of-the-art medical imaging segmentation
- Minimal manual tuning required

### Architecture Details
```
Input: CT Volume (variable size, normalized)
         â†“
    3D U-Net Network
     â”œâ”€ Encoder: 8 stages, progressive downsampling
     â”œâ”€ Bottleneck: Feature extraction
     â””â”€ Decoder: Progressive upsampling + skip connections
         â†“
Output: 9-class probability maps (8 classes + background)
         â†“
Post-processing: Smoothing, morphological operations
         â†“
Final Segmentation: Multi-label 3D volume
```

### Training Configuration
- **Training Strategy**: 5-fold cross-validation
- **Loss Function**: Dice + Cross-entropy (combined)
- **Optimizer**: Adam with automatic learning rate scheduling
- **Batch Size**: Adaptive to GPU memory
- **Epochs**: Up to 1000 (with early stopping)
- **Data Augmentation**: Aggressive spatial & intensity augmentation

### Validation
- Per-class Dice coefficient
- Foreground Dice (all structures combined)
- Results saved in `fold_X/validation_raw/`

---

## ğŸ“ˆ Expected Performance

<div align="center">

### Validation Metrics

| Metric | Description | Target |
|:-------|:------------|:-------|
| **Dice Similarity** | Volume overlap accuracy | > 0.90 |
| **Hausdorff Distance** | Surface distance (mm) | < 5.0 |
| **IoU** | Intersection-over-Union | > 0.85 |

### â±ï¸ Training Timeline

| Phase | Duration | Notes |
|:------|:---------|:------|
| Preprocessing | 10-30 min | One-time setup |
| Per Fold Training | 4-8 hours | GPU-dependent |
| Total Training (5 folds) | 20-40 hours | Can run in parallel |
| **Complete Pipeline** | **1-2 days** | End-to-end |

<sub>*Benchmarked on NVIDIA RTX 3090/4090 (24GB VRAM)*</sub>

</div>

---

## ğŸ“ Output Directories

### nnUNet_results Structure
```
Dataset001_PelvisThighs/
â””â”€â”€ nnUNetTrainer__nnUNetPlans__3d_fullres/
    â”œâ”€â”€ fold_1/
    â”‚   â”œâ”€â”€ checkpoint_final.pth       (Final model)
    â”‚   â”œâ”€â”€ checkpoint_best.pth        (Best checkpoint)
    â”‚   â”œâ”€â”€ training_log_*.txt         (Training metrics)
    â”‚   â”œâ”€â”€ validation_raw/            (Raw predictions)
    â”‚   â””â”€â”€ validation_raw_postprocessed/
    â”œâ”€â”€ fold_2/ to fold_5/
    â”œâ”€â”€ dataset.json
    â”œâ”€â”€ plans.json
    â””â”€â”€ dataset_fingerprint.json
```

### nnUNet_preds (Inference Results)
```
â”œâ”€â”€ PELVISTHIGHS_001.nii.gz  (Predicted segmentation)
â”œâ”€â”€ dataset.json              (Dataset info)
â”œâ”€â”€ plans.json               (Inference configuration)
â””â”€â”€ predict_from_raw_data_args.json
```

---

## ğŸ” Monitoring & Validation

### Check Training Progress
```powershell
python "Data Preparation/check_training_progress.py"
```

Shows:
- Fold status (NOT STARTED / IN PROGRESS / COMPLETED)
- Last update timestamp
- Latest validation metrics

### Inspect Predictions
```python
import nibabel as nib
import numpy as np

pred = nib.load("nnUNet_preds/PELVISTHIGHS_001.nii.gz").get_fdata()
print(f"Unique labels: {np.unique(pred)}")
print(f"Shape: {pred.shape}")
```

### Access Validation Results
```python
import json
from pathlib import Path

results_dir = Path("Data Preparation/nnUNet_results/Dataset001_PelvisThighs")
fold_dir = results_dir / "nnUNetTrainer__nnUNetPlans__3d_fullres/fold_1"

with open(fold_dir / "validation_raw_postprocessed/summary.json") as f:
    metrics = json.load(f)
    print(f"Validation Dice: {metrics['foreground_mean']['Dice']}")
```

---

## ğŸ› ï¸ Advanced Usage

### Customize Dataset Preparation
Edit `prepare_for_nnunet_new.py` to:
- Change `ALLOWED_LABELS` for different anatomical structures
- Modify `find_raw_ct_for_case()` for custom data discovery
- Adjust label merging strategy

### Custom Training Configuration
Modify `train_nnunet.py`:
```python
cmd = [
    'nnUNetv2_train',
    '1',              # Dataset ID
    '3d_fullres',    # Config (2d, 3d_lowres, 3d_fullres)
    str(fold),       # Fold number
    '--npz',         # Save predictions
    '--num_gpus', '2'  # Multi-GPU training
]
```

### Resume Interrupted Training
```powershell
python train_single_fold.py --fold 0 --continue
```

---

## ğŸ“š References & Resources

<div align="center">

| Resource | Link |
|:---------|:-----|
| ğŸ“– nnU-Net v2 Paper | Isensee et al., *Nature Methods* (2021) |
| ğŸ”— nnU-Net GitHub | [MIC-DKFZ/nnUNet](https://github.com/MIC-DKFZ/nnUNet) |
| ğŸ“– U-Net Paper | [arXiv:1505.04597](https://arxiv.org/abs/1505.04597) |
| ğŸ”¥ PyTorch Docs | [pytorch.org/docs](https://pytorch.org/docs) |
| ğŸ§Š Three.js Docs | [threejs.org/docs](https://threejs.org/docs) |
| ğŸ¥ NIfTI Format | Neuroimaging Informatics Technology Initiative |

</div>

---

## ğŸ› Troubleshooting

<details>
<summary><b>ğŸ”´ GPU Not Detected</b></summary>

```powershell
python -c "import torch; print(f'CUDA Available: {torch.cuda.is_available()}')"
python -c "import torch; print(torch.cuda.get_device_properties(0))"
```

**Solution**: Ensure NVIDIA drivers and CUDA toolkit are properly installed.

</details>

<details>
<summary><b>ğŸ”´ Memory Errors During Training</b></summary>

```powershell
nvidia-smi  # Check VRAM usage
```

**Solution**: Reduce batch size in `plans.json` or use `2d` configuration instead of `3d_fullres`.

</details>

<details>
<summary><b>ğŸ”´ Missing Dependencies</b></summary>

```powershell
pip install --upgrade nnunetv2
python -c "import nnunetv2; print(nnunetv2.__version__)"
```

</details>

<details>
<summary><b>ğŸ”´ Data Not Found</b></summary>

```powershell
echo $env:nnUNet_raw
echo $env:nnUNet_preprocessed
echo $env:nnUNet_results
dir "Data Preparation/nnUNet_raw_data/Dataset001_LowerLimb"
```

**Solution**: Verify environment variables are set correctly.

</details>

<details>
<summary><b>ğŸ”´ Bone Viewer Not Loading</b></summary>

1. Ensure backend is running on port 8001
2. Check browser console for CORS errors
3. Try clearing browser cache
4. Use Chrome or Edge for best PWA support

</details>

---

## âœ… Checklist for First-Time Users

### AI Segmentation Pipeline
- [ ] Activate virtual environment (`.\3D-Segmentation\Scripts\Activate.ps1`)
- [ ] Set nnU-Net environment variables
- [ ] Verify GPU availability
- [ ] Run `prepare_for_nnunet_new.py` (data preparation)
- [ ] Run `train_nnunet.py` (start training)
- [ ] Monitor with `check_training_progress.py`
- [ ] Analyze results in `nnUNet_results/`

### 3D Bone Viewer Application
- [ ] Install backend dependencies (`pip install -r requirements.txt`)
- [ ] Start backend server (`python main.py`)
- [ ] Launch frontend (`python -m http.server 8080`)
- [ ] Install PWA in browser (optional)
- [ ] Upload segmentation results for visualization

---

<div align="center">

## ğŸ“¬ Contact & Support

For questions, issues, or contributions, please open an issue in this repository.

---

### ğŸ“ Project Information

| Attribute | Details |
|:----------|:--------|
| **Framework** | nnU-Net v2 (Automatic Medical Image Segmentation) |
| **Task** | Multi-class 3D segmentation + Interactive visualization |
| **Input** | CT images (NRRD/NIfTI format) |
| **Output** | 8-class segmentation masks + 3D rendered models |
| **Validation** | 5-fold cross-validation |
| **GPU Support** | NVIDIA CUDA 12.1+ |
| **License** | MIT |

---

**Last Updated**: January 2026 | **Status**: ğŸŸ¢ Active Development | **Version**: 2.0

<sub>Made with â¤ï¸ for the medical imaging community</sub>

</div>
